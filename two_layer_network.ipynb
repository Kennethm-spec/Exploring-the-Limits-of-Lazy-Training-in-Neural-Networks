{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard \n",
    "%rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 10)  # 100 10-dimensional observations\n",
    "# binary label classification for each observation\n",
    "y = np.random.randint(0, 2, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_range = np.arange(100, 105, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs[\"loss\"]\n",
    "        if loss <= self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = []\n",
    "final_weights = []\n",
    "diff_weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units: 100\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 16:17:14.924735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.7084 - accuracy: 0.4946"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Multiple Default OpKernel registrations match NodeDef '{{node ZerosLike}}': 'op: \"ZerosLike\" device_type: \"DEFAULT\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"y\"' and 'op: \"ZerosLike\" device_type: \"DEFAULT\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"y\"' [Op:ZerosLike]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39mlog_dir, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback], verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Print out final weights and compute differences:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m final_weights\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_weights()[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:194\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m@lazy_tensor_creator\u001b[39m\u001b[39m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_tensor\u001b[39m():\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m    195\u001b[0m     tag\u001b[39m=\u001b[39mtag,\n\u001b[1;32m    196\u001b[0m     tensor\u001b[39m=\u001b[39mlazy_tensor,\n\u001b[1;32m    197\u001b[0m     step\u001b[39m=\u001b[39mstep,\n\u001b[1;32m    198\u001b[0m     metadata\u001b[39m=\u001b[39msummary_metadata,\n\u001b[1;32m    199\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/util/lazy_tensor_creator.py:66\u001b[0m, in \u001b[0;36mLazyTensorCreator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor \u001b[39m=\u001b[39m _CALL_IN_PROGRESS_SENTINEL\n\u001b[0;32m---> 66\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor_callable()\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:192\u001b[0m, in \u001b[0;36mhistogram.<locals>.lazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m@lazy_tensor_creator\u001b[39m\u001b[39m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_tensor\u001b[39m():\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m _buckets(data, buckets)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:291\u001b[0m, in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mtranspose(a\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(\n\u001b[1;32m    288\u001b[0m         has_single_value, when_single_value, when_multiple_values\n\u001b[1;32m    289\u001b[0m     )\n\u001b[0;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(is_empty, when_empty, when_nonempty)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:287\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m     bucket_counts \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(\n\u001b[1;32m    282\u001b[0m         tf\u001b[39m.\u001b[39mconcat([zeroes[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], [data_size]], \u001b[39m0\u001b[39m)[:bucket_count],\n\u001b[1;32m    283\u001b[0m         dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mtranspose(a\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[0;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcond(\n\u001b[1;32m    288\u001b[0m     has_single_value, when_single_value, when_multiple_values\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:263\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty.<locals>.when_multiple_values\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m one_hots \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mone_hot(\n\u001b[1;32m    257\u001b[0m     clamped_indices, depth\u001b[39m=\u001b[39mbucket_count, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m bucket_counts \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(\n\u001b[1;32m    260\u001b[0m     tf\u001b[39m.\u001b[39mreduce_sum(input_tensor\u001b[39m=\u001b[39mone_hots, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m    261\u001b[0m     dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64,\n\u001b[1;32m    262\u001b[0m )\n\u001b[0;32m--> 263\u001b[0m edges \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlinspace(min_, max_, bucket_count \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    264\u001b[0m \u001b[39m# Ensure edges[-1] == max_, which TF's linspace implementation does not\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# do, leaving it subject to the whim of floating point rounding error.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m edges \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconcat([edges[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], [max_]], \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Multiple Default OpKernel registrations match NodeDef '{{node ZerosLike}}': 'op: \"ZerosLike\" device_type: \"DEFAULT\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"y\"' and 'op: \"ZerosLike\" device_type: \"DEFAULT\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"y\"' [Op:ZerosLike]"
     ]
    }
   ],
   "source": [
    "for units in unit_range:\n",
    "    print(f\"Number of units: {units}\")\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=units, activation='relu', input_shape=(10,)),\n",
    "        tf.keras.layers.Dense(units = units, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')])\n",
    "\n",
    "    # Print initial weights:\n",
    "    initial_weights.append(model.layers[0].get_weights()[0])\n",
    "    # Compile model with loss function and optimizer:\n",
    "\n",
    "    # Instantiate the callback:\n",
    "    my_callback = MyThresholdCallback(threshold=0.005)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X, y, epochs=400, batch_size=1, callbacks=my_callback , verbose=1)\n",
    "\n",
    "    # Print out final weights and compute differences:\n",
    "    final_weights.append(model.layers[0].get_weights()[0])\n",
    "    diff_weights.append(final_weights[-1] - initial_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9d36f077aa35a74f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9d36f077aa35a74f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
