{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 10)  # 100 10-dimensional observations\n",
    "# binary label classification for each observation\n",
    "y = np.random.randint(0, 2, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs[\"loss\"]\n",
    "        if loss <= self.threshold:\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units per layer: 500\n",
      "Number of layers: 2\n"
     ]
    }
   ],
   "source": [
    "my_callback = MyThresholdCallback(threshold=0.005)\n",
    "\n",
    "\n",
    "units_per_layer = 500\n",
    "layers = 2\n",
    "print(f\"Number of units per layer: {units_per_layer}\")\n",
    "print(f\"Number of layers: {layers}\")\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = units_per_layer, activation = 'relu', input_shape = (10,)))\n",
    "for _ in range(layers - 1):\n",
    "    model.add(tf.keras.layers.Dense(units = units_per_layer, activation = 'relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Grab the random initialization of the weights:\n",
    "initial_weights_ml = []\n",
    "for i in range(layers):\n",
    "    initial_weights_ml.append(model.layers[i].get_weights()[0])\n",
    "\n",
    "# Compile and fit the model:\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "history = model.fit(X, y, epochs=5000, batch_size=1, callbacks=[my_callback], verbose=0)\n",
    "\n",
    "# Grab the final position of the weights:\n",
    "final_weights_ml = []\n",
    "for i in range(layers):\n",
    "    final_weights_ml.append(model.layers[i].get_weights()[0])\n",
    "\n",
    "# Find the difference for each layer:\n",
    "diff_weights_ml = []\n",
    "for i in range(layers):\n",
    "    diff_weights_ml.append(np.linalg.norm(initial_weights_ml[i]-final_weights_ml[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units: 100\n",
      "Number of units: 110\n",
      "Number of units: 120\n",
      "Number of units: 130\n",
      "Number of units: 140\n",
      "Number of units: 150\n",
      "Number of units: 160\n",
      "Number of units: 170\n",
      "Number of units: 180\n",
      "Number of units: 190\n",
      "Number of units: 200\n",
      "Number of units: 210\n",
      "Number of units: 220\n",
      "Number of units: 230\n",
      "Number of units: 240\n",
      "Number of units: 250\n",
      "Number of units: 260\n",
      "Number of units: 270\n",
      "Number of units: 280\n",
      "Number of units: 290\n",
      "Number of units: 300\n",
      "Number of units: 310\n",
      "Number of units: 320\n",
      "Number of units: 330\n",
      "Number of units: 340\n",
      "Number of units: 350\n",
      "Number of units: 360\n",
      "Number of units: 370\n",
      "Number of units: 380\n",
      "Number of units: 390\n",
      "Number of units: 400\n",
      "Number of units: 410\n",
      "Number of units: 420\n",
      "Number of units: 430\n",
      "Number of units: 440\n",
      "Number of units: 450\n",
      "Number of units: 460\n",
      "Number of units: 470\n",
      "Number of units: 480\n",
      "Number of units: 490\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 10) # 100 datapoints of 10 features each\n",
    "y = np.random.randint(0, 2, size = 100) # binary classification labels\n",
    "\n",
    "# Initialize arrays for storing weights\n",
    "initial_weights = []\n",
    "final_weights = []\n",
    "diff_weights = []\n",
    "\n",
    "# Define the range of units in the first layer\n",
    "unit_range = np.arange(100, 500, 10)\n",
    "\n",
    "for units in unit_range:\n",
    "    # Define the model architecture\n",
    "    print(f\"Number of units: {units}\")\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=units, activation='relu', input_shape=(10,)),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Print initial weights\n",
    "    initial_weights.append(model.layers[0].get_weights()[0])\n",
    "\n",
    "    # Compile the model with a loss function and an optimizer\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model using lazy training\n",
    "    model.fit(X, y, epochs=1000, batch_size=1, callbacks = [my_callback], verbose=0)\n",
    "\n",
    "    # Print final weights and calculate difference\n",
    "    final_weights.append(model.layers[0].get_weights()[0])\n",
    "    diff_weights.append(final_weights[-1] - initial_weights[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_avg = []\n",
    "for i in range(len(unit_range)):\n",
    "    diff_weights_flat = np.ndarray.flatten(diff_weights[i])\n",
    "    diff_weights_flat = np.abs(diff_weights_flat)\n",
    "    diff_avg.append(np.average(diff_weights_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the size of the figure\n",
    "fig, ax = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "# create the plot\n",
    "ax.plot(unit_range, diff_avg, linestyle = '-', marker = 'o')\n",
    "\n",
    "# set the title and axis labels\n",
    "ax.set_title('Average drift of neurons as a function of amount of nuerons')\n",
    "ax.set_xlabel('Number of neurons')\n",
    "ax.set_ylabel('Average drift')\n",
    "ax.set_ylim([0, 2.5])\n",
    "ax.set_xlim([100, 1000])\n",
    "\n",
    "# plot line of best fit \n",
    "ax.plot(unit_range, line_of_best_fit, linestyle = '--', color = 'red')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
