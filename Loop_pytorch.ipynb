{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb7da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units: 100\n",
      "train loss: 0.004860672630693159, at epoch: 336\n",
      "\n",
      "Number of units: 110\n",
      "train loss: 0.004723888545561863, at epoch: 318\n",
      "\n",
      "Number of units: 120\n",
      "train loss: 0.004896260369687298, at epoch: 345\n",
      "\n",
      "Number of units: 130\n",
      "train loss: 0.004879272458565538, at epoch: 310\n",
      "\n",
      "Number of units: 140\n",
      "train loss: 0.004635570972442338, at epoch: 284\n",
      "\n",
      "Number of units: 150\n",
      "train loss: 0.004838160178538828, at epoch: 293\n",
      "\n",
      "Number of units: 160\n",
      "train loss: 0.004942459204385159, at epoch: 274\n",
      "\n",
      "Number of units: 170\n",
      "train loss: 0.00483092492395059, at epoch: 253\n",
      "\n",
      "Number of units: 180\n",
      "train loss: 0.004784231476865557, at epoch: 252\n",
      "\n",
      "Number of units: 190\n",
      "train loss: 0.004488454741345436, at epoch: 260\n",
      "\n",
      "Number of units: 200\n",
      "train loss: 0.00478838343999314, at epoch: 226\n",
      "\n",
      "Number of units: 210\n",
      "train loss: 0.004788711685066573, at epoch: 246\n",
      "\n",
      "Number of units: 220\n",
      "train loss: 0.0049266578691117505, at epoch: 268\n",
      "\n",
      "Number of units: 230\n",
      "train loss: 0.004830430811927045, at epoch: 214\n",
      "\n",
      "Number of units: 240\n",
      "train loss: 0.004718689925551871, at epoch: 221\n",
      "\n",
      "Number of units: 250\n",
      "train loss: 0.004982805593812145, at epoch: 220\n",
      "\n",
      "Number of units: 260\n",
      "train loss: 0.004789449454813166, at epoch: 223\n",
      "\n",
      "Number of units: 270\n",
      "train loss: 0.004773490205215296, at epoch: 209\n",
      "\n",
      "Number of units: 280\n",
      "train loss: 0.004844812632208004, at epoch: 211\n",
      "\n",
      "Number of units: 290\n",
      "train loss: 0.0047799992898399065, at epoch: 203\n",
      "\n",
      "Number of units: 300\n",
      "train loss: 0.0048411924804946695, at epoch: 202\n",
      "\n",
      "Number of units: 310\n",
      "train loss: 0.004862034128497044, at epoch: 195\n",
      "\n",
      "Number of units: 320\n",
      "train loss: 0.0048450419478052705, at epoch: 196\n",
      "\n",
      "Number of units: 330\n",
      "train loss: 0.00497560926491758, at epoch: 189\n",
      "\n",
      "Number of units: 340\n",
      "train loss: 0.004890567596614801, at epoch: 190\n",
      "\n",
      "Number of units: 350\n",
      "train loss: 0.004889125471840998, at epoch: 184\n",
      "\n",
      "Number of units: 360\n",
      "train loss: 0.00488544089190384, at epoch: 184\n",
      "\n",
      "Number of units: 370\n",
      "train loss: 0.004928306729331098, at epoch: 190\n",
      "\n",
      "Number of units: 380\n",
      "train loss: 0.004642224604256171, at epoch: 191\n",
      "\n",
      "Number of units: 390\n",
      "train loss: 0.0048375232569628675, at epoch: 176\n",
      "\n",
      "Number of units: 400\n",
      "train loss: 0.0048728862578633425, at epoch: 192\n",
      "\n",
      "Number of units: 410\n",
      "train loss: 0.004842486634514671, at epoch: 170\n",
      "\n",
      "Number of units: 420\n",
      "train loss: 0.004986458413266064, at epoch: 171\n",
      "\n",
      "Number of units: 430\n",
      "train loss: 0.004832169249103089, at epoch: 171\n",
      "\n",
      "Number of units: 440\n",
      "train loss: 0.004928378155117343, at epoch: 165\n",
      "\n",
      "Number of units: 450\n",
      "train loss: 0.004886964677604055, at epoch: 173\n",
      "\n",
      "Number of units: 460\n",
      "train loss: 0.004801641169385675, at epoch: 167\n",
      "\n",
      "Number of units: 470\n",
      "train loss: 0.004725591206368165, at epoch: 162\n",
      "\n",
      "Number of units: 480\n",
      "train loss: 0.004849085558098523, at epoch: 160\n",
      "\n",
      "Number of units: 490\n",
      "train loss: 0.004918053639428308, at epoch: 154\n",
      "\n",
      "Number of units: 500\n",
      "train loss: 0.004344142129120883, at epoch: 164\n",
      "\n",
      "Number of units: 510\n",
      "train loss: 0.004808143387861321, at epoch: 164\n",
      "\n",
      "Number of units: 520\n",
      "train loss: 0.004602972159041201, at epoch: 154\n",
      "\n",
      "Number of units: 530\n",
      "train loss: 0.004798753844147825, at epoch: 155\n",
      "\n",
      "Number of units: 540\n",
      "train loss: 0.0049727626914008735, at epoch: 153\n",
      "\n",
      "Number of units: 550\n",
      "train loss: 0.004918803629804245, at epoch: 149\n",
      "\n",
      "Number of units: 560\n",
      "train loss: 0.004873919431049672, at epoch: 152\n",
      "\n",
      "Number of units: 570\n",
      "train loss: 0.0049979771067319234, at epoch: 153\n",
      "\n",
      "Number of units: 580\n",
      "train loss: 0.004862323338498698, at epoch: 146\n",
      "\n",
      "Number of units: 590\n",
      "train loss: 0.004623970062170031, at epoch: 152\n",
      "\n",
      "Number of units: 600\n",
      "train loss: 0.0049471382764591, at epoch: 147\n",
      "\n",
      "Number of units: 610\n",
      "train loss: 0.004909889366647064, at epoch: 144\n",
      "\n",
      "Number of units: 620\n",
      "train loss: 0.004905028593231009, at epoch: 147\n",
      "\n",
      "Number of units: 630\n",
      "train loss: 0.004898230128935097, at epoch: 144\n",
      "\n",
      "Number of units: 640\n",
      "train loss: 0.004971157200197922, at epoch: 139\n",
      "\n",
      "Number of units: 650\n",
      "train loss: 0.0048685246336575005, at epoch: 142\n",
      "\n",
      "Number of units: 660\n",
      "train loss: 0.004584435261902229, at epoch: 143\n",
      "\n",
      "Number of units: 670\n",
      "train loss: 0.004767765505048942, at epoch: 138\n",
      "\n",
      "Number of units: 680\n",
      "train loss: 0.004983208275271522, at epoch: 137\n",
      "\n",
      "Number of units: 690\n",
      "train loss: 0.004680316932444981, at epoch: 139\n",
      "\n",
      "Number of units: 700\n",
      "train loss: 0.0048794599650841515, at epoch: 138\n",
      "\n",
      "Number of units: 710\n",
      "train loss: 0.00478660011659116, at epoch: 133\n",
      "\n",
      "Number of units: 720\n",
      "train loss: 0.004541561893184394, at epoch: 136\n",
      "\n",
      "Number of units: 730\n",
      "train loss: 0.004747495667220392, at epoch: 131\n",
      "\n",
      "Number of units: 740\n",
      "train loss: 0.004691878440721667, at epoch: 130\n",
      "\n",
      "Number of units: 750\n",
      "train loss: 0.004873439873949792, at epoch: 134\n",
      "\n",
      "Number of units: 760\n",
      "train loss: 0.0046969258576575615, at epoch: 131\n",
      "\n",
      "Number of units: 770\n",
      "train loss: 0.004987492079931286, at epoch: 133\n",
      "\n",
      "Number of units: 780\n",
      "train loss: 0.004842299698712225, at epoch: 127\n",
      "\n",
      "Number of units: 790\n",
      "train loss: 0.004843088247790206, at epoch: 125\n",
      "\n",
      "Number of units: 800\n",
      "train loss: 0.004910243415242804, at epoch: 128\n",
      "\n",
      "Number of units: 810\n",
      "train loss: 0.004983408693943261, at epoch: 127\n",
      "\n",
      "Number of units: 820\n",
      "train loss: 0.004673644765489371, at epoch: 129\n",
      "\n",
      "Number of units: 830\n",
      "train loss: 0.004820375500685827, at epoch: 130\n",
      "\n",
      "Number of units: 840\n",
      "train loss: 0.004845995489678217, at epoch: 126\n",
      "\n",
      "Number of units: 850\n",
      "train loss: 0.0048588576811926035, at epoch: 126\n",
      "\n",
      "Number of units: 860\n",
      "train loss: 0.004173290958688085, at epoch: 127\n",
      "\n",
      "Number of units: 870\n",
      "train loss: 0.004495433295070938, at epoch: 127\n",
      "\n",
      "Number of units: 880\n",
      "train loss: 0.00482208023765935, at epoch: 125\n",
      "\n",
      "Number of units: 890\n",
      "train loss: 0.004357630095879017, at epoch: 126\n",
      "\n",
      "Number of units: 900\n",
      "train loss: 0.0049607831754997275, at epoch: 120\n",
      "\n",
      "Number of units: 910\n",
      "train loss: 0.004911861457593432, at epoch: 120\n",
      "\n",
      "Number of units: 920\n",
      "train loss: 0.00496005706226299, at epoch: 122\n",
      "\n",
      "Number of units: 930\n",
      "train loss: 0.004521019638780217, at epoch: 120\n",
      "\n",
      "Number of units: 940\n",
      "train loss: 0.004945568367120927, at epoch: 120\n",
      "\n",
      "Number of units: 950\n",
      "train loss: 0.0042836261313152595, at epoch: 121\n",
      "\n",
      "Number of units: 960\n",
      "train loss: 0.004591077267480159, at epoch: 119\n",
      "\n",
      "Number of units: 970\n",
      "train loss: 0.0038900178361302553, at epoch: 125\n",
      "\n",
      "Number of units: 980\n",
      "train loss: 0.004729107671780781, at epoch: 119\n",
      "\n",
      "Number of units: 990\n",
      "train loss: 0.0046605153009114985, at epoch: 117\n",
      "\n",
      "Number of units: 1000\n",
      "train loss: 0.004112935994508007, at epoch: 120\n",
      "\n",
      "Number of units: 1010\n",
      "train loss: 0.004874247036200501, at epoch: 114\n",
      "\n",
      "Number of units: 1020\n",
      "train loss: 0.004890903572945717, at epoch: 115\n",
      "\n",
      "Number of units: 1030\n",
      "train loss: 0.004997444955735659, at epoch: 112\n",
      "\n",
      "Number of units: 1040\n",
      "train loss: 0.004083910192444052, at epoch: 121\n",
      "\n",
      "Number of units: 1050\n",
      "train loss: 0.004843131954367124, at epoch: 114\n",
      "\n",
      "Number of units: 1060\n",
      "train loss: 0.004885437840534905, at epoch: 114\n",
      "\n",
      "Number of units: 1070\n",
      "train loss: 0.004961796646139192, at epoch: 115\n",
      "\n",
      "Number of units: 1080\n",
      "train loss: 0.004529132951747812, at epoch: 113\n",
      "\n",
      "Number of units: 1090\n",
      "train loss: 0.004939672828714663, at epoch: 111\n",
      "\n",
      "Number of units: 1100\n",
      "train loss: 0.004404204059616177, at epoch: 117\n",
      "\n",
      "Number of units: 1110\n",
      "train loss: 0.00492355555285286, at epoch: 114\n",
      "\n",
      "Number of units: 1120\n",
      "train loss: 0.0043430693254958895, at epoch: 114\n",
      "\n",
      "Number of units: 1130\n",
      "train loss: 0.004371145936128187, at epoch: 115\n",
      "\n",
      "Number of units: 1140\n",
      "train loss: 0.00493829643585741, at epoch: 115\n",
      "\n",
      "Number of units: 1150\n",
      "train loss: 0.00471754445802631, at epoch: 111\n",
      "\n",
      "Number of units: 1160\n",
      "train loss: 0.004854233979321521, at epoch: 110\n",
      "\n",
      "Number of units: 1170\n",
      "train loss: 0.004886890346676296, at epoch: 109\n",
      "\n",
      "Number of units: 1180\n",
      "train loss: 0.00491213920680309, at epoch: 108\n",
      "\n",
      "Number of units: 1190\n",
      "train loss: 0.00467751142242264, at epoch: 110\n",
      "\n",
      "Number of units: 1200\n",
      "train loss: 0.0049533800351902356, at epoch: 111\n",
      "\n",
      "Number of units: 1210\n",
      "train loss: 0.004658976961259498, at epoch: 111\n",
      "\n",
      "Number of units: 1220\n",
      "train loss: 0.004837920702894963, at epoch: 106\n",
      "\n",
      "Number of units: 1230\n",
      "train loss: 0.004985660584861904, at epoch: 108\n",
      "\n",
      "Number of units: 1240\n",
      "train loss: 0.004672829430101615, at epoch: 107\n",
      "\n",
      "Number of units: 1250\n",
      "train loss: 0.004603288053959034, at epoch: 108\n",
      "\n",
      "Number of units: 1260\n",
      "train loss: 0.0049314013648157125, at epoch: 107\n",
      "\n",
      "Number of units: 1270\n",
      "train loss: 0.004893002374133318, at epoch: 106\n",
      "\n",
      "Number of units: 1280\n",
      "train loss: 0.004874453256043694, at epoch: 107\n",
      "\n",
      "Number of units: 1290\n",
      "train loss: 0.0046054192132254455, at epoch: 106\n",
      "\n",
      "Number of units: 1300\n",
      "train loss: 0.0047506001121975314, at epoch: 107\n",
      "\n",
      "Number of units: 1310\n",
      "train loss: 0.004832927797867797, at epoch: 107\n",
      "\n",
      "Number of units: 1320\n",
      "train loss: 0.004324449725628483, at epoch: 105\n",
      "\n",
      "Number of units: 1330\n",
      "train loss: 0.004579292665689536, at epoch: 106\n",
      "\n",
      "Number of units: 1340\n",
      "train loss: 0.004802878488700912, at epoch: 103\n",
      "\n",
      "Number of units: 1350\n",
      "train loss: 0.004716871939224916, at epoch: 105\n",
      "\n",
      "Number of units: 1360\n",
      "train loss: 0.004831169726591042, at epoch: 103\n",
      "\n",
      "Number of units: 1370\n",
      "train loss: 0.004728871841141426, at epoch: 103\n",
      "\n",
      "Number of units: 1380\n",
      "train loss: 0.0043813234626624365, at epoch: 105\n",
      "\n",
      "Number of units: 1390\n",
      "train loss: 0.004939050981462856, at epoch: 102\n",
      "\n",
      "Number of units: 1400\n",
      "train loss: 0.00491681038281996, at epoch: 104\n",
      "\n",
      "Number of units: 1410\n",
      "train loss: 0.004662742375456333, at epoch: 104\n",
      "\n",
      "Number of units: 1420\n",
      "train loss: 0.004769095397003014, at epoch: 101\n",
      "\n",
      "Number of units: 1430\n",
      "train loss: 0.004437550625107178, at epoch: 106\n",
      "\n",
      "Number of units: 1440\n",
      "train loss: 0.004358974266310724, at epoch: 103\n",
      "\n",
      "Number of units: 1450\n",
      "train loss: 0.004833523030948754, at epoch: 98\n",
      "\n",
      "Number of units: 1460\n",
      "train loss: 0.004936632384382733, at epoch: 103\n",
      "\n",
      "Number of units: 1470\n",
      "train loss: 0.004915844462855716, at epoch: 100\n",
      "\n",
      "Number of units: 1480\n",
      "train loss: 0.004986957593056047, at epoch: 103\n",
      "\n",
      "Number of units: 1490\n",
      "train loss: 0.004668033633436721, at epoch: 101\n",
      "\n",
      "Number of units: 1500\n",
      "train loss: 0.004666630737995234, at epoch: 101\n",
      "\n",
      "Number of units: 1510\n",
      "train loss: 0.004376894634320649, at epoch: 102\n",
      "\n",
      "Number of units: 1520\n",
      "train loss: 0.004898648890415984, at epoch: 103\n",
      "\n",
      "Number of units: 1530\n",
      "train loss: 0.0042674668104058355, at epoch: 101\n",
      "\n",
      "Number of units: 1540\n",
      "train loss: 0.004911318936348721, at epoch: 98\n",
      "\n",
      "Number of units: 1550\n",
      "train loss: 0.004882370533908898, at epoch: 99\n",
      "\n",
      "Number of units: 1560\n",
      "train loss: 0.004684453818809402, at epoch: 98\n",
      "\n",
      "Number of units: 1570\n",
      "train loss: 0.004408118198489461, at epoch: 100\n",
      "\n",
      "Number of units: 1580\n",
      "train loss: 0.004626196757980665, at epoch: 100\n",
      "\n",
      "Number of units: 1590\n",
      "train loss: 0.004668989224201425, at epoch: 98\n",
      "\n",
      "Number of units: 1600\n",
      "train loss: 0.004911510583170298, at epoch: 99\n",
      "\n",
      "Number of units: 1610\n",
      "train loss: 0.004821263285775927, at epoch: 95\n",
      "\n",
      "Number of units: 1620\n",
      "train loss: 0.004641312566470788, at epoch: 98\n",
      "\n",
      "Number of units: 1630\n",
      "train loss: 0.0045899063059601985, at epoch: 100\n",
      "\n",
      "Number of units: 1640\n",
      "train loss: 0.004905096029063998, at epoch: 96\n",
      "\n",
      "Number of units: 1650\n",
      "train loss: 0.004729761295336061, at epoch: 96\n",
      "\n",
      "Number of units: 1660\n",
      "train loss: 0.004738413082706643, at epoch: 97\n",
      "\n",
      "Number of units: 1670\n",
      "train loss: 0.004759126939093505, at epoch: 99\n",
      "\n",
      "Number of units: 1680\n",
      "train loss: 0.004773125854619593, at epoch: 94\n",
      "\n",
      "Number of units: 1690\n",
      "train loss: 0.004475011254901347, at epoch: 95\n",
      "\n",
      "Number of units: 1700\n",
      "train loss: 0.004946972978910367, at epoch: 95\n",
      "\n",
      "Number of units: 1710\n",
      "train loss: 0.004985814821744441, at epoch: 95\n",
      "\n",
      "Number of units: 1720\n",
      "train loss: 0.00482123413499437, at epoch: 95\n",
      "\n",
      "Number of units: 1730\n",
      "train loss: 0.004960648144952415, at epoch: 91\n",
      "\n",
      "Number of units: 1740\n",
      "train loss: 0.004827100374096744, at epoch: 94\n",
      "\n",
      "Number of units: 1750\n",
      "train loss: 0.0047153381663144955, at epoch: 96\n",
      "\n",
      "Number of units: 1760\n",
      "train loss: 0.004876077015326246, at epoch: 96\n",
      "\n",
      "Number of units: 1770\n",
      "train loss: 0.004854424645791369, at epoch: 95\n",
      "\n",
      "Number of units: 1780\n",
      "train loss: 0.004868594856852866, at epoch: 94\n",
      "\n",
      "Number of units: 1790\n",
      "train loss: 0.004452904266356654, at epoch: 95\n",
      "\n",
      "Number of units: 1800\n",
      "train loss: 0.004965854046699292, at epoch: 93\n",
      "\n",
      "Number of units: 1810\n",
      "train loss: 0.004071058817397386, at epoch: 96\n",
      "\n",
      "Number of units: 1820\n",
      "train loss: 0.004540201917062063, at epoch: 93\n",
      "\n",
      "Number of units: 1830\n",
      "train loss: 0.004682604451100758, at epoch: 93\n",
      "\n",
      "Number of units: 1840\n",
      "train loss: 0.004792765171742701, at epoch: 95\n",
      "\n",
      "Number of units: 1850\n",
      "train loss: 0.00477870903989924, at epoch: 94\n",
      "\n",
      "Number of units: 1860\n",
      "train loss: 0.004891982679158673, at epoch: 92\n",
      "\n",
      "Number of units: 1870\n",
      "train loss: 0.004929949663634261, at epoch: 92\n",
      "\n",
      "Number of units: 1880\n",
      "train loss: 0.004238561781382941, at epoch: 96\n",
      "\n",
      "Number of units: 1890\n",
      "train loss: 0.004776046455881726, at epoch: 92\n",
      "\n",
      "Number of units: 1900\n",
      "train loss: 0.004613661882618771, at epoch: 93\n",
      "\n",
      "Number of units: 1910\n",
      "train loss: 0.004927063917775172, at epoch: 93\n",
      "\n",
      "Number of units: 1920\n",
      "train loss: 0.004724161941222178, at epoch: 93\n",
      "\n",
      "Number of units: 1930\n",
      "train loss: 0.00498542060781432, at epoch: 90\n",
      "\n",
      "Number of units: 1940\n",
      "train loss: 0.004370858635120953, at epoch: 93\n",
      "\n",
      "Number of units: 1950\n",
      "train loss: 0.004355922587718624, at epoch: 93\n",
      "\n",
      "Number of units: 1960\n",
      "train loss: 0.00483618753949969, at epoch: 91\n",
      "\n",
      "Number of units: 1970\n",
      "train loss: 0.004833110170468444, at epoch: 91\n",
      "\n",
      "Number of units: 1980\n",
      "train loss: 0.004729108385863583, at epoch: 89\n",
      "\n",
      "Number of units: 1990\n",
      "train loss: 0.004714054301494457, at epoch: 90\n",
      "\n",
      "Number of units: 2000\n",
      "train loss: 0.004396226676263097, at epoch: 89\n",
      "\n",
      "Number of units: 2010\n",
      "train loss: 0.0048636507920653575, at epoch: 91\n",
      "\n",
      "Number of units: 2020\n",
      "train loss: 0.004924583455999994, at epoch: 88\n",
      "\n",
      "Number of units: 2030\n",
      "train loss: 0.0047107430533617385, at epoch: 90\n",
      "\n",
      "Number of units: 2040\n",
      "train loss: 0.0047176248018536175, at epoch: 90\n",
      "\n",
      "Number of units: 2050\n",
      "train loss: 0.004726468736686798, at epoch: 91\n",
      "\n",
      "Number of units: 2060\n",
      "train loss: 0.004889207449945161, at epoch: 89\n",
      "\n",
      "Number of units: 2070\n",
      "train loss: 0.004931399791326499, at epoch: 89\n",
      "\n",
      "Number of units: 2080\n",
      "train loss: 0.0049999504832913995, at epoch: 88\n",
      "\n",
      "Number of units: 2090\n",
      "train loss: 0.0046126202206966125, at epoch: 91\n",
      "\n",
      "Number of units: 2100\n",
      "train loss: 0.004661863468887191, at epoch: 90\n",
      "\n",
      "Number of units: 2110\n",
      "train loss: 0.004834753851215509, at epoch: 88\n",
      "\n",
      "Number of units: 2120\n",
      "train loss: 0.004760478672753834, at epoch: 88\n",
      "\n",
      "Number of units: 2130\n",
      "train loss: 0.004439946287528187, at epoch: 89\n",
      "\n",
      "Number of units: 2140\n",
      "train loss: 0.004601944279329615, at epoch: 90\n",
      "\n",
      "Number of units: 2150\n",
      "train loss: 0.004892639542052848, at epoch: 91\n",
      "\n",
      "Number of units: 2160\n",
      "train loss: 0.004812590140045358, at epoch: 90\n",
      "\n",
      "Number of units: 2170\n",
      "train loss: 0.004572832107103579, at epoch: 89\n",
      "\n",
      "Number of units: 2180\n",
      "train loss: 0.004851466578408577, at epoch: 86\n",
      "\n",
      "Number of units: 2190\n",
      "train loss: 0.004518814754164993, at epoch: 89\n",
      "\n",
      "Number of units: 2200\n",
      "train loss: 0.004899757363481285, at epoch: 88\n",
      "\n",
      "Number of units: 2210\n",
      "train loss: 0.0049621398642649694, at epoch: 87\n",
      "\n",
      "Number of units: 2220\n",
      "train loss: 0.004466252816684459, at epoch: 90\n",
      "\n",
      "Number of units: 2230\n",
      "train loss: 0.004336437916786906, at epoch: 87\n",
      "\n",
      "Number of units: 2240\n",
      "train loss: 0.00459862065345618, at epoch: 87\n",
      "\n",
      "Number of units: 2250\n",
      "train loss: 0.004418889245905717, at epoch: 88\n",
      "\n",
      "Number of units: 2260\n",
      "train loss: 0.004466221178027752, at epoch: 88\n",
      "\n",
      "Number of units: 2270\n",
      "train loss: 0.004731576581098267, at epoch: 85\n",
      "\n",
      "Number of units: 2280\n",
      "train loss: 0.0049150774029806145, at epoch: 87\n",
      "\n",
      "Number of units: 2290\n",
      "train loss: 0.0049753987262499775, at epoch: 86\n",
      "\n",
      "Number of units: 2300\n",
      "train loss: 0.00485096904682024, at epoch: 86\n",
      "\n",
      "Number of units: 2310\n",
      "train loss: 0.0047154158614557675, at epoch: 87\n",
      "\n",
      "Number of units: 2320\n",
      "train loss: 0.004773341076534905, at epoch: 86\n",
      "\n",
      "Number of units: 2330\n",
      "train loss: 0.004941384793572752, at epoch: 83\n",
      "\n",
      "Number of units: 2340\n",
      "train loss: 0.004957273689392423, at epoch: 83\n",
      "\n",
      "Number of units: 2350\n",
      "train loss: 0.004486250519628925, at epoch: 86\n",
      "\n",
      "Number of units: 2360\n",
      "train loss: 0.0047065068627537695, at epoch: 86\n",
      "\n",
      "Number of units: 2370\n",
      "train loss: 0.004624353595516482, at epoch: 86\n",
      "\n",
      "Number of units: 2380\n",
      "train loss: 0.004966101052845602, at epoch: 87\n",
      "\n",
      "Number of units: 2390\n",
      "train loss: 0.004640523076155887, at epoch: 85\n",
      "\n",
      "Number of units: 2400\n",
      "train loss: 0.004829368178464506, at epoch: 86\n",
      "\n",
      "Number of units: 2410\n",
      "train loss: 0.0048444017312819195, at epoch: 85\n",
      "\n",
      "Number of units: 2420\n",
      "train loss: 0.004675626112296811, at epoch: 85\n",
      "\n",
      "Number of units: 2430\n",
      "train loss: 0.004581217298443789, at epoch: 84\n",
      "\n",
      "Number of units: 2440\n",
      "train loss: 0.004973361330298758, at epoch: 84\n",
      "\n",
      "Number of units: 2450\n",
      "train loss: 0.004940654227483492, at epoch: 82\n",
      "\n",
      "Number of units: 2460\n",
      "train loss: 0.004736931624133262, at epoch: 87\n",
      "\n",
      "Number of units: 2470\n",
      "train loss: 0.004937762905212253, at epoch: 86\n",
      "\n",
      "Number of units: 2480\n",
      "train loss: 0.004894686640293458, at epoch: 83\n",
      "\n",
      "Number of units: 2490\n",
      "train loss: 0.004968443841032694, at epoch: 83\n",
      "\n",
      "Number of units: 2500\n",
      "train loss: 0.00471030114313237, at epoch: 85\n",
      "\n",
      "Number of units: 2510\n",
      "train loss: 0.004984196657927669, at epoch: 84\n",
      "\n",
      "Number of units: 2520\n",
      "train loss: 0.00477872605455218, at epoch: 83\n",
      "\n",
      "Number of units: 2530\n",
      "train loss: 0.004826331555970569, at epoch: 85\n",
      "\n",
      "Number of units: 2540\n",
      "train loss: 0.00497558030581871, at epoch: 82\n",
      "\n",
      "Number of units: 2550\n",
      "train loss: 0.004600728669639693, at epoch: 82\n",
      "\n",
      "Number of units: 2560\n",
      "train loss: 0.00481124263642073, at epoch: 83\n",
      "\n",
      "Number of units: 2570\n",
      "train loss: 0.00460982881592372, at epoch: 83\n",
      "\n",
      "Number of units: 2580\n",
      "train loss: 0.004757000280107491, at epoch: 83\n",
      "\n",
      "Number of units: 2590\n",
      "train loss: 0.004031630423472166, at epoch: 84\n",
      "\n",
      "Number of units: 2600\n",
      "train loss: 0.00452715234894697, at epoch: 85\n",
      "\n",
      "Number of units: 2610\n",
      "train loss: 0.004446493626843449, at epoch: 83\n",
      "\n",
      "Number of units: 2620\n",
      "train loss: 0.00466857284500378, at epoch: 82\n",
      "\n",
      "Number of units: 2630\n",
      "train loss: 0.004913322323611169, at epoch: 83\n",
      "\n",
      "Number of units: 2640\n",
      "train loss: 0.004791423370802477, at epoch: 81\n",
      "\n",
      "Number of units: 2650\n",
      "train loss: 0.004964530613392526, at epoch: 83\n",
      "\n",
      "Number of units: 2660\n",
      "train loss: 0.004534671769734473, at epoch: 81\n",
      "\n",
      "Number of units: 2670\n",
      "train loss: 0.004623949488044446, at epoch: 82\n",
      "\n",
      "Number of units: 2680\n",
      "train loss: 0.004617548857559086, at epoch: 83\n",
      "\n",
      "Number of units: 2690\n",
      "train loss: 0.004310759337246281, at epoch: 82\n",
      "\n",
      "Number of units: 2700\n",
      "train loss: 0.004455273058404714, at epoch: 82\n",
      "\n",
      "Number of units: 2710\n",
      "train loss: 0.004648677354340975, at epoch: 81\n",
      "\n",
      "Number of units: 2720\n",
      "train loss: 0.004908118570652676, at epoch: 79\n",
      "\n",
      "Number of units: 2730\n",
      "train loss: 0.004877343484394032, at epoch: 79\n",
      "\n",
      "Number of units: 2740\n",
      "train loss: 0.004718094385544873, at epoch: 80\n",
      "\n",
      "Number of units: 2750\n",
      "train loss: 0.004987088851206067, at epoch: 79\n",
      "\n",
      "Number of units: 2760\n",
      "train loss: 0.004840876156123954, at epoch: 80\n",
      "\n",
      "Number of units: 2770\n",
      "train loss: 0.004926278602772527, at epoch: 81\n",
      "\n",
      "Number of units: 2780\n",
      "train loss: 0.004702910919402825, at epoch: 79\n",
      "\n",
      "Number of units: 2790\n",
      "train loss: 0.004832739867007092, at epoch: 80\n",
      "\n",
      "Number of units: 2800\n",
      "train loss: 0.004876146726716684, at epoch: 81\n",
      "\n",
      "Number of units: 2810\n",
      "train loss: 0.004862294072200939, at epoch: 80\n",
      "\n",
      "Number of units: 2820\n",
      "train loss: 0.004909859675505572, at epoch: 81\n",
      "\n",
      "Number of units: 2830\n",
      "train loss: 0.004548002363978867, at epoch: 81\n",
      "\n",
      "Number of units: 2840\n",
      "train loss: 0.004914796480746873, at epoch: 81\n",
      "\n",
      "Number of units: 2850\n",
      "train loss: 0.004460851019535994, at epoch: 81\n",
      "\n",
      "Number of units: 2860\n",
      "train loss: 0.00458578223993527, at epoch: 80\n",
      "\n",
      "Number of units: 2870\n",
      "train loss: 0.004663733338063025, at epoch: 80\n",
      "\n",
      "Number of units: 2880\n",
      "train loss: 0.004972059015504726, at epoch: 80\n",
      "\n",
      "Number of units: 2890\n",
      "train loss: 0.0049711875788096905, at epoch: 82\n",
      "\n",
      "Number of units: 2900\n",
      "train loss: 0.004241194599376854, at epoch: 83\n",
      "\n",
      "Number of units: 2910\n",
      "train loss: 0.004665486850240655, at epoch: 79\n",
      "\n",
      "Number of units: 2920\n",
      "train loss: 0.004641065439847694, at epoch: 81\n",
      "\n",
      "Number of units: 2930\n",
      "train loss: 0.004926345110817465, at epoch: 78\n",
      "\n",
      "Number of units: 2940\n",
      "train loss: 0.004794771257980699, at epoch: 77\n",
      "\n",
      "Number of units: 2950\n",
      "train loss: 0.004971867880243508, at epoch: 77\n",
      "\n",
      "Number of units: 2960\n",
      "train loss: 0.004515562612025974, at epoch: 79\n",
      "\n",
      "Number of units: 2970\n",
      "train loss: 0.004699849403023961, at epoch: 79\n",
      "\n",
      "Number of units: 2980\n",
      "train loss: 0.004464317922294185, at epoch: 78\n",
      "\n",
      "Number of units: 2990\n",
      "train loss: 0.004805032557208051, at epoch: 78\n",
      "\n",
      "Number of units: 3000\n",
      "train loss: 0.004920514579405903, at epoch: 79\n",
      "\n",
      "Number of units: 3010\n",
      "train loss: 0.004848995643642695, at epoch: 79\n",
      "\n",
      "Number of units: 3020\n",
      "train loss: 0.004268286298339205, at epoch: 80\n",
      "\n",
      "Number of units: 3030\n",
      "train loss: 0.004895312991717162, at epoch: 77\n",
      "\n",
      "Number of units: 3040\n",
      "train loss: 0.004900958143642811, at epoch: 78\n",
      "\n",
      "Number of units: 3050\n",
      "train loss: 0.004650654776798433, at epoch: 78\n",
      "\n",
      "Number of units: 3060\n",
      "train loss: 0.004944295871973736, at epoch: 76\n",
      "\n",
      "Number of units: 3070\n",
      "train loss: 0.004426781750199211, at epoch: 78\n",
      "\n",
      "Number of units: 3080\n",
      "train loss: 0.0047762009982542965, at epoch: 78\n",
      "\n",
      "Number of units: 3090\n",
      "train loss: 0.004819860782041303, at epoch: 78\n",
      "\n",
      "Number of units: 3100\n",
      "train loss: 0.004345537166434639, at epoch: 79\n",
      "\n",
      "Number of units: 3110\n",
      "train loss: 0.004464296908702181, at epoch: 78\n",
      "\n",
      "Number of units: 3120\n",
      "train loss: 0.004912370535313926, at epoch: 78\n",
      "\n",
      "Number of units: 3130\n",
      "train loss: 0.004952697971112911, at epoch: 77\n",
      "\n",
      "Number of units: 3140\n",
      "train loss: 0.004308916355496422, at epoch: 79\n",
      "\n",
      "Number of units: 3150\n",
      "train loss: 0.004761805653438387, at epoch: 76\n",
      "\n",
      "Number of units: 3160\n",
      "train loss: 0.00458721800325776, at epoch: 78\n",
      "\n",
      "Number of units: 3170\n",
      "train loss: 0.004140619564972212, at epoch: 78\n",
      "\n",
      "Number of units: 3180\n",
      "train loss: 0.004817733669943039, at epoch: 78\n",
      "\n",
      "Number of units: 3190\n",
      "train loss: 0.004588131346555997, at epoch: 77\n",
      "\n",
      "Number of units: 3200\n",
      "train loss: 0.004950025982561925, at epoch: 77\n",
      "\n",
      "Number of units: 3210\n",
      "train loss: 0.0049293963072705085, at epoch: 76\n",
      "\n",
      "Number of units: 3220\n",
      "train loss: 0.004191212039438596, at epoch: 77\n",
      "\n",
      "Number of units: 3230\n",
      "train loss: 0.004603660790164099, at epoch: 76\n",
      "\n",
      "Number of units: 3240\n",
      "train loss: 0.004916313763845323, at epoch: 76\n",
      "\n",
      "Number of units: 3250\n",
      "train loss: 0.004887965275684394, at epoch: 77\n",
      "\n",
      "Number of units: 3260\n",
      "train loss: 0.004907690640000056, at epoch: 78\n",
      "\n",
      "Number of units: 3270\n",
      "train loss: 0.00482641446479704, at epoch: 78\n",
      "\n",
      "Number of units: 3280\n",
      "train loss: 0.004958659021366998, at epoch: 77\n",
      "\n",
      "Number of units: 3290\n",
      "train loss: 0.0047298885000518, at epoch: 76\n",
      "\n",
      "Number of units: 3300\n",
      "train loss: 0.004735256447616081, at epoch: 78\n",
      "\n",
      "Number of units: 3310\n",
      "train loss: 0.004603373047125956, at epoch: 76\n",
      "\n",
      "Number of units: 3320\n",
      "train loss: 0.004874173860810629, at epoch: 75\n",
      "\n",
      "Number of units: 3330\n",
      "train loss: 0.004252750693814278, at epoch: 77\n",
      "\n",
      "Number of units: 3340\n",
      "train loss: 0.004724339746055648, at epoch: 75\n",
      "\n",
      "Number of units: 3350\n",
      "train loss: 0.004727144512858672, at epoch: 76\n",
      "\n",
      "Number of units: 3360\n",
      "train loss: 0.004601146186748224, at epoch: 74\n",
      "\n",
      "Number of units: 3370\n",
      "train loss: 0.0047071273579746276, at epoch: 74\n",
      "\n",
      "Number of units: 3380\n",
      "train loss: 0.004647400298602804, at epoch: 78\n",
      "\n",
      "Number of units: 3390\n",
      "train loss: 0.004598567419830601, at epoch: 76\n",
      "\n",
      "Number of units: 3400\n",
      "train loss: 0.004992046336819839, at epoch: 74\n",
      "\n",
      "Number of units: 3410\n",
      "train loss: 0.004619879313541162, at epoch: 75\n",
      "\n",
      "Number of units: 3420\n",
      "train loss: 0.004714115749208076, at epoch: 76\n",
      "\n",
      "Number of units: 3430\n",
      "train loss: 0.004915157436271613, at epoch: 75\n",
      "\n",
      "Number of units: 3440\n",
      "train loss: 0.004707373443277447, at epoch: 77\n",
      "\n",
      "Number of units: 3450\n",
      "train loss: 0.004656320042784046, at epoch: 76\n",
      "\n",
      "Number of units: 3460\n",
      "train loss: 0.00479037150286274, at epoch: 74\n",
      "\n",
      "Number of units: 3470\n",
      "train loss: 0.0048163238833558355, at epoch: 73\n",
      "\n",
      "Number of units: 3480\n",
      "train loss: 0.004664131237933589, at epoch: 74\n",
      "\n",
      "Number of units: 3490\n",
      "train loss: 0.004944080877232864, at epoch: 73\n",
      "\n",
      "Number of units: 3500\n",
      "train loss: 0.004592339176085715, at epoch: 75\n",
      "\n",
      "Number of units: 3510\n",
      "train loss: 0.004782513553345779, at epoch: 73\n",
      "\n",
      "Number of units: 3520\n",
      "train loss: 0.004714882543486851, at epoch: 74\n",
      "\n",
      "Number of units: 3530\n",
      "train loss: 0.004553116395994721, at epoch: 75\n",
      "\n",
      "Number of units: 3540\n",
      "train loss: 0.004832576697995705, at epoch: 74\n",
      "\n",
      "Number of units: 3550\n",
      "train loss: 0.004692611204560535, at epoch: 74\n",
      "\n",
      "Number of units: 3560\n",
      "train loss: 0.004844045536825092, at epoch: 73\n",
      "\n",
      "Number of units: 3570\n",
      "train loss: 0.004933623731819808, at epoch: 74\n",
      "\n",
      "Number of units: 3580\n",
      "train loss: 0.004531132916628167, at epoch: 74\n",
      "\n",
      "Number of units: 3590\n",
      "train loss: 0.0047829661762096975, at epoch: 74\n",
      "\n",
      "Number of units: 3600\n",
      "train loss: 0.004972052724947389, at epoch: 73\n",
      "\n",
      "Number of units: 3610\n",
      "train loss: 0.00491387603401563, at epoch: 72\n",
      "\n",
      "Number of units: 3620\n",
      "train loss: 0.00488301058782838, at epoch: 72\n",
      "\n",
      "Number of units: 3630\n",
      "train loss: 0.004848818191582609, at epoch: 72\n",
      "\n",
      "Number of units: 3640\n",
      "train loss: 0.004793463738571404, at epoch: 72\n",
      "\n",
      "Number of units: 3650\n",
      "train loss: 0.004973565658971211, at epoch: 73\n",
      "\n",
      "Number of units: 3660\n",
      "train loss: 0.00498690084247869, at epoch: 73\n",
      "\n",
      "Number of units: 3670\n",
      "train loss: 0.0049626278668444, at epoch: 72\n",
      "\n",
      "Number of units: 3680\n",
      "train loss: 0.004832691381263316, at epoch: 72\n",
      "\n",
      "Number of units: 3690\n",
      "train loss: 0.004653321514529693, at epoch: 75\n",
      "\n",
      "Number of units: 3700\n",
      "train loss: 0.0045109617254189514, at epoch: 75\n",
      "\n",
      "Number of units: 3710\n",
      "train loss: 0.004433301987622826, at epoch: 73\n",
      "\n",
      "Number of units: 3720\n",
      "train loss: 0.004916895299193698, at epoch: 73\n",
      "\n",
      "Number of units: 3730\n",
      "train loss: 0.004856876023984569, at epoch: 71\n",
      "\n",
      "Number of units: 3740\n",
      "train loss: 0.0049531943265407104, at epoch: 73\n",
      "\n",
      "Number of units: 3750\n",
      "train loss: 0.004780868732954104, at epoch: 72\n",
      "\n",
      "Number of units: 3760\n",
      "train loss: 0.004236564998300878, at epoch: 75\n",
      "\n",
      "Number of units: 3770\n",
      "train loss: 0.004982163529093669, at epoch: 72\n",
      "\n",
      "Number of units: 3780\n",
      "train loss: 0.004965858535172174, at epoch: 72\n",
      "\n",
      "Number of units: 3790\n",
      "train loss: 0.004866039142444549, at epoch: 73\n",
      "\n",
      "Number of units: 3800\n",
      "train loss: 0.004482487158390995, at epoch: 74\n",
      "\n",
      "Number of units: 3810\n",
      "train loss: 0.004949363899069681, at epoch: 71\n",
      "\n",
      "Number of units: 3820\n",
      "train loss: 0.004825806647606896, at epoch: 72\n",
      "\n",
      "Number of units: 3830\n",
      "train loss: 0.004961499130016307, at epoch: 72\n",
      "\n",
      "Number of units: 3840\n",
      "train loss: 0.004674048054167486, at epoch: 71\n",
      "\n",
      "Number of units: 3850\n",
      "train loss: 0.004876178830043046, at epoch: 73\n",
      "\n",
      "Number of units: 3860\n",
      "train loss: 0.0046722922980376325, at epoch: 72\n",
      "\n",
      "Number of units: 3870\n",
      "train loss: 0.004768007685847806, at epoch: 72\n",
      "\n",
      "Number of units: 3880\n",
      "train loss: 0.004670870222392409, at epoch: 71\n",
      "\n",
      "Number of units: 3890\n",
      "train loss: 0.004226427081719635, at epoch: 80\n",
      "\n",
      "Number of units: 3900\n",
      "train loss: 0.004830397519297094, at epoch: 71\n",
      "\n",
      "Number of units: 3910\n",
      "train loss: 0.0045526453588502136, at epoch: 72\n",
      "\n",
      "Number of units: 3920\n",
      "train loss: 0.004977696714759645, at epoch: 72\n",
      "\n",
      "Number of units: 3930\n",
      "train loss: 0.004203243973072972, at epoch: 74\n",
      "\n",
      "Number of units: 3940\n",
      "train loss: 0.0049827309236070505, at epoch: 70\n",
      "\n",
      "Number of units: 3950\n",
      "train loss: 0.004342849813271528, at epoch: 72\n",
      "\n",
      "Number of units: 3960\n",
      "train loss: 0.004981777913491783, at epoch: 71\n",
      "\n",
      "Number of units: 3970\n",
      "train loss: 0.004788197507142513, at epoch: 72\n",
      "\n",
      "Number of units: 3980\n",
      "train loss: 0.004700372700209527, at epoch: 73\n",
      "\n",
      "Number of units: 3990\n",
      "train loss: 0.0048774359385629395, at epoch: 72\n",
      "\n",
      "Number of units: 4000\n",
      "train loss: 0.004836456119387833, at epoch: 71\n",
      "\n",
      "Number of units: 4010\n",
      "train loss: 0.0049060487421238004, at epoch: 69\n",
      "\n",
      "Number of units: 4020\n",
      "train loss: 0.004933104935935262, at epoch: 70\n",
      "\n",
      "Number of units: 4030\n",
      "train loss: 0.004944998240795258, at epoch: 69\n",
      "\n",
      "Number of units: 4040\n",
      "train loss: 0.004934336201057476, at epoch: 70\n",
      "\n",
      "Number of units: 4050\n",
      "train loss: 0.004711112781854467, at epoch: 72\n",
      "\n",
      "Number of units: 4060\n",
      "train loss: 0.0043609553733477925, at epoch: 72\n",
      "\n",
      "Number of units: 4070\n",
      "train loss: 0.004945479683838698, at epoch: 69\n",
      "\n",
      "Number of units: 4080\n",
      "train loss: 0.004848707970847954, at epoch: 70\n",
      "\n",
      "Number of units: 4090\n",
      "train loss: 0.0042235548368091715, at epoch: 72\n",
      "\n",
      "Number of units: 4100\n",
      "train loss: 0.004572740206151593, at epoch: 71\n",
      "\n",
      "Number of units: 4110\n",
      "train loss: 0.004939753737222646, at epoch: 71\n",
      "\n",
      "Number of units: 4120\n",
      "train loss: 0.004487485927094212, at epoch: 71\n",
      "\n",
      "Number of units: 4130\n",
      "train loss: 0.0045125620974619095, at epoch: 70\n",
      "\n",
      "Number of units: 4140\n",
      "train loss: 0.0046942836338109825, at epoch: 71\n",
      "\n",
      "Number of units: 4150\n",
      "train loss: 0.004411890528414801, at epoch: 69\n",
      "\n",
      "Number of units: 4160\n",
      "train loss: 0.0049015524387104395, at epoch: 70\n",
      "\n",
      "Number of units: 4170\n",
      "train loss: 0.004797855360994276, at epoch: 70\n",
      "\n",
      "Number of units: 4180\n",
      "train loss: 0.0045369448770317435, at epoch: 72\n",
      "\n",
      "Number of units: 4190\n",
      "train loss: 0.0048272378525842895, at epoch: 70\n",
      "\n",
      "Number of units: 4200\n",
      "train loss: 0.004856272253330189, at epoch: 70\n",
      "\n",
      "Number of units: 4210\n",
      "train loss: 0.004799176308735582, at epoch: 69\n",
      "\n",
      "Number of units: 4220\n",
      "train loss: 0.004959490864972622, at epoch: 71\n",
      "\n",
      "Number of units: 4230\n",
      "train loss: 0.0046700701938084425, at epoch: 71\n",
      "\n",
      "Number of units: 4240\n",
      "train loss: 0.004688621531554418, at epoch: 69\n",
      "\n",
      "Number of units: 4250\n",
      "train loss: 0.0048846470537409915, at epoch: 70\n",
      "\n",
      "Number of units: 4260\n",
      "train loss: 0.004623235277242657, at epoch: 69\n",
      "\n",
      "Number of units: 4270\n",
      "train loss: 0.004716287725120196, at epoch: 71\n",
      "\n",
      "Number of units: 4280\n",
      "train loss: 0.004564845935457243, at epoch: 70\n",
      "\n",
      "Number of units: 4290\n",
      "train loss: 0.0046719565266653265, at epoch: 70\n",
      "\n",
      "Number of units: 4300\n",
      "train loss: 0.0047314648760732325, at epoch: 69\n",
      "\n",
      "Number of units: 4310\n",
      "train loss: 0.004809665239113201, at epoch: 70\n",
      "\n",
      "Number of units: 4320\n",
      "train loss: 0.004654578291929283, at epoch: 72\n",
      "\n",
      "Number of units: 4330\n",
      "train loss: 0.004307129011313293, at epoch: 71\n",
      "\n",
      "Number of units: 4340\n",
      "train loss: 0.004412181089331284, at epoch: 71\n",
      "\n",
      "Number of units: 4350\n",
      "train loss: 0.0046987456691647365, at epoch: 69\n",
      "\n",
      "Number of units: 4360\n",
      "train loss: 0.004698922997924911, at epoch: 68\n",
      "\n",
      "Number of units: 4370\n",
      "train loss: 0.004258598167958212, at epoch: 70\n",
      "\n",
      "Number of units: 4380\n",
      "train loss: 0.004399582363321883, at epoch: 70\n",
      "\n",
      "Number of units: 4390\n",
      "train loss: 0.004620922441002904, at epoch: 69\n",
      "\n",
      "Number of units: 4400\n",
      "train loss: 0.004864222213709013, at epoch: 69\n",
      "\n",
      "Number of units: 4410\n",
      "train loss: 0.004619763877424816, at epoch: 68\n",
      "\n",
      "Number of units: 4420\n",
      "train loss: 0.0045428348055565945, at epoch: 71\n",
      "\n",
      "Number of units: 4430\n",
      "train loss: 0.00441437052874619, at epoch: 68\n",
      "\n",
      "Number of units: 4440\n",
      "train loss: 0.0047352118783103945, at epoch: 69\n",
      "\n",
      "Number of units: 4450\n",
      "train loss: 0.004946688372140216, at epoch: 67\n",
      "\n",
      "Number of units: 4460\n",
      "train loss: 0.004592815267965306, at epoch: 69\n",
      "\n",
      "Number of units: 4470\n",
      "train loss: 0.004686951746736554, at epoch: 69\n",
      "\n",
      "Number of units: 4480\n",
      "train loss: 0.004737410489065894, at epoch: 67\n",
      "\n",
      "Number of units: 4490\n",
      "train loss: 0.004506834465809675, at epoch: 67\n",
      "\n",
      "Number of units: 4500\n",
      "train loss: 0.004576453183792069, at epoch: 69\n",
      "\n",
      "Number of units: 4510\n",
      "train loss: 0.004618955416353856, at epoch: 69\n",
      "\n",
      "Number of units: 4520\n",
      "train loss: 0.004130311587616688, at epoch: 69\n",
      "\n",
      "Number of units: 4530\n",
      "train loss: 0.004635882447428514, at epoch: 72\n",
      "\n",
      "Number of units: 4540\n",
      "train loss: 0.004706008200497252, at epoch: 69\n",
      "\n",
      "Number of units: 4550\n",
      "train loss: 0.004834021395943182, at epoch: 68\n",
      "\n",
      "Number of units: 4560\n",
      "train loss: 0.004996897657190402, at epoch: 69\n",
      "\n",
      "Number of units: 4570\n",
      "train loss: 0.004969893937690131, at epoch: 68\n",
      "\n",
      "Number of units: 4580\n",
      "train loss: 0.004814098359312879, at epoch: 77\n",
      "\n",
      "Number of units: 4590\n",
      "train loss: 0.004958464875972766, at epoch: 68\n",
      "\n",
      "Number of units: 4600\n",
      "train loss: 0.004731768364914615, at epoch: 68\n",
      "\n",
      "Number of units: 4610\n",
      "train loss: 0.004539003928458101, at epoch: 69\n",
      "\n",
      "Number of units: 4620\n",
      "train loss: 0.0048786810320359565, at epoch: 68\n",
      "\n",
      "Number of units: 4630\n",
      "train loss: 0.004485568774158537, at epoch: 68\n",
      "\n",
      "Number of units: 4640\n",
      "train loss: 0.004960450987076683, at epoch: 66\n",
      "\n",
      "Number of units: 4650\n",
      "train loss: 0.0046689477073630315, at epoch: 68\n",
      "\n",
      "Number of units: 4660\n",
      "train loss: 0.0046916492747777734, at epoch: 68\n",
      "\n",
      "Number of units: 4670\n",
      "train loss: 0.004800280696542245, at epoch: 68\n",
      "\n",
      "Number of units: 4680\n",
      "train loss: 0.004822124379720663, at epoch: 68\n",
      "\n",
      "Number of units: 4690\n",
      "train loss: 0.004996987478122605, at epoch: 66\n",
      "\n",
      "Number of units: 4700\n",
      "train loss: 0.00443815075680618, at epoch: 68\n",
      "\n",
      "Number of units: 4710\n",
      "train loss: 0.004613212531799888, at epoch: 70\n",
      "\n",
      "Number of units: 4720\n",
      "train loss: 0.004212251473296647, at epoch: 67\n",
      "\n",
      "Number of units: 4730\n",
      "train loss: 0.004832402802388742, at epoch: 67\n",
      "\n",
      "Number of units: 4740\n",
      "train loss: 0.0049586389542923826, at epoch: 68\n",
      "\n",
      "Number of units: 4750\n",
      "train loss: 0.004743563913251592, at epoch: 68\n",
      "\n",
      "Number of units: 4760\n",
      "train loss: 0.00466486798091978, at epoch: 67\n",
      "\n",
      "Number of units: 4770\n",
      "train loss: 0.004937433368172606, at epoch: 68\n",
      "\n",
      "Number of units: 4780\n",
      "train loss: 0.0048790585692097465, at epoch: 66\n",
      "\n",
      "Number of units: 4790\n",
      "train loss: 0.004925530015776189, at epoch: 67\n",
      "\n",
      "Number of units: 4800\n",
      "train loss: 0.004513606920852453, at epoch: 68\n",
      "\n",
      "Number of units: 4810\n",
      "train loss: 0.004992619911013208, at epoch: 73\n",
      "\n",
      "Number of units: 4820\n",
      "train loss: 0.004782530833152805, at epoch: 67\n",
      "\n",
      "Number of units: 4830\n",
      "train loss: 0.004782512657386064, at epoch: 67\n",
      "\n",
      "Number of units: 4840\n",
      "train loss: 0.004594468385517417, at epoch: 67\n",
      "\n",
      "Number of units: 4850\n",
      "train loss: 0.004707753554735064, at epoch: 67\n",
      "\n",
      "Number of units: 4860\n",
      "train loss: 0.0047447612133362325, at epoch: 66\n",
      "\n",
      "Number of units: 4870\n",
      "train loss: 0.0048736030958781386, at epoch: 67\n",
      "\n",
      "Number of units: 4880\n",
      "train loss: 0.004878980321944937, at epoch: 68\n",
      "\n",
      "Number of units: 4890\n",
      "train loss: 0.004851732458101594, at epoch: 67\n",
      "\n",
      "Number of units: 4900\n",
      "train loss: 0.00481937655244451, at epoch: 68\n",
      "\n",
      "Number of units: 4910\n",
      "train loss: 0.004739331922737619, at epoch: 69\n",
      "\n",
      "Number of units: 4920\n",
      "train loss: 0.00465731273141273, at epoch: 67\n",
      "\n",
      "Number of units: 4930\n",
      "train loss: 0.004817406387587937, at epoch: 66\n",
      "\n",
      "Number of units: 4940\n",
      "train loss: 0.0048427631470673305, at epoch: 67\n",
      "\n",
      "Number of units: 4950\n",
      "train loss: 0.00490989024148007, at epoch: 67\n",
      "\n",
      "Number of units: 4960\n",
      "train loss: 0.004325246265075862, at epoch: 68\n",
      "\n",
      "Number of units: 4970\n",
      "train loss: 0.004929721274378949, at epoch: 65\n",
      "\n",
      "Number of units: 4980\n",
      "train loss: 0.004539941239137306, at epoch: 66\n",
      "\n",
      "Number of units: 4990\n",
      "train loss: 0.00487566530628726, at epoch: 66\n",
      "\n",
      "Number of units: 5000\n",
      "train loss: 0.004568458971507567, at epoch: 66\n",
      "\n",
      "Number of units: 5010\n",
      "train loss: 0.004470467425022377, at epoch: 67\n",
      "\n",
      "Number of units: 5020\n",
      "train loss: 0.004702819428003408, at epoch: 66\n",
      "\n",
      "Number of units: 5030\n",
      "train loss: 0.004819693636306397, at epoch: 66\n",
      "\n",
      "Number of units: 5040\n",
      "train loss: 0.004600080864267966, at epoch: 68\n",
      "\n",
      "Number of units: 5050\n",
      "train loss: 0.004683060216044623, at epoch: 66\n",
      "\n",
      "Number of units: 5060\n",
      "train loss: 0.00464490604445416, at epoch: 66\n",
      "\n",
      "Number of units: 5070\n",
      "train loss: 0.004803331806013489, at epoch: 67\n",
      "\n",
      "Number of units: 5080\n",
      "train loss: 0.00497314205702537, at epoch: 64\n",
      "\n",
      "Number of units: 5090\n",
      "train loss: 0.004860080686252104, at epoch: 66\n",
      "\n",
      "Number of units: 5100\n",
      "train loss: 0.00435048010234425, at epoch: 67\n",
      "\n",
      "Number of units: 5110\n",
      "train loss: 0.004815039188111711, at epoch: 66\n",
      "\n",
      "Number of units: 5120\n",
      "train loss: 0.0038304109806921362, at epoch: 68\n",
      "\n",
      "Number of units: 5130\n",
      "train loss: 0.00455398175574885, at epoch: 67\n",
      "\n",
      "Number of units: 5140\n",
      "train loss: 0.004532240985828935, at epoch: 65\n",
      "\n",
      "Number of units: 5150\n",
      "train loss: 0.004336648462279982, at epoch: 68\n",
      "\n",
      "Number of units: 5160\n",
      "train loss: 0.0049900328581060195, at epoch: 65\n",
      "\n",
      "Number of units: 5170\n",
      "train loss: 0.004301073948088856, at epoch: 67\n",
      "\n",
      "Number of units: 5180\n",
      "train loss: 0.004505625787279541, at epoch: 65\n",
      "\n",
      "Number of units: 5190\n",
      "train loss: 0.004551895991410788, at epoch: 66\n",
      "\n",
      "Number of units: 5200\n",
      "train loss: 0.0049478193766680076, at epoch: 64\n",
      "\n",
      "Number of units: 5210\n",
      "train loss: 0.004870432127874551, at epoch: 66\n",
      "\n",
      "Number of units: 5220\n",
      "train loss: 0.0048234595630583495, at epoch: 65\n",
      "\n",
      "Number of units: 5230\n",
      "train loss: 0.004677759473562446, at epoch: 65\n",
      "\n",
      "Number of units: 5240\n",
      "train loss: 0.004679337756107316, at epoch: 64\n",
      "\n",
      "Number of units: 5250\n",
      "train loss: 0.004621971183998994, at epoch: 65\n",
      "\n",
      "Number of units: 5260\n",
      "train loss: 0.004698838867822701, at epoch: 66\n",
      "\n",
      "Number of units: 5270\n",
      "train loss: 0.004563687472569882, at epoch: 67\n",
      "\n",
      "Number of units: 5280\n",
      "train loss: 0.004829475130452749, at epoch: 65\n",
      "\n",
      "Number of units: 5290\n",
      "train loss: 0.00469895291177977, at epoch: 64\n",
      "\n",
      "Number of units: 5300\n",
      "train loss: 0.00499021560910819, at epoch: 63\n",
      "\n",
      "Number of units: 5310\n",
      "train loss: 0.004566537809770921, at epoch: 65\n",
      "\n",
      "Number of units: 5320\n",
      "train loss: 0.004963307004771309, at epoch: 65\n",
      "\n",
      "Number of units: 5330\n",
      "train loss: 0.004644103626170022, at epoch: 65\n",
      "\n",
      "Number of units: 5340\n",
      "train loss: 0.004738231382792719, at epoch: 65\n",
      "\n",
      "Number of units: 5350\n",
      "train loss: 0.004589890274245932, at epoch: 67\n",
      "\n",
      "Number of units: 5360\n",
      "train loss: 0.004905687483023939, at epoch: 64\n",
      "\n",
      "Number of units: 5370\n",
      "train loss: 0.0049954776707321, at epoch: 63\n",
      "\n",
      "Number of units: 5380\n",
      "train loss: 0.004949401346465265, at epoch: 65\n",
      "\n",
      "Number of units: 5390\n",
      "train loss: 0.0047214445112985, at epoch: 63\n",
      "\n",
      "Number of units: 5400\n",
      "train loss: 0.00470482068039928, at epoch: 64\n",
      "\n",
      "Number of units: 5410\n",
      "train loss: 0.0049780391537433384, at epoch: 64\n",
      "\n",
      "Number of units: 5420\n",
      "train loss: 0.004838258386425878, at epoch: 64\n",
      "\n",
      "Number of units: 5430\n",
      "train loss: 0.004559290141153269, at epoch: 65\n",
      "\n",
      "Number of units: 5440\n",
      "train loss: 0.004935000052099099, at epoch: 63\n",
      "\n",
      "Number of units: 5450\n",
      "train loss: 0.004729243804845851, at epoch: 65\n",
      "\n",
      "Number of units: 5460\n",
      "train loss: 0.004696505510971179, at epoch: 65\n",
      "\n",
      "Number of units: 5470\n",
      "train loss: 0.004646180645924574, at epoch: 64\n",
      "\n",
      "Number of units: 5480\n",
      "train loss: 0.004956122011017214, at epoch: 64\n",
      "\n",
      "Number of units: 5490\n",
      "train loss: 0.00486719942584159, at epoch: 63\n",
      "\n",
      "Number of units: 5500\n",
      "train loss: 0.004926164995516728, at epoch: 64\n",
      "\n",
      "Number of units: 5510\n",
      "train loss: 0.004564550418464251, at epoch: 63\n",
      "\n",
      "Number of units: 5520\n",
      "train loss: 0.004897204200971715, at epoch: 63\n",
      "\n",
      "Number of units: 5530\n",
      "train loss: 0.004935021843678555, at epoch: 63\n",
      "\n",
      "Number of units: 5540\n",
      "train loss: 0.004718386560098793, at epoch: 64\n",
      "\n",
      "Number of units: 5550\n",
      "train loss: 0.004748157589035031, at epoch: 64\n",
      "\n",
      "Number of units: 5560\n",
      "train loss: 0.004787310354935244, at epoch: 63\n",
      "\n",
      "Number of units: 5570\n",
      "train loss: 0.004991741105501432, at epoch: 63\n",
      "\n",
      "Number of units: 5580\n",
      "train loss: 0.004990943352424324, at epoch: 62\n",
      "\n",
      "Number of units: 5590\n",
      "train loss: 0.004837699426595918, at epoch: 65\n",
      "\n",
      "Number of units: 5600\n",
      "train loss: 0.004756527049921857, at epoch: 65\n",
      "\n",
      "Number of units: 5610\n",
      "train loss: 0.0045287431352784326, at epoch: 66\n",
      "\n",
      "Number of units: 5620\n",
      "train loss: 0.004926589586194723, at epoch: 64\n",
      "\n",
      "Number of units: 5630\n",
      "train loss: 0.004006560931092622, at epoch: 65\n",
      "\n",
      "Number of units: 5640\n",
      "train loss: 0.004894819379794626, at epoch: 65\n",
      "\n",
      "Number of units: 5650\n",
      "train loss: 0.0045009747042189475, at epoch: 64\n",
      "\n",
      "Number of units: 5660\n",
      "train loss: 0.0046829936201686455, at epoch: 64\n",
      "\n",
      "Number of units: 5670\n",
      "train loss: 0.004909779714344893, at epoch: 64\n",
      "\n",
      "Number of units: 5680\n",
      "train loss: 0.004424206949279892, at epoch: 64\n",
      "\n",
      "Number of units: 5690\n",
      "train loss: 0.004732780184607464, at epoch: 64\n",
      "\n",
      "Number of units: 5700\n",
      "train loss: 0.004795129939414551, at epoch: 62\n",
      "\n",
      "Number of units: 5710\n",
      "train loss: 0.004789611535029508, at epoch: 62\n",
      "\n",
      "Number of units: 5720\n",
      "train loss: 0.004703046680307068, at epoch: 63\n",
      "\n",
      "Number of units: 5730\n",
      "train loss: 0.004952871765372607, at epoch: 64\n",
      "\n",
      "Number of units: 5740\n",
      "train loss: 0.004979726155863773, at epoch: 63\n",
      "\n",
      "Number of units: 5750\n",
      "train loss: 0.004482424653372732, at epoch: 66\n",
      "\n",
      "Number of units: 5760\n",
      "train loss: 0.004993227991529352, at epoch: 63\n",
      "\n",
      "Number of units: 5770\n",
      "train loss: 0.0049447898386114275, at epoch: 62\n",
      "\n",
      "Number of units: 5780\n",
      "train loss: 0.004896955726283067, at epoch: 63\n",
      "\n",
      "Number of units: 5790\n",
      "train loss: 0.004887916084737185, at epoch: 65\n",
      "\n",
      "Number of units: 5800\n",
      "train loss: 0.004889158610342861, at epoch: 62\n",
      "\n",
      "Number of units: 5810\n",
      "train loss: 0.004842485632453872, at epoch: 62\n",
      "\n",
      "Number of units: 5820\n",
      "train loss: 0.004750873505222444, at epoch: 64\n",
      "\n",
      "Number of units: 5830\n",
      "train loss: 0.004544299663513698, at epoch: 64\n",
      "\n",
      "Number of units: 5840\n",
      "train loss: 0.004697377738727937, at epoch: 62\n",
      "\n",
      "Number of units: 5850\n",
      "train loss: 0.00435253715846045, at epoch: 63\n",
      "\n",
      "Number of units: 5860\n",
      "train loss: 0.004263198630761451, at epoch: 64\n",
      "\n",
      "Number of units: 5870\n",
      "train loss: 0.0045506105913685245, at epoch: 63\n",
      "\n",
      "Number of units: 5880\n",
      "train loss: 0.004947854184722473, at epoch: 62\n",
      "\n",
      "Number of units: 5890\n",
      "train loss: 0.004926412243548839, at epoch: 62\n",
      "\n",
      "Number of units: 5900\n",
      "train loss: 0.004846236968808171, at epoch: 62\n",
      "\n",
      "Number of units: 5910\n",
      "train loss: 0.004698957712296305, at epoch: 63\n",
      "\n",
      "Number of units: 5920\n",
      "train loss: 0.004769211151867125, at epoch: 61\n",
      "\n",
      "Number of units: 5930\n",
      "train loss: 0.004756769835128125, at epoch: 62\n",
      "\n",
      "Number of units: 5940\n",
      "train loss: 0.004677245298964294, at epoch: 63\n",
      "\n",
      "Number of units: 5950\n",
      "train loss: 0.004989812583378921, at epoch: 61\n",
      "\n",
      "Number of units: 5960\n",
      "train loss: 0.004984955067404826, at epoch: 62\n",
      "\n",
      "Number of units: 5970\n",
      "train loss: 0.0042830236323544565, at epoch: 63\n",
      "\n",
      "Number of units: 5980\n",
      "train loss: 0.004761789424953804, at epoch: 61\n",
      "\n",
      "Number of units: 5990\n",
      "train loss: 0.004892921635803305, at epoch: 62\n",
      "\n",
      "Number of units: 6000\n",
      "train loss: 0.004835212690289268, at epoch: 63\n",
      "\n",
      "Number of units: 6010\n",
      "train loss: 0.0048200513743921645, at epoch: 62\n",
      "\n",
      "Number of units: 6020\n",
      "train loss: 0.004848886182028309, at epoch: 63\n",
      "\n",
      "Number of units: 6030\n",
      "train loss: 0.00485855268273383, at epoch: 62\n",
      "\n",
      "Number of units: 6040\n",
      "train loss: 0.0048588270817847955, at epoch: 62\n",
      "\n",
      "Number of units: 6050\n",
      "train loss: 0.004213599430261184, at epoch: 64\n",
      "\n",
      "Number of units: 6060\n",
      "train loss: 0.004637121769825399, at epoch: 62\n",
      "\n",
      "Number of units: 6070\n",
      "train loss: 0.004714174171552941, at epoch: 62\n",
      "\n",
      "Number of units: 6080\n",
      "train loss: 0.004897729243031108, at epoch: 62\n",
      "\n",
      "Number of units: 6090\n",
      "train loss: 0.004965094225404983, at epoch: 61\n",
      "\n",
      "Number of units: 6100\n",
      "train loss: 0.004490656197017415, at epoch: 63\n",
      "\n",
      "Number of units: 6110\n",
      "train loss: 0.004892521390726756, at epoch: 61\n",
      "\n",
      "Number of units: 6120\n",
      "train loss: 0.0048734144193389286, at epoch: 61\n",
      "\n",
      "Number of units: 6130\n",
      "train loss: 0.004551386140358318, at epoch: 62\n",
      "\n",
      "Number of units: 6140\n",
      "train loss: 0.004983640922051791, at epoch: 62\n",
      "\n",
      "Number of units: 6150\n",
      "train loss: 0.004864979101513427, at epoch: 62\n",
      "\n",
      "Number of units: 6160\n",
      "train loss: 0.004928404034548635, at epoch: 61\n",
      "\n",
      "Number of units: 6170\n",
      "train loss: 0.0046754006570751015, at epoch: 63\n",
      "\n",
      "Number of units: 6180\n",
      "train loss: 0.004435773102284202, at epoch: 63\n",
      "\n",
      "Number of units: 6190\n",
      "train loss: 0.0048736127710253645, at epoch: 61\n",
      "\n",
      "Number of units: 6200\n",
      "train loss: 0.004426176506482307, at epoch: 61\n",
      "\n",
      "Number of units: 6210\n",
      "train loss: 0.004294299725759174, at epoch: 64\n",
      "\n",
      "Number of units: 6220\n",
      "train loss: 0.00483823862514555, at epoch: 60\n",
      "\n",
      "Number of units: 6230\n",
      "train loss: 0.004738770531017736, at epoch: 62\n",
      "\n",
      "Number of units: 6240\n",
      "train loss: 0.004856075542923577, at epoch: 62\n",
      "\n",
      "Number of units: 6250\n",
      "train loss: 0.004956586947104142, at epoch: 62\n",
      "\n",
      "Number of units: 6260\n",
      "train loss: 0.0047930159696517195, at epoch: 61\n",
      "\n",
      "Number of units: 6270\n",
      "train loss: 0.004457495108209173, at epoch: 62\n",
      "\n",
      "Number of units: 6280\n",
      "train loss: 0.00479388101904874, at epoch: 63\n",
      "\n",
      "Number of units: 6290\n",
      "train loss: 0.004288116748834341, at epoch: 63\n",
      "\n",
      "Number of units: 6300\n",
      "train loss: 0.004915477765546256, at epoch: 60\n",
      "\n",
      "Number of units: 6310\n",
      "train loss: 0.004908497179582696, at epoch: 62\n",
      "\n",
      "Number of units: 6320\n",
      "train loss: 0.00459888965382163, at epoch: 63\n",
      "\n",
      "Number of units: 6330\n",
      "train loss: 0.004696296371063227, at epoch: 62\n",
      "\n",
      "Number of units: 6340\n",
      "train loss: 0.0049584388218988805, at epoch: 61\n",
      "\n",
      "Number of units: 6350\n",
      "train loss: 0.004510211092876375, at epoch: 62\n",
      "\n",
      "Number of units: 6360\n",
      "train loss: 0.0046268206064110015, at epoch: 62\n",
      "\n",
      "Number of units: 6370\n",
      "train loss: 0.004638019238281004, at epoch: 63\n",
      "\n",
      "Number of units: 6380\n",
      "train loss: 0.0047567164694714845, at epoch: 62\n",
      "\n",
      "Number of units: 6390\n",
      "train loss: 0.004617212256513312, at epoch: 61\n",
      "\n",
      "Number of units: 6400\n",
      "train loss: 0.004728731348128008, at epoch: 63\n",
      "\n",
      "Number of units: 6410\n",
      "train loss: 0.004651911058949736, at epoch: 62\n",
      "\n",
      "Number of units: 6420\n",
      "train loss: 0.00416930275901052, at epoch: 62\n",
      "\n",
      "Number of units: 6430\n",
      "train loss: 0.0048604048138338385, at epoch: 60\n",
      "\n",
      "Number of units: 6440\n",
      "train loss: 0.0043088527759988435, at epoch: 63\n",
      "\n",
      "Number of units: 6450\n",
      "train loss: 0.0043268119228179105, at epoch: 62\n",
      "\n",
      "Number of units: 6460\n",
      "train loss: 0.004804285076054384, at epoch: 62\n",
      "\n",
      "Number of units: 6470\n",
      "train loss: 0.004547327592410966, at epoch: 62\n",
      "\n",
      "Number of units: 6480\n",
      "train loss: 0.004727457609528756, at epoch: 61\n",
      "\n",
      "Number of units: 6490\n",
      "train loss: 0.004829023136635442, at epoch: 62\n",
      "\n",
      "Number of units: 6500\n",
      "train loss: 0.004801713809890771, at epoch: 60\n",
      "\n",
      "Number of units: 6510\n",
      "train loss: 0.004893434046985589, at epoch: 61\n",
      "\n",
      "Number of units: 6520\n",
      "train loss: 0.004457976484508777, at epoch: 61\n",
      "\n",
      "Number of units: 6530\n",
      "train loss: 0.004875620746042273, at epoch: 60\n",
      "\n",
      "Number of units: 6540\n",
      "train loss: 0.00452951928200946, at epoch: 62\n",
      "\n",
      "Number of units: 6550\n",
      "train loss: 0.0049390861522215345, at epoch: 61\n",
      "\n",
      "Number of units: 6560\n",
      "train loss: 0.004585931609181557, at epoch: 61\n",
      "\n",
      "Number of units: 6570\n",
      "train loss: 0.004944766141727541, at epoch: 61\n",
      "\n",
      "Number of units: 6580\n",
      "train loss: 0.004511994776956954, at epoch: 62\n",
      "\n",
      "Number of units: 6590\n",
      "train loss: 0.00488842780338814, at epoch: 60\n",
      "\n",
      "Number of units: 6600\n",
      "train loss: 0.004928114092863325, at epoch: 60\n",
      "\n",
      "Number of units: 6610\n",
      "train loss: 0.004641534134172502, at epoch: 61\n",
      "\n",
      "Number of units: 6620\n",
      "train loss: 0.00480252177275247, at epoch: 60\n",
      "\n",
      "Number of units: 6630\n",
      "train loss: 0.00485411360513126, at epoch: 60\n",
      "\n",
      "Number of units: 6640\n",
      "train loss: 0.004275550938730248, at epoch: 61\n",
      "\n",
      "Number of units: 6650\n",
      "train loss: 0.004350635106016512, at epoch: 61\n",
      "\n",
      "Number of units: 6660\n",
      "train loss: 0.004939095097945483, at epoch: 59\n",
      "\n",
      "Number of units: 6670\n",
      "train loss: 0.004521398037155109, at epoch: 63\n",
      "\n",
      "Number of units: 6680\n",
      "train loss: 0.004813227558484243, at epoch: 60\n",
      "\n",
      "Number of units: 6690\n",
      "train loss: 0.00488215955666476, at epoch: 59\n",
      "\n",
      "Number of units: 6700\n",
      "train loss: 0.004719102632896011, at epoch: 59\n",
      "\n",
      "Number of units: 6710\n",
      "train loss: 0.004932370773480557, at epoch: 60\n",
      "\n",
      "Number of units: 6720\n",
      "train loss: 0.004530815556611287, at epoch: 61\n",
      "\n",
      "Number of units: 6730\n",
      "train loss: 0.004934832346425538, at epoch: 59\n",
      "\n",
      "Number of units: 6740\n",
      "train loss: 0.004996320052039209, at epoch: 60\n",
      "\n",
      "Number of units: 6750\n",
      "train loss: 0.004669158262406086, at epoch: 60\n",
      "\n",
      "Number of units: 6760\n",
      "train loss: 0.004624997474981001, at epoch: 61\n",
      "\n",
      "Number of units: 6770\n",
      "train loss: 0.004991671378195974, at epoch: 59\n",
      "\n",
      "Number of units: 6780\n",
      "train loss: 0.004417537615361198, at epoch: 61\n",
      "\n",
      "Number of units: 6790\n",
      "train loss: 0.004763322899973446, at epoch: 59\n",
      "\n",
      "Number of units: 6800\n",
      "train loss: 0.004630566201327611, at epoch: 60\n",
      "\n",
      "Number of units: 6810\n",
      "train loss: 0.004924940350103952, at epoch: 61\n",
      "\n",
      "Number of units: 6820\n",
      "train loss: 0.004641281031442759, at epoch: 62\n",
      "\n",
      "Number of units: 6830\n",
      "train loss: 0.004610686544354508, at epoch: 60\n",
      "\n",
      "Number of units: 6840\n",
      "train loss: 0.0049824612046529635, at epoch: 59\n",
      "\n",
      "Number of units: 6850\n",
      "train loss: 0.004629681817392566, at epoch: 60\n",
      "\n",
      "Number of units: 6860\n",
      "train loss: 0.004722208913522081, at epoch: 60\n",
      "\n",
      "Number of units: 6870\n",
      "train loss: 0.004431437211270577, at epoch: 61\n",
      "\n",
      "Number of units: 6880\n",
      "train loss: 0.004852835907659028, at epoch: 59\n",
      "\n",
      "Number of units: 6890\n",
      "train loss: 0.004328698511570792, at epoch: 61\n",
      "\n",
      "Number of units: 6900\n",
      "train loss: 0.0047352240429506766, at epoch: 61\n",
      "\n",
      "Number of units: 6910\n",
      "train loss: 0.0048196278420078896, at epoch: 60\n",
      "\n",
      "Number of units: 6920\n",
      "train loss: 0.004841552516282945, at epoch: 59\n",
      "\n",
      "Number of units: 6930\n",
      "train loss: 0.004885415878192134, at epoch: 60\n",
      "\n",
      "Number of units: 6940\n",
      "train loss: 0.004921292224640866, at epoch: 59\n",
      "\n",
      "Number of units: 6950\n",
      "train loss: 0.004742073086948153, at epoch: 59\n",
      "\n",
      "Number of units: 6960\n",
      "train loss: 0.004569614336395489, at epoch: 60\n",
      "\n",
      "Number of units: 6970\n",
      "train loss: 0.00427478927601527, at epoch: 62\n",
      "\n",
      "Number of units: 6980\n",
      "train loss: 0.004937931201666288, at epoch: 59\n",
      "\n",
      "Number of units: 6990\n",
      "train loss: 0.004491397313124708, at epoch: 61\n",
      "\n",
      "Number of units: 7000\n",
      "train loss: 0.004741759741282294, at epoch: 61\n",
      "\n",
      "Number of units: 7010\n",
      "train loss: 0.004968853836896869, at epoch: 60\n",
      "\n",
      "Number of units: 7020\n",
      "train loss: 0.00488384149543549, at epoch: 59\n",
      "\n",
      "Number of units: 7030\n",
      "train loss: 0.004933934953452308, at epoch: 58\n",
      "\n",
      "Number of units: 7040\n",
      "train loss: 0.004582604652849796, at epoch: 60\n",
      "\n",
      "Number of units: 7050\n",
      "train loss: 0.004826874315882037, at epoch: 59\n",
      "\n",
      "Number of units: 7060\n",
      "train loss: 0.004878769242426415, at epoch: 59\n",
      "\n",
      "Number of units: 7070\n",
      "train loss: 0.004905004332875933, at epoch: 60\n",
      "\n",
      "Number of units: 7080\n",
      "train loss: 0.004868127651099599, at epoch: 60\n",
      "\n",
      "Number of units: 7090\n",
      "train loss: 0.0049437047289598015, at epoch: 59\n",
      "\n",
      "Number of units: 7100\n",
      "train loss: 0.0045662275009993895, at epoch: 59\n",
      "\n",
      "Number of units: 7110\n",
      "train loss: 0.0049367769445944985, at epoch: 59\n",
      "\n",
      "Number of units: 7120\n",
      "train loss: 0.004780132315549963, at epoch: 59\n",
      "\n",
      "Number of units: 7130\n",
      "train loss: 0.004981270942346327, at epoch: 59\n",
      "\n",
      "Number of units: 7140\n",
      "train loss: 0.004615325936175623, at epoch: 59\n",
      "\n",
      "Number of units: 7150\n",
      "train loss: 0.004612806619819594, at epoch: 59\n",
      "\n",
      "Number of units: 7160\n",
      "train loss: 0.004519271557008438, at epoch: 59\n",
      "\n",
      "Number of units: 7170\n",
      "train loss: 0.004957838046465213, at epoch: 58\n",
      "\n",
      "Number of units: 7180\n",
      "train loss: 0.004581693187279257, at epoch: 59\n",
      "\n",
      "Number of units: 7190\n",
      "train loss: 0.0048571005188580325, at epoch: 59\n",
      "\n",
      "Number of units: 7200\n",
      "train loss: 0.004816361771122502, at epoch: 59\n",
      "\n",
      "Number of units: 7210\n",
      "train loss: 0.004730774389636281, at epoch: 59\n",
      "\n",
      "Number of units: 7220\n",
      "train loss: 0.004792248854771515, at epoch: 58\n",
      "\n",
      "Number of units: 7230\n",
      "train loss: 0.004609502364647824, at epoch: 60\n",
      "\n",
      "Number of units: 7240\n",
      "train loss: 0.004627476773200101, at epoch: 59\n",
      "\n",
      "Number of units: 7250\n",
      "train loss: 0.004663149568679046, at epoch: 59\n",
      "\n",
      "Number of units: 7260\n",
      "train loss: 0.0049495272211970585, at epoch: 59\n",
      "\n",
      "Number of units: 7270\n",
      "train loss: 0.004570667937543362, at epoch: 59\n",
      "\n",
      "Number of units: 7280\n",
      "train loss: 0.00482752471793674, at epoch: 58\n",
      "\n",
      "Number of units: 7290\n",
      "train loss: 0.004785596111526047, at epoch: 59\n",
      "\n",
      "Number of units: 7300\n",
      "train loss: 0.004929875660463949, at epoch: 57\n",
      "\n",
      "Number of units: 7310\n",
      "train loss: 0.004663512005566303, at epoch: 58\n",
      "\n",
      "Number of units: 7320\n",
      "train loss: 0.004789800214786056, at epoch: 60\n",
      "\n",
      "Number of units: 7330\n",
      "train loss: 0.004975947214179541, at epoch: 59\n",
      "\n",
      "Number of units: 7340\n",
      "train loss: 0.0045274665726788045, at epoch: 58\n",
      "\n",
      "Number of units: 7350\n",
      "train loss: 0.004621625188371468, at epoch: 59\n",
      "\n",
      "Number of units: 7360\n",
      "train loss: 0.0046533231596652055, at epoch: 59\n",
      "\n",
      "Number of units: 7370\n",
      "train loss: 0.004861185395021153, at epoch: 60\n",
      "\n",
      "Number of units: 7380\n",
      "train loss: 0.004478555266519493, at epoch: 59\n",
      "\n",
      "Number of units: 7390\n",
      "train loss: 0.004630288908022635, at epoch: 58\n",
      "\n",
      "Number of units: 7400\n",
      "train loss: 0.004967731814430749, at epoch: 58\n",
      "\n",
      "Number of units: 7410\n",
      "train loss: 0.004772137250868696, at epoch: 60\n",
      "\n",
      "Number of units: 7420\n",
      "train loss: 0.00468392619022552, at epoch: 59\n",
      "\n",
      "Number of units: 7430\n",
      "train loss: 0.004640416336915223, at epoch: 59\n",
      "\n",
      "Number of units: 7440\n",
      "train loss: 0.004796152256313917, at epoch: 57\n",
      "\n",
      "Number of units: 7450\n",
      "train loss: 0.00496648963887651, at epoch: 59\n",
      "\n",
      "Number of units: 7460\n",
      "train loss: 0.004305779273568078, at epoch: 60\n",
      "\n",
      "Number of units: 7470\n",
      "train loss: 0.004945093468302275, at epoch: 60\n",
      "\n",
      "Number of units: 7480\n",
      "train loss: 0.0045336614981465575, at epoch: 58\n",
      "\n",
      "Number of units: 7490\n",
      "train loss: 0.004831132802053162, at epoch: 58\n",
      "\n",
      "Number of units: 7500\n",
      "train loss: 0.00478464203699275, at epoch: 59\n",
      "\n",
      "Number of units: 7510\n",
      "train loss: 0.004775389987150902, at epoch: 58\n",
      "\n",
      "Number of units: 7520\n",
      "train loss: 0.004998549050836232, at epoch: 57\n",
      "\n",
      "Number of units: 7530\n",
      "train loss: 0.004879800734111086, at epoch: 56\n",
      "\n",
      "Number of units: 7540\n",
      "train loss: 0.004755213687632249, at epoch: 58\n",
      "\n",
      "Number of units: 7550\n",
      "train loss: 0.004963919042684495, at epoch: 58\n",
      "\n",
      "Number of units: 7560\n",
      "train loss: 0.004422870297122472, at epoch: 58\n",
      "\n",
      "Number of units: 7570\n",
      "train loss: 0.004772837547375844, at epoch: 60\n",
      "\n",
      "Number of units: 7580\n",
      "train loss: 0.004809580737171473, at epoch: 58\n",
      "\n",
      "Number of units: 7590\n",
      "train loss: 0.004294934247446065, at epoch: 59\n",
      "\n",
      "Number of units: 7600\n",
      "train loss: 0.004744257681634281, at epoch: 58\n",
      "\n",
      "Number of units: 7610\n",
      "train loss: 0.0048145124865664, at epoch: 57\n",
      "\n",
      "Number of units: 7620\n",
      "train loss: 0.004823012874152824, at epoch: 59\n",
      "\n",
      "Number of units: 7630\n",
      "train loss: 0.004836138568056754, at epoch: 56\n",
      "\n",
      "Number of units: 7640\n",
      "train loss: 0.004852069434175519, at epoch: 58\n",
      "\n",
      "Number of units: 7650\n",
      "train loss: 0.004601934744842424, at epoch: 59\n",
      "\n",
      "Number of units: 7660\n",
      "train loss: 0.0047928919891626265, at epoch: 57\n",
      "\n",
      "Number of units: 7670\n",
      "train loss: 0.004911606272299025, at epoch: 57\n",
      "\n",
      "Number of units: 7680\n",
      "train loss: 0.004546961442687234, at epoch: 58\n",
      "\n",
      "Number of units: 7690\n",
      "train loss: 0.004641970076764607, at epoch: 58\n",
      "\n",
      "Number of units: 7700\n",
      "train loss: 0.004823003924562954, at epoch: 57\n",
      "\n",
      "Number of units: 7710\n",
      "train loss: 0.0049379619640353666, at epoch: 57\n",
      "\n",
      "Number of units: 7720\n",
      "train loss: 0.004414168650793613, at epoch: 59\n",
      "\n",
      "Number of units: 7730\n",
      "train loss: 0.004729084090160427, at epoch: 58\n",
      "\n",
      "Number of units: 7740\n",
      "train loss: 0.004670686675613069, at epoch: 57\n",
      "\n",
      "Number of units: 7750\n",
      "train loss: 0.004726273766370923, at epoch: 56\n",
      "\n",
      "Number of units: 7760\n",
      "train loss: 0.004311673919802104, at epoch: 59\n",
      "\n",
      "Number of units: 7770\n",
      "train loss: 0.004792592172365175, at epoch: 59\n",
      "\n",
      "Number of units: 7780\n",
      "train loss: 0.004844202335915497, at epoch: 57\n",
      "\n",
      "Number of units: 7790\n",
      "train loss: 0.0047737611959209406, at epoch: 57\n",
      "\n",
      "Number of units: 7800\n",
      "train loss: 0.0046193378914159665, at epoch: 58\n",
      "\n",
      "Number of units: 7810\n",
      "train loss: 0.00473041773117302, at epoch: 59\n",
      "\n",
      "Number of units: 7820\n",
      "train loss: 0.004795044164976332, at epoch: 58\n",
      "\n",
      "Number of units: 7830\n",
      "train loss: 0.004794404054836718, at epoch: 58\n",
      "\n",
      "Number of units: 7840\n",
      "train loss: 0.004381829265771558, at epoch: 59\n",
      "\n",
      "Number of units: 7850\n",
      "train loss: 0.004896707905700169, at epoch: 57\n",
      "\n",
      "Number of units: 7860\n",
      "train loss: 0.0048319945177797766, at epoch: 58\n",
      "\n",
      "Number of units: 7870\n",
      "train loss: 0.004824789646937689, at epoch: 57\n",
      "\n",
      "Number of units: 7880\n",
      "train loss: 0.004828931866543371, at epoch: 57\n",
      "\n",
      "Number of units: 7890\n",
      "train loss: 0.004797836374166309, at epoch: 56\n",
      "\n",
      "Number of units: 7900\n",
      "train loss: 0.0038443922999647382, at epoch: 59\n",
      "\n",
      "Number of units: 7910\n",
      "train loss: 0.004880352917008395, at epoch: 56\n",
      "\n",
      "Number of units: 7920\n",
      "train loss: 0.004342017732865315, at epoch: 58\n",
      "\n",
      "Number of units: 7930\n",
      "train loss: 0.004951055925369588, at epoch: 58\n",
      "\n",
      "Number of units: 7940\n",
      "train loss: 0.004758884661431467, at epoch: 58\n",
      "\n",
      "Number of units: 7950\n",
      "train loss: 0.004767525087773947, at epoch: 57\n",
      "\n",
      "Number of units: 7960\n",
      "train loss: 0.004907929791126548, at epoch: 56\n",
      "\n",
      "Number of units: 7970\n",
      "train loss: 0.004451857235264925, at epoch: 58\n",
      "\n",
      "Number of units: 7980\n",
      "train loss: 0.004553903999226918, at epoch: 58\n",
      "\n",
      "Number of units: 7990\n",
      "train loss: 0.004827206326033888, at epoch: 57\n",
      "\n",
      "Number of units: 8000\n",
      "train loss: 0.004360682804630187, at epoch: 59\n",
      "\n",
      "Number of units: 8010\n",
      "train loss: 0.004521220384956451, at epoch: 58\n",
      "\n",
      "Number of units: 8020\n",
      "train loss: 0.0048817681498246656, at epoch: 57\n",
      "\n",
      "Number of units: 8030\n",
      "train loss: 0.004578949884540293, at epoch: 58\n",
      "\n",
      "Number of units: 8040\n",
      "train loss: 0.0045781000647667726, at epoch: 59\n",
      "\n",
      "Number of units: 8050\n",
      "train loss: 0.0048977597168573085, at epoch: 57\n",
      "\n",
      "Number of units: 8060\n",
      "train loss: 0.004791546043753385, at epoch: 57\n",
      "\n",
      "Number of units: 8070\n",
      "train loss: 0.004501778544910735, at epoch: 57\n",
      "\n",
      "Number of units: 8080\n",
      "train loss: 0.004449775185160547, at epoch: 57\n",
      "\n",
      "Number of units: 8090\n",
      "train loss: 0.004538065555433377, at epoch: 57\n",
      "\n",
      "Number of units: 8100\n",
      "train loss: 0.004696628918467809, at epoch: 57\n",
      "\n",
      "Number of units: 8110\n",
      "train loss: 0.004967513904572911, at epoch: 56\n",
      "\n",
      "Number of units: 8120\n",
      "train loss: 0.004736493547813438, at epoch: 57\n",
      "\n",
      "Number of units: 8130\n",
      "train loss: 0.004673080764883366, at epoch: 57\n",
      "\n",
      "Number of units: 8140\n",
      "train loss: 0.004743891405043428, at epoch: 56\n",
      "\n",
      "Number of units: 8150\n",
      "train loss: 0.00449634853599207, at epoch: 57\n",
      "\n",
      "Number of units: 8160\n",
      "train loss: 0.004937713978353031, at epoch: 56\n",
      "\n",
      "Number of units: 8170\n",
      "train loss: 0.004919603230373468, at epoch: 56\n",
      "\n",
      "Number of units: 8180\n",
      "train loss: 0.004866827409293819, at epoch: 56\n",
      "\n",
      "Number of units: 8190\n",
      "train loss: 0.004618571505558293, at epoch: 56\n",
      "\n",
      "Number of units: 8200\n",
      "train loss: 0.0043865819821292005, at epoch: 58\n",
      "\n",
      "Number of units: 8210\n",
      "train loss: 0.004699490702361118, at epoch: 57\n",
      "\n",
      "Number of units: 8220\n",
      "train loss: 0.004650896430647435, at epoch: 56\n",
      "\n",
      "Number of units: 8230\n",
      "train loss: 0.004467331490909601, at epoch: 57\n",
      "\n",
      "Number of units: 8240\n",
      "train loss: 0.004977119017735276, at epoch: 57\n",
      "\n",
      "Number of units: 8250\n",
      "train loss: 0.004377653816955842, at epoch: 58\n",
      "\n",
      "Number of units: 8260\n",
      "train loss: 0.004998851577351502, at epoch: 57\n",
      "\n",
      "Number of units: 8270\n",
      "train loss: 0.004865059514516474, at epoch: 56\n",
      "\n",
      "Number of units: 8280\n",
      "train loss: 0.004741874185376673, at epoch: 57\n",
      "\n",
      "Number of units: 8290\n",
      "train loss: 0.004811670927658156, at epoch: 56\n",
      "\n",
      "Number of units: 8300\n",
      "train loss: 0.004723950467189297, at epoch: 56\n",
      "\n",
      "Number of units: 8310\n",
      "train loss: 0.004236769742606157, at epoch: 57\n",
      "\n",
      "Number of units: 8320\n",
      "train loss: 0.004646711776927077, at epoch: 57\n",
      "\n",
      "Number of units: 8330\n",
      "train loss: 0.004775957278558849, at epoch: 56\n",
      "\n",
      "Number of units: 8340\n",
      "train loss: 0.0047795614891902, at epoch: 56\n",
      "\n",
      "Number of units: 8350\n",
      "train loss: 0.004810626504292941, at epoch: 57\n",
      "\n",
      "Number of units: 8360\n",
      "train loss: 0.0048281011316692, at epoch: 55\n",
      "\n",
      "Number of units: 8370\n",
      "train loss: 0.004843429119069924, at epoch: 56\n",
      "\n",
      "Number of units: 8380\n",
      "train loss: 0.004874216241335034, at epoch: 57\n",
      "\n",
      "Number of units: 8390\n",
      "train loss: 0.004762664654402897, at epoch: 56\n",
      "\n",
      "Number of units: 8400\n",
      "train loss: 0.004613591717526902, at epoch: 56\n",
      "\n",
      "Number of units: 8410\n",
      "train loss: 0.0046967386495572324, at epoch: 56\n",
      "\n",
      "Number of units: 8420\n",
      "train loss: 0.004886770902537592, at epoch: 55\n",
      "\n",
      "Number of units: 8430\n",
      "train loss: 0.004908149267202475, at epoch: 56\n",
      "\n",
      "Number of units: 8440\n",
      "train loss: 0.004817962269525538, at epoch: 55\n",
      "\n",
      "Number of units: 8450\n",
      "train loss: 0.0048140356330782196, at epoch: 56\n",
      "\n",
      "Number of units: 8460\n",
      "train loss: 0.004771604717876699, at epoch: 57\n",
      "\n",
      "Number of units: 8470\n",
      "train loss: 0.0049502303640588255, at epoch: 56\n",
      "\n",
      "Number of units: 8480\n",
      "train loss: 0.004980405055387109, at epoch: 56\n",
      "\n",
      "Number of units: 8490\n",
      "train loss: 0.00477194444929637, at epoch: 56\n",
      "\n",
      "Number of units: 8500\n",
      "train loss: 0.004975192950566338, at epoch: 55\n",
      "\n",
      "Number of units: 8510\n",
      "train loss: 0.004802895611763347, at epoch: 56\n",
      "\n",
      "Number of units: 8520\n",
      "train loss: 0.0044873724829176355, at epoch: 56\n",
      "\n",
      "Number of units: 8530\n",
      "train loss: 0.004499366943791756, at epoch: 57\n",
      "\n",
      "Number of units: 8540\n",
      "train loss: 0.00427471587751711, at epoch: 58\n",
      "\n",
      "Number of units: 8550\n",
      "train loss: 0.0048273449749638075, at epoch: 55\n",
      "\n",
      "Number of units: 8560\n",
      "train loss: 0.004617465089182531, at epoch: 56\n",
      "\n",
      "Number of units: 8570\n",
      "train loss: 0.004809608822397422, at epoch: 55\n",
      "\n",
      "Number of units: 8580\n",
      "train loss: 0.004941557893685058, at epoch: 55\n",
      "\n",
      "Number of units: 8590\n",
      "train loss: 0.004594631421433633, at epoch: 56\n",
      "\n",
      "Number of units: 8600\n",
      "train loss: 0.004540186896977047, at epoch: 56\n",
      "\n",
      "Number of units: 8610\n",
      "train loss: 0.004655888796322643, at epoch: 55\n",
      "\n",
      "Number of units: 8620\n",
      "train loss: 0.004831407420605274, at epoch: 56\n",
      "\n",
      "Number of units: 8630\n",
      "train loss: 0.004756106580105097, at epoch: 54\n",
      "\n",
      "Number of units: 8640\n",
      "train loss: 0.0047724202303845685, at epoch: 55\n",
      "\n",
      "Number of units: 8650\n",
      "train loss: 0.004873475541737662, at epoch: 56\n",
      "\n",
      "Number of units: 8660\n",
      "train loss: 0.004504457832621256, at epoch: 57\n",
      "\n",
      "Number of units: 8670\n",
      "train loss: 0.004744262217767528, at epoch: 56\n",
      "\n",
      "Number of units: 8680\n",
      "train loss: 0.004959074713162295, at epoch: 56\n",
      "\n",
      "Number of units: 8690\n",
      "train loss: 0.0049108486669601345, at epoch: 56\n",
      "\n",
      "Number of units: 8700\n",
      "train loss: 0.004714975890217374, at epoch: 56\n",
      "\n",
      "Number of units: 8710\n",
      "train loss: 0.0044368447634843735, at epoch: 57\n",
      "\n",
      "Number of units: 8720\n",
      "train loss: 0.004634775987190665, at epoch: 56\n",
      "\n",
      "Number of units: 8730\n",
      "train loss: 0.004768871157600643, at epoch: 55\n",
      "\n",
      "Number of units: 8740\n",
      "train loss: 0.003935259732622853, at epoch: 58\n",
      "\n",
      "Number of units: 8750\n",
      "train loss: 0.004842809636490983, at epoch: 56\n",
      "\n",
      "Number of units: 8760\n",
      "train loss: 0.004595187303092416, at epoch: 55\n",
      "\n",
      "Number of units: 8770\n",
      "train loss: 0.004959551681535004, at epoch: 55\n",
      "\n",
      "Number of units: 8780\n",
      "train loss: 0.004761339762613943, at epoch: 55\n",
      "\n",
      "Number of units: 8790\n",
      "train loss: 0.004824164530784287, at epoch: 55\n",
      "\n",
      "Number of units: 8800\n",
      "train loss: 0.00478454566557275, at epoch: 55\n",
      "\n",
      "Number of units: 8810\n",
      "train loss: 0.004539735525159472, at epoch: 56\n",
      "\n",
      "Number of units: 8820\n",
      "train loss: 0.004857390373956037, at epoch: 55\n",
      "\n",
      "Number of units: 8830\n",
      "train loss: 0.0048840790307735915, at epoch: 54\n",
      "\n",
      "Number of units: 8840\n",
      "train loss: 0.004287807466595837, at epoch: 56\n",
      "\n",
      "Number of units: 8850\n",
      "train loss: 0.004540038371949322, at epoch: 55\n",
      "\n",
      "Number of units: 8860\n",
      "train loss: 0.004767933184282356, at epoch: 55\n",
      "\n",
      "Number of units: 8870\n",
      "train loss: 0.004624793935466869, at epoch: 56\n",
      "\n",
      "Number of units: 8880\n",
      "train loss: 0.004960340712370908, at epoch: 53\n",
      "\n",
      "Number of units: 8890\n",
      "train loss: 0.004357086345481207, at epoch: 56\n",
      "\n",
      "Number of units: 8900\n",
      "train loss: 0.0048551473020552295, at epoch: 54\n",
      "\n",
      "Number of units: 8910\n",
      "train loss: 0.004261304947650615, at epoch: 56\n",
      "\n",
      "Number of units: 8920\n",
      "train loss: 0.004860646840767231, at epoch: 55\n",
      "\n",
      "Number of units: 8930\n",
      "train loss: 0.004940465724808973, at epoch: 55\n",
      "\n",
      "Number of units: 8940\n",
      "train loss: 0.004930602216523994, at epoch: 56\n",
      "\n",
      "Number of units: 8950\n",
      "train loss: 0.004454768178233053, at epoch: 55\n",
      "\n",
      "Number of units: 8960\n",
      "train loss: 0.004883240535961022, at epoch: 54\n",
      "\n",
      "Number of units: 8970\n",
      "train loss: 0.004950781787308642, at epoch: 54\n",
      "\n",
      "Number of units: 8980\n",
      "train loss: 0.004934677645536567, at epoch: 55\n",
      "\n",
      "Number of units: 8990\n",
      "train loss: 0.0046495395563403005, at epoch: 56\n",
      "\n",
      "Number of units: 9000\n",
      "train loss: 0.004824666189590516, at epoch: 55\n",
      "\n",
      "Number of units: 9010\n",
      "train loss: 0.004642517495928473, at epoch: 55\n",
      "\n",
      "Number of units: 9020\n",
      "train loss: 0.004875126658157711, at epoch: 56\n",
      "\n",
      "Number of units: 9030\n",
      "train loss: 0.004936368573410732, at epoch: 55\n",
      "\n",
      "Number of units: 9040\n",
      "train loss: 0.004777451408185698, at epoch: 55\n",
      "\n",
      "Number of units: 9050\n",
      "train loss: 0.0047364477156526166, at epoch: 55\n",
      "\n",
      "Number of units: 9060\n",
      "train loss: 0.004738739235421576, at epoch: 55\n",
      "\n",
      "Number of units: 9070\n",
      "train loss: 0.004725916974286974, at epoch: 55\n",
      "\n",
      "Number of units: 9080\n",
      "train loss: 0.004799393746059195, at epoch: 56\n",
      "\n",
      "Number of units: 9090\n",
      "train loss: 0.004718266931566859, at epoch: 56\n",
      "\n",
      "Number of units: 9100\n",
      "train loss: 0.004337584774265224, at epoch: 56\n",
      "\n",
      "Number of units: 9110\n",
      "train loss: 0.004512849180421199, at epoch: 55\n",
      "\n",
      "Number of units: 9120\n",
      "train loss: 0.004806371269950205, at epoch: 56\n",
      "\n",
      "Number of units: 9130\n",
      "train loss: 0.004529338453770038, at epoch: 55\n",
      "\n",
      "Number of units: 9140\n",
      "train loss: 0.004909612785552895, at epoch: 54\n",
      "\n",
      "Number of units: 9150\n",
      "train loss: 0.00460954573153316, at epoch: 55\n",
      "\n",
      "Number of units: 9160\n",
      "train loss: 0.004810261814906767, at epoch: 54\n",
      "\n",
      "Number of units: 9170\n",
      "train loss: 0.004570547879483797, at epoch: 55\n",
      "\n",
      "Number of units: 9180\n",
      "train loss: 0.004620199408880126, at epoch: 54\n",
      "\n",
      "Number of units: 9190\n",
      "train loss: 0.004726638308814018, at epoch: 55\n",
      "\n",
      "Number of units: 9200\n",
      "train loss: 0.004969495735872442, at epoch: 54\n",
      "\n",
      "Number of units: 9210\n",
      "train loss: 0.00480053145069121, at epoch: 54\n",
      "\n",
      "Number of units: 9220\n",
      "train loss: 0.004540770568177663, at epoch: 55\n",
      "\n",
      "Number of units: 9230\n",
      "train loss: 0.004817401290949874, at epoch: 56\n",
      "\n",
      "Number of units: 9240\n",
      "train loss: 0.0046073785089910755, at epoch: 54\n",
      "\n",
      "Number of units: 9250\n",
      "train loss: 0.004619516709745994, at epoch: 54\n",
      "\n",
      "Number of units: 9260\n",
      "train loss: 0.0048288053237456555, at epoch: 55\n",
      "\n",
      "Number of units: 9270\n",
      "train loss: 0.004992634875768545, at epoch: 54\n",
      "\n",
      "Number of units: 9280\n",
      "train loss: 0.004648729725427074, at epoch: 55\n",
      "\n",
      "Number of units: 9290\n",
      "train loss: 0.004906157495481125, at epoch: 54\n",
      "\n",
      "Number of units: 9300\n",
      "train loss: 0.004295293402793732, at epoch: 55\n",
      "\n",
      "Number of units: 9310\n",
      "train loss: 0.0049681192590992395, at epoch: 54\n",
      "\n",
      "Number of units: 9320\n",
      "train loss: 0.004746992325192423, at epoch: 54\n",
      "\n",
      "Number of units: 9330\n",
      "train loss: 0.00468332767873676, at epoch: 54\n",
      "\n",
      "Number of units: 9340\n",
      "train loss: 0.004695057041529936, at epoch: 54\n",
      "\n",
      "Number of units: 9350\n",
      "train loss: 0.004743758962897573, at epoch: 54\n",
      "\n",
      "Number of units: 9360\n",
      "train loss: 0.004905180138496235, at epoch: 54\n",
      "\n",
      "Number of units: 9370\n",
      "train loss: 0.004340403164640065, at epoch: 56\n",
      "\n",
      "Number of units: 9380\n",
      "train loss: 0.004890412640316981, at epoch: 54\n",
      "\n",
      "Number of units: 9390\n",
      "train loss: 0.004736762624648918, at epoch: 55\n",
      "\n",
      "Number of units: 9400\n",
      "train loss: 0.004505797307832609, at epoch: 54\n",
      "\n",
      "Number of units: 9410\n",
      "train loss: 0.00496824887938942, at epoch: 53\n",
      "\n",
      "Number of units: 9420\n",
      "train loss: 0.0048410885366564575, at epoch: 55\n",
      "\n",
      "Number of units: 9430\n",
      "train loss: 0.004878452102668689, at epoch: 55\n",
      "\n",
      "Number of units: 9440\n",
      "train loss: 0.004733077538259636, at epoch: 54\n",
      "\n",
      "Number of units: 9450\n",
      "train loss: 0.004960127045542322, at epoch: 53\n",
      "\n",
      "Number of units: 9460\n",
      "train loss: 0.004340946711946003, at epoch: 55\n",
      "\n",
      "Number of units: 9470\n",
      "train loss: 0.004777740560723487, at epoch: 53\n",
      "\n",
      "Number of units: 9480\n",
      "train loss: 0.004800414196286624, at epoch: 54\n",
      "\n",
      "Number of units: 9490\n",
      "train loss: 0.004425180662288426, at epoch: 54\n",
      "\n",
      "Number of units: 9500\n",
      "train loss: 0.004747743512722309, at epoch: 53\n",
      "\n",
      "Number of units: 9510\n",
      "train loss: 0.00461783322827614, at epoch: 53\n",
      "\n",
      "Number of units: 9520\n",
      "train loss: 0.004739535943318742, at epoch: 54\n",
      "\n",
      "Number of units: 9530\n",
      "train loss: 0.004674014470681414, at epoch: 54\n",
      "\n",
      "Number of units: 9540\n",
      "train loss: 0.004416652482972267, at epoch: 54\n",
      "\n",
      "Number of units: 9550\n",
      "train loss: 0.004676046540718062, at epoch: 56\n",
      "\n",
      "Number of units: 9560\n",
      "train loss: 0.004671835070905672, at epoch: 54\n",
      "\n",
      "Number of units: 9570\n",
      "train loss: 0.004631158253766898, at epoch: 53\n",
      "\n",
      "Number of units: 9580\n",
      "train loss: 0.004690275956638175, at epoch: 54\n",
      "\n",
      "Number of units: 9590\n",
      "train loss: 0.004243928690649454, at epoch: 57\n",
      "\n",
      "Number of units: 9600\n",
      "train loss: 0.004051323710593238, at epoch: 55\n",
      "\n",
      "Number of units: 9610\n",
      "train loss: 0.004804826178004759, at epoch: 54\n",
      "\n",
      "Number of units: 9620\n",
      "train loss: 0.004824948655153776, at epoch: 53\n",
      "\n",
      "Number of units: 9630\n",
      "train loss: 0.00412140918226271, at epoch: 56\n",
      "\n",
      "Number of units: 9640\n",
      "train loss: 0.004651302776246666, at epoch: 54\n",
      "\n",
      "Number of units: 9650\n",
      "train loss: 0.00454919872787741, at epoch: 55\n",
      "\n",
      "Number of units: 9660\n",
      "train loss: 0.004680209793940548, at epoch: 53\n",
      "\n",
      "Number of units: 9670\n",
      "train loss: 0.004877267150747002, at epoch: 54\n",
      "\n",
      "Number of units: 9680\n",
      "train loss: 0.004689201021517419, at epoch: 54\n",
      "\n",
      "Number of units: 9690\n",
      "train loss: 0.004345445348319572, at epoch: 56\n",
      "\n",
      "Number of units: 9700\n",
      "train loss: 0.004912279568283111, at epoch: 54\n",
      "\n",
      "Number of units: 9710\n",
      "train loss: 0.004928974053515276, at epoch: 53\n",
      "\n",
      "Number of units: 9720\n",
      "train loss: 0.004937650062474859, at epoch: 52\n",
      "\n",
      "Number of units: 9730\n",
      "train loss: 0.004304882385886799, at epoch: 54\n",
      "\n",
      "Number of units: 9740\n",
      "train loss: 0.00451863076524603, at epoch: 55\n",
      "\n",
      "Number of units: 9750\n",
      "train loss: 0.004866893220615794, at epoch: 54\n",
      "\n",
      "Number of units: 9760\n",
      "train loss: 0.004795109233971289, at epoch: 54\n",
      "\n",
      "Number of units: 9770\n",
      "train loss: 0.004653426504423805, at epoch: 53\n",
      "\n",
      "Number of units: 9780\n",
      "train loss: 0.004584069930428996, at epoch: 54\n",
      "\n",
      "Number of units: 9790\n",
      "train loss: 0.004991194246999839, at epoch: 51\n",
      "\n",
      "Number of units: 9800\n",
      "train loss: 0.0049678161238097115, at epoch: 53\n",
      "\n",
      "Number of units: 9810\n",
      "train loss: 0.0045930366562890864, at epoch: 54\n",
      "\n",
      "Number of units: 9820\n",
      "train loss: 0.004654273273198442, at epoch: 53\n",
      "\n",
      "Number of units: 9830\n",
      "train loss: 0.004682954763038652, at epoch: 54\n",
      "\n",
      "Number of units: 9840\n",
      "train loss: 0.0049438984268999776, at epoch: 53\n",
      "\n",
      "Number of units: 9850\n",
      "train loss: 0.004913056589366534, at epoch: 53\n",
      "\n",
      "Number of units: 9860\n",
      "train loss: 0.004571169059285012, at epoch: 53\n",
      "\n",
      "Number of units: 9870\n",
      "train loss: 0.004957172296319073, at epoch: 53\n",
      "\n",
      "Number of units: 9880\n",
      "train loss: 0.004986971044859274, at epoch: 52\n",
      "\n",
      "Number of units: 9890\n",
      "train loss: 0.004674562657780826, at epoch: 53\n",
      "\n",
      "Number of units: 9900\n",
      "train loss: 0.004654364915667202, at epoch: 53\n",
      "\n",
      "Number of units: 9910\n",
      "train loss: 0.0049193412809950135, at epoch: 54\n",
      "\n",
      "Number of units: 9920\n",
      "train loss: 0.004892866837292331, at epoch: 52\n",
      "\n",
      "Number of units: 9930\n",
      "train loss: 0.0046772852556659925, at epoch: 53\n",
      "\n",
      "Number of units: 9940\n",
      "train loss: 0.004896491203560345, at epoch: 53\n",
      "\n",
      "Number of units: 9950\n",
      "train loss: 0.0046647992698791545, at epoch: 54\n",
      "\n",
      "Number of units: 9960\n",
      "train loss: 0.00487890004333849, at epoch: 53\n",
      "\n",
      "Number of units: 9970\n",
      "train loss: 0.004935346059155847, at epoch: 56\n",
      "\n",
      "Number of units: 9980\n",
      "train loss: 0.00445478499068713, at epoch: 54\n",
      "\n",
      "Number of units: 9990\n",
      "train loss: 0.004807852830444972, at epoch: 52\n",
      "\n",
      "Number of units: 10000\n",
      "train loss: 0.004988592867339889, at epoch: 51\n",
      "\n",
      "Number of units: 10010\n",
      "train loss: 0.004760321723071001, at epoch: 53\n",
      "\n",
      "Number of units: 10020\n",
      "train loss: 0.004891250870233534, at epoch: 53\n",
      "\n",
      "Number of units: 10030\n",
      "train loss: 0.0049636378549860185, at epoch: 52\n",
      "\n",
      "Number of units: 10040\n",
      "train loss: 0.004634831813011147, at epoch: 54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Generate synthetic dataset\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "X = np.random.rand(100, 10) # 100 datapoints of 10 features each\n",
    "y = np.random.randint(0, 2, size = 100) # binary classification labels\n",
    "\n",
    "# Initialize arrays for storing weights\n",
    "initial_weights = []\n",
    "final_weights = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "class DynamicDataset():\n",
    "    def __init__(self, data):\n",
    "        # X: (N, 9), Y: (N, 6)\n",
    "        self.X = data['X'].astype(np.float32)\n",
    "        self.Y = data['Y'].astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "#define model\n",
    "class NeuralNet(nn.Module):\n",
    "    # ---\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, units)\n",
    "        self.layer2 = nn.Linear(units, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.layer1(x))\n",
    "        x = torch.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "\n",
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        train_prediction = model.forward(features)\n",
    "        labels = labels.view(-1, 1)\n",
    "        # print(\n",
    "        #     f\"prediction: {train_prediction}, and its shape: {train_prediction.size()}\")\n",
    "        # print(f\"ground_truth: {labels}, and its shape: {labels.size()}\")\n",
    "        loss = criterion(train_prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    # print(f\"train loss: {train_loss/(i+1)}\")\n",
    "    # ---\n",
    "    train_loss /= (i + 1)\n",
    "    return train_loss\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(test_loader):\n",
    "          features = data[0]\n",
    "          labels = data[1]\n",
    "          test_prediction = model.forward(features)\n",
    "          loss = criterion(test_prediction, labels)\n",
    "          test_loss += loss.item()\n",
    "    print(f\"test loss: {test_loss/(i+1)}\\n\")\n",
    "    # ---\n",
    "    return test_loss\n",
    "\n",
    "# We are only using CPU, and GPU is not allowed.\n",
    "device = torch.device(\"cpu\")\n",
    "# torch.manual_seed(random_state)\n",
    "\n",
    "data = {\"X\":X, \"Y\":y}\n",
    "dataset = DynamicDataset(data)\n",
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=True, batch_size=batch_size)\n",
    "# The name of the directory to save all the checkpoints\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_dir = os.path.join('models', timestr)\n",
    "\n",
    "# Define the range of units in the first layer\n",
    "unit_range = np.arange(100, 10050, 10)\n",
    "\n",
    "for units in unit_range:\n",
    "    # Define the model architecture\n",
    "    print(f\"Number of units: {units}\")\n",
    "    model = NeuralNet(input_dim=10, units=units)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print initial weights\n",
    "    # initial_weights.append(model.layers[0].get_weights()[0])\n",
    "    # initial_model_copy = type(model)(input_dim=10, units=units)\n",
    "    # initial_model_copy.load_state_dict(model.state_dict())\n",
    "    # initial_layer_weights = initial_model_copy.state_dict()\n",
    "    initial_layer_weights = copy.deepcopy(model.state_dict())  # to keep it seperate from its internal pointers\n",
    "    initial_weights.append(initial_layer_weights)\n",
    "    # print(f\"initial layer weights: \\n{initial_layer_weights}\")\n",
    "    # Compile the model with a loss function and an optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    epochs = 2000\n",
    "    previous_lowest_train_loss = float('inf')\n",
    "    train_losses = []\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # print(f\"epoch number {epoch}\")\n",
    "        train_loss = train(model=model, train_loader=train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        # print(f\"train loss: {train_loss}, at epoch: {epoch}\")\n",
    "        if train_loss <= 0.005:\n",
    "            print(f\"train loss: {train_loss}, at epoch: {epoch}\\n\")\n",
    "            train_losses.append(train_loss)\n",
    "            break\n",
    "    losses.append(train_losses)\n",
    "    final_layer_weights = model.state_dict()\n",
    "    final_weights.append(final_layer_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81aef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "weights = {\"initial weights\" : initial_weights, \"final weights\": final_weights, \"losses\": losses}\n",
    "pickle.dump(weights, open( \"data_big_plus.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80034e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# data = pickle.load(open(\"results/data_big.pkl\", \"rb\"))\n",
    "# initial = data[\"initial weights\"]\n",
    "# final = data[\"final weights\"]\n",
    "# size = len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# max_weight_diffs = []\n",
    "# for i in range(size):\n",
    "#     # Compute max weight difference\n",
    "#     max_1 = torch.max(initial[i][\"layer1.weight\"] - final[i][\"layer1.weight\"])\n",
    "#     max_2 = torch.max(initial[i][\"layer2.weight\"] - final[i][\"layer2.weight\"])\n",
    "#     current_max = max(max_1, max_2)\n",
    "#     max_weight_diffs.append(current_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70fdc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# max_vals = []\n",
    "\n",
    "# for i in range(len(diff_weights)):\n",
    "#     max_vals.append(diff_weights[i])\n",
    "    \n",
    "# # set the size of the figure\n",
    "# fig, ax = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "# # create the plot\n",
    "# ax.plot(unit_range, max_vals, linestyle = '-', marker = 'o')\n",
    "\n",
    "# # set the title and axis labels\n",
    "# ax.set_title('Maximum difference in weights vs neurons')\n",
    "# ax.set_xlabel('Number of neurons')\n",
    "# ax.set_ylabel('Maximum weight difference')\n",
    "# ax.set_ylim([0, 2.5])\n",
    "# ax.set_xlim([100, 1000])\n",
    "\n",
    "# # calculate line of best fit\n",
    "# coefficients = np.polyfit(unit_range, max_vals, 2)\n",
    "# line_of_best_fit = coefficients[0] * unit_range**2 + coefficients[1] * unit_range + coefficients[2]\n",
    "\n",
    "# # plot line of best fit \n",
    "# ax.plot(unit_range, line_of_best_fit, linestyle = '--', color = 'red')\n",
    "\n",
    "# # display the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52bd086",
   "metadata": {},
   "source": [
    "Personal progress:\n",
    "- reimplement code in pytorch\n",
    "- added early stoping at training loss of 0.005\n",
    "- added data saving in pickle file format for futher processing\n",
    "- implemented Frobenius norm of layer weights and unit calculation to plot results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaf90f7e",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- classify bound of significant movement on synthetic data\n",
    "- 2 layer neural nets\n",
    "- find network under our bound of significance of lazy training\n",
    "- take that network\n",
    "- add depth\n",
    "- find how many neurons we can narrow it by with 2 layers instead of 1\n",
    "- switch to MNIST and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3690c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open(\"results/data_big_plus.pkl\", \"rb\"))\n",
    "initial = data[\"initial weights\"]\n",
    "final = data[\"final weights\"]\n",
    "losses = data[\"\"]\n",
    "size = len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b08296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4628d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "norms = []\n",
    "for i in range(size):\n",
    "    # Compute Frobenius norm between A and B\n",
    "    fro_norm_1 = torch.norm(\n",
    "        initial[i][\"layer1.weight\"]-final[i][\"layer1.weight\"], p='fro')\n",
    "    fro_norm_2 = torch.norm(\n",
    "        initial[i][\"layer2.weight\"]-final[i][\"layer2.weight\"], p='fro')\n",
    "    fro_norm = fro_norm_1 + fro_norm_2\n",
    "    norms.append(fro_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2964bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "unit_range = np.arange(100, 10050, 10)\n",
    "for units in unit_range:\n",
    "    norms[count] = norms[count] / units \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6504938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the size of the figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# create the plot\n",
    "ax.plot(unit_range, norms, linestyle='-', marker='o')\n",
    "\n",
    "# set the title and axis labels\n",
    "ax.set_title('Euclidian distance between the initial and final weights vs number of neurons')\n",
    "ax.set_xlabel('Number of neurons')\n",
    "ax.set_ylabel('Euclidian distance between the initial and final weights')\n",
    "\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4aaa384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.01515685\n",
      "Median: 0.006108641\n",
      "Variance: 0.0009900859\n",
      "Standard deviation: 0.03146563\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbWklEQVR4nO3de7zldV3v8ddbEFBULjLOIYYc0AnDvOFoqJUamYLpUBlhKgNxGku6qKdHklrZKXtojxShDCPxOHgD5BxlKupEeDtUCMMlCNAYEJwZbhPKHSHgc/5Y3/1zsdl7z9oz+7f2nuH1fDzWY31/39/ts35r1n7P77J+K1WFJEkAj5vvAiRJC4ehIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAp6lCRXJnnFfNcxn5L8bJL1Se5O8oKe1rE0SSXZsYdlvzvJx+d6udr+GQqPMUmuT/JTk/qOTnL+xHBVPbuqvrKZ5fT2B22B+DPg16vqSVV16eSR7bXf00Lj7iS3j7/E6VXVn1TVf5/LZSZ5RXvdfzmp//wkR8/lujR/DAUtSAsgbJ4OXLmZaZ7XQuNJVbX75JEL4DX04R7gLUmWbu2CttPts80zFPQow3sTSV6cZG2SO5PckuTDbbKvtefb2/+UX5LkcUnem+SGJLcmOS3JbkPLPaqNuy3J701az/uSnJXk00nuBI5u6/7XJLcnuSnJXyTZaWh5leRtSa5JcleSP0ryjCT/0uo9c3j6Sa9xylqT7JzkbmAH4N+SXDuL7Tax93Rskm8DX9rcNml+OcmN7TX+9qQaj09ybdtmZybZc9K6Vib5dpL/TPKeoXnfl+TTrf2KJBu24D2eyu3AJ4E/mGYbTPt6p9k+Ryf55yQntPf5uiQvbf3r2zJWDi3/sCRXtfd74/D20twwFLQ5JwInVtVTgGcAZ7b+n2jPu7f/Kf8rcHR7vBLYH3gS8BcASQ4E/hJ4E7A3sBuwz6R1rQDOAnYHPgM8BLwD2At4CXAI8LZJ87waeCFwMPA7wCnAm4F9gR8B3jjN65qy1qq6v6qe1KZ5XlU9Y9otM72XAz/captyPZOmfyWwDPhp4F35/uG93wAOb8v7AeC7wEcnzftjwAEMts3vJ/nhLah3uvd4Ou8Hfj7JAVOMO5rNv97h7QPwo8DlwFOBzwKnAy8CnsngvfyLJBPvyanAW6vqyQze3y+N9Ao1uqry8Rh6ANcDdzP4H9/E417g/EnT/FRrfw34Q2CvSctZChSw41DfecDbhoYPAP4L2BH4feBzQ+OeCDwwtJ73AV/bTO1vB74wNFzAy4aGLwbeNTT8IeAj0yxr2lqHlv3MGWop4M6hbXjS0DbZf8RtMjH9s4bG/ylwamtfDRwyNG7vKeZdMjT+QuDIoe356dZ+BbBhin8HM77HU7zmbjmtzjNa+3zg6Fm83uHtczRwzdDwc9o0i4f6bgOe39rfBt4KPGW+P0vb68M9hcemw6tq94kHj/7f97BjgR8CvpHkoiQ/M8O0PwDcMDR8A4M/BovbuPUTI6rqXgYf9mHrhweS/FCSv01yczuk9CcM9hqG3TLUvm+K4ScxtZlqHdVBQ9vxN6d5HaOsZ/2k8T/Q2k8HvtAOq9zOICQemjTvzUPte5n+9c5kNu/xhA8Cr07yvEn9s3298Oj3jKqa7n38eeAw4IYkX03ykhFq1SwYCppRVV1TVW8EnsbgD8FZSXZl8L+5yW5k8Idswg8CDzL40N8ELJkYkeQJDA4XPGJ1k4ZPBr4BLKvBoY13A9nyVzNyrVtr+HWMsp59J42/sbXXA4cOB3hV7VJVG2dZzz0M9swASLIDsKgrdvr3eFpVdRvwEeCPJo0a5fVu8a2Zq+qiqlrRav0imz/UpVkyFDSjJG9OsqiqHmZwmATgYWBTe95/aPLPAe9Isl87BvwnDA4xPMjgXMHr2knEnRgc3tjcH/gnMzhEc3eSZwG/Nkcva3O1zqVR1vN7SZ6Y5NnAMcAZrf9jwPuTPB0gyaIkK7aghv8Adkny2iSPB94L7Dwxcob3eHM+DLyUwfmBCb1t1yQ7JXlTkt2q6r8Y/NsYpU7NgqGgzXkNcGW7IudEBses72uHf94P/HM7vHEw8AngUwyOUX8L+B6Dk6VU1ZWtfTqDvYa7gVuB+2dY928DvwTcBfw13/9jORemrXWOjbKerwLrGByP/7Oq+sfWfyKwBvjHJHcBFzA4KTsrVXUHg0OEHwc2MthzGL4aacr3eITl3sng3MKeQ919b9e3ANe3w4m/yuDCBc2htJM30li1/0XezuDQ0LfmuRxJjXsKGpskr2uHSXZl8I3hKxhcBSNpgTAUNE4rGJyIvJHBdflHlruq0oLi4SNJUsc9BUlSZ5u+IdVee+1VS5cune8yJGmbcvHFF/9nVS2aatw2HQpLly5l7dq1812GJG1Tktww3TgPH0mSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOtv0N5q3xtLj/27G8dd/4LVjqkSSFg73FCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktTpLRSSHJDksqHHnUnenmTPJOcmuaY979GmT5KTkqxLcnmSg/qqTZI0td5Coaq+WVXPr6rnAy8E7gW+ABwPnFdVy4Dz2jDAocCy9lgFnNxXbZKkqY3r8NEhwLVVdQOwAljd+lcDh7f2CuC0GrgA2D3J3mOqT5LE+ELhSOBzrb24qm5q7ZuBxa29D7B+aJ4Nre8RkqxKsjbJ2k2bNvVVryQ9JvUeCkl2Al4PfH7yuKoqoGazvKo6paqWV9XyRYsWzVGVkiQYz57CocAlVXVLG75l4rBQe7619W8E9h2ab0nrkySNyThC4Y18/9ARwBpgZWuvBM4e6j+qXYV0MHDH0GEmSdIY9Pp7Ckl2BV4FvHWo+wPAmUmOBW4Ajmj95wCHAesYXKl0TJ+1SZIerddQqKp7gKdO6ruNwdVIk6ct4Lg+65EkzcxvNEuSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOr2GQpLdk5yV5BtJrk7ykiR7Jjk3yTXteY82bZKclGRdksuTHNRnbZKkR+t7T+FE4B+q6lnA84CrgeOB86pqGXBeGwY4FFjWHquAk3uuTZI0SW+hkGQ34CeAUwGq6oGquh1YAaxuk60GDm/tFcBpNXABsHuSvfuqT5L0aH3uKewHbAL+V5JLk3w8ya7A4qq6qU1zM7C4tfcB1g/Nv6H1PUKSVUnWJlm7adOmHsuXpMeePkNhR+Ag4OSqegFwD98/VARAVRVQs1loVZ1SVcuravmiRYvmrFhJUr+hsAHYUFVfb8NnMQiJWyYOC7XnW9v4jcC+Q/MvaX2SpDHpLRSq6mZgfZIDWtchwFXAGmBl61sJnN3aa4Cj2lVIBwN3DB1mkiSNwY49L/83gM8k2Qm4DjiGQRCdmeRY4AbgiDbtOcBhwDrg3jatJGmMeg2FqroMWD7FqEOmmLaA4/qsR5I0M7/RLEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq9BoKSa5PckWSy5KsbX17Jjk3yTXteY/WnyQnJVmX5PIkB/VZmyTp0caxp/DKqnp+VS1vw8cD51XVMuC8NgxwKLCsPVYBJ4+hNknSkPk4fLQCWN3aq4HDh/pPq4ELgN2T7D0P9UnSY1bfoVDAPya5OMmq1re4qm5q7ZuBxa29D7B+aN4Nre8RkqxKsjbJ2k2bNvVVtyQ9Ju3Y8/J/rKo2JnkacG6SbwyPrKpKUrNZYFWdApwCsHz58lnNK0maWa97ClW1sT3fCnwBeDFwy8RhofZ8a5t8I7Dv0OxLWp8kaUx6C4UkuyZ58kQb+Gng34E1wMo22Urg7NZeAxzVrkI6GLhj6DCTJGkM+jx8tBj4QpKJ9Xy2qv4hyUXAmUmOBW4AjmjTnwMcBqwD7gWO6bE2SdIUeguFqroOeN4U/bcBh0zRX8BxfdUjSdo8v9EsSeqMFApJntN3IZKk+TfqnsJfJrkwyduS7NZrRZKkeTNSKFTVjwNvYnDJ6MVJPpvkVb1WJkkau5HPKVTVNcB7gXcBLwdOSvKNJD/XV3GSpPEa9ZzCc5OcAFwN/CTwuqr64dY+ocf6JEljNOolqX8OfBx4d1XdN9FZVTcmeW8vlUmSxm7UUHgtcF9VPQSQ5HHALlV1b1V9qrfqJEljNeo5hX8CnjA0/MTWJ0najowaCrtU1d0TA639xH5KkiTNl1FD4Z7hn8dM8kLgvhmmlyRtg0Y9p/B24PNJbgQC/DfgF/sqSpI0P0YKhaq6KMmzgANa1zer6r/6K0uSNB9mc5fUFwFL2zwHJaGqTuulKknSvBgpFJJ8CngGcBnwUOsuwFCQpO3IqHsKy4ED228eSJK2U6NeffTvDE4uS5K2Y6PuKewFXJXkQuD+ic6qen0vVUmS5sWoofC+PouQJC0Mo/6ewleB64HHt/ZFwCWjzJtkhySXJvnbNrxfkq8nWZfkjCQ7tf6d2/C6Nn7plrwgSdKWG/XW2b8CnAX8VevaB/jiiOv4LQa33J7wQeCEqnom8F3g2NZ/LPDd1n9Cm06SNEajnmg+DngZcCd0P7jztM3NlGQJgzusfrwNh8FvMJzVJlkNHN7aK9owbfwhbXpJ0piMGgr3V9UDEwNJdmTwPYXN+QjwO8DDbfipwO1V9WAb3sBgr4P2vB6gjb+jTf8ISVYlWZtk7aZNm0YsX5I0ilFD4atJ3g08of028+eBv5lphiQ/A9xaVRdvZY2PUFWnVNXyqlq+aNGiuVy0JD3mjXr10fEMjvlfAbwVOId2SGgGLwNen+QwYBfgKcCJwO5Jdmx7A0uAjW36jcC+wIa2J7IbcNssXoskaSuNevXRw1X111X1C1X1htae8fBRVf1uVS2pqqXAkcCXqupNwJeBN7TJVgJnt/aaNkwb/yW/QS1J4zXqvY++xRTnEKpq/y1Y57uA05P8MXApcGrrPxX4VJJ1wHcYBIkkaYxmc++jCbsAvwDsOepKquorwFda+zrgxVNM8722XEnSPBn18NFtQ4+NVfURBpeaSpK2I6MePjpoaPBxDPYcZvNbDJKkbcCof9g/NNR+kMEtL46Y82okSfNq1J/jfGXfhUiS5t+oh4/eOdP4qvrw3JQjSZpPs7n66EUMvksA8DrgQuCaPoqSJM2PUUNhCXBQVd0FkOR9wN9V1Zv7KkySNH6j3vtoMfDA0PADrU+StB0ZdU/hNODCJF9ow4fz/dtcS5K2E6NeffT+JH8P/HjrOqaqLu2vLEnSfBj18BHAE4E7q+pEBncy3a+nmiRJ82TUn+P8AwY3svvd1vV44NN9FSVJmh+j7in8LPB64B6AqroReHJfRUmS5seoofBA+22DAkiya38lSZLmy6ihcGaSv2Lwq2m/AvwT8Nf9lSVJmg+bvfooSYAzgGcBdwIHAL9fVef2XJskacw2GwpVVUnOqarnAAaBJG3HRj18dEmSF/VaiSRp3o0aCj8KXJDk2iSXJ7kiyeUzzZBklyQXJvm3JFcm+cPWv1+SrydZl+SMJDu1/p3b8Lo2fulWvTJJ0qzNePgoyQ9W1beBV2/Bsu8HfrKq7k7yeOD89q3odwInVNXpST4GHAuc3J6/W1XPTHIk8EHgF7dgvZKkLbS5PYUvAlTVDcCHq+qG4cdMM9bA3W3w8e1RwE8CZ7X+1QzuowSwgu/fT+ks4JB2kluSNCabC4XhP8r7z3bhSXZIchlwK4OT1NcCt1fVg22SDcA+rb0PsB6gjb8DeOps1ylJ2nKbC4Wapj2Sqnqoqp7P4PcYXszgstatkmRVkrVJ1m7atGlrFydJGrK5UHhekjuT3AU8t7XvTHJXkjtHXUlV3Q58GXgJgy/ATZzLWAJsbO2NwL4AbfxuwG1TLOuUqlpeVcsXLVo0agmSpBHMGApVtUNVPaWqnlxVO7b2xPBTZpo3yaIku7f2E4BXAVczCIc3tMlWAme39po2TBv/pXZrDUnSmIz6IztbYm9gdZIdGITPmVX1t0muAk5P8sfApcCpbfpTgU8lWQd8Bziyx9okSVPoLRSq6nLgBVP0X8fg/MLk/u8Bv9BXPZKkzZvNj+xIkrZzhoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6vYVCkn2TfDnJVUmuTPJbrX/PJOcmuaY979H6k+SkJOuSXJ7koL5qkyRNrc89hQeB/1FVBwIHA8clORA4HjivqpYB57VhgEOBZe2xCji5x9okSVPoLRSq6qaquqS17wKuBvYBVgCr22SrgcNbewVwWg1cAOyeZO++6pMkPdpYzikkWQq8APg6sLiqbmqjbgYWt/Y+wPqh2Ta0vsnLWpVkbZK1mzZt6q9oSXoM6j0UkjwJ+N/A26vqzuFxVVVAzWZ5VXVKVS2vquWLFi2aw0olSb2GQpLHMwiEz1TV/2ndt0wcFmrPt7b+jcC+Q7MvaX2SpDHp8+qjAKcCV1fVh4dGrQFWtvZK4Oyh/qPaVUgHA3cMHWaSJI3Bjj0u+2XAW4ArklzW+t4NfAA4M8mxwA3AEW3cOcBhwDrgXuCYHmuTJE2ht1CoqvOBTDP6kCmmL+C4vuqRJG2e32iWJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHV6+43mJJ8Afga4tap+pPXtCZwBLAWuB46oqu8mCXAicBhwL3B0VV3SV22jWHr83804/voPvHZMlUjS+PS5p/BJ4DWT+o4HzquqZcB5bRjgUGBZe6wCTu6xLknSNHoLhar6GvCdSd0rgNWtvRo4fKj/tBq4ANg9yd591SZJmtq4zyksrqqbWvtmYHFr7wOsH5puQ+t7lCSrkqxNsnbTpk39VSpJj0HzdqK5qgqoLZjvlKpaXlXLFy1a1ENlkvTYNe5QuGXisFB7vrX1bwT2HZpuSeuTJI3RuENhDbCytVcCZw/1H5WBg4E7hg4zSZLGpM9LUj8HvALYK8kG4A+ADwBnJjkWuAE4ok1+DoPLUdcxuCT1mL7qkiRNr7dQqKo3TjPqkCmmLeC4vmqRJI3GbzRLkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp09ttLrZ3M/1cpz/VKWlb5Z6CJKljKEiSOoaCJKljKEiSOp5o7sFMJ6HBE9GSFi73FCRJHUNBktTx8NE88DsOkhaqBRUKSV4DnAjsAHy8qj4wzyWNnecjJM2nBRMKSXYAPgq8CtgAXJRkTVVdNb+VLSybC42tYeBIWjChALwYWFdV1wEkOR1YARgKY9Jn4MyXrQk699r0WLSQQmEfYP3Q8AbgRydPlGQVsKoN3p3km7Ncz17Af25RheO1rdQJC7jWfPBRXXNW6xTLnksLdptOwVrnXt91Pn26EQspFEZSVacAp2zp/EnWVtXyOSypF9tKnWCtfdhW6gRr7cN81rmQLkndCOw7NLyk9UmSxmQhhcJFwLIk+yXZCTgSWDPPNUnSY8qCOXxUVQ8m+XXg/zK4JPUTVXVlD6va4kNPY7at1AnW2odtpU6w1j7MW52pqvlatyRpgVlIh48kSfPMUJAkdbabUEjymiTfTLIuyfFTjN85yRlt/NeTLB0a97ut/5tJXr1Qa02yNMl9SS5rj48tgFp/IsklSR5M8oZJ41YmuaY9Vi7gOh8a2qa9X9wwQq3vTHJVksuTnJfk6UPjxrZN56DWsW3XEer81SRXtFrOT3Lg0LiF9vmfstaxff6rapt/MDgxfS2wP7AT8G/AgZOmeRvwsdY+EjijtQ9s0+8M7NeWs8MCrXUp8O8LbLsuBZ4LnAa8Yah/T+C69rxHa++x0Ops4+5eYNv0lcATW/vXht7/sW3Tra11nNt1xDqfMtR+PfAPrb0QP//T1TqWz//2sqfQ3SKjqh4AJm6RMWwFsLq1zwIOSZLWf3pV3V9V3wLWteUtxFrHbbO1VtX1VXU58PCkeV8NnFtV36mq7wLnAq9ZgHWO2yi1frmq7m2DFzD4zg6Md5tuba3jNEqddw4N7gpMXGGz4D7/M9Q6FttLKEx1i4x9ppumqh4E7gCeOuK8c2lragXYL8mlSb6a5Md7rHPUWvuYd7a2dl27JFmb5IIkh89pZY8221qPBf5+C+fdWltTK4xvu45UZ5LjklwL/Cnwm7OZdw5tTa0whs//gvmegkZyE/CDVXVbkhcCX0zy7En/s9DsPb2qNibZH/hSkiuq6tr5LirJm4HlwMvnu5bNmabWBbVdq+qjwEeT/BLwXqD3czJbappax/L53172FEa5RUY3TZIdgd2A20acdy5tca1tF/c2gKq6mMGxyR+a51r7mHe2tmpdVbWxPV8HfAV4wVwWN8lItSb5KeA9wOur6v7ZzDuHtqbWcW7X2W6X04HDt3DerbXFtY7t89/3SYtxPBjs8VzH4ETRxMmbZ0+a5jgeefL2zNZ+No880XQd/Z5o2ppaF03UxuBE1UZgz/msdWjaT/LoE83fYnBCdI/W7qXWraxzD2Dn1t4LuIZJJ/7m4f1/AYMP/LJJ/WPbpnNQ69i264h1Lhtqvw5Y29oL8fM/Xa1j+fz38sLn4wEcBvxH+wf6ntb3Pxn87wVgF+DzDE4kXQjsPzTve9p83wQOXai1Aj8PXAlcBlwCvG4B1PoiBsdF72Gw53Xl0Ly/3F7DOuCYhVgn8FLgivbhvAI4dgFs038Cbmnv82XAmvnYpltT67i36wh1njj02fkyQ3+IF+Dnf8pax/X59zYXkqTO9nJOQZI0BwwFSVLHUJAkdQwFSVLHUJAkdQwFaQRJKsmHhoZ/O8n75rEkqReGgjSa+4GfS7LXlszcvpkuLXj+Q5VG8yCD3819B4MvO3Uy+L2LTzD45u4mBl8q+3aSTwLfY/Ct339OsidwXxt+GoMvoh0FvAT4elUdPY4XIs3EPQVpdB8F3pRkt0n9fw6srqrnAp8BThoatwR4aVW9sw3vwSAE3gGsAU5gcKuF5yR5fo+1SyMxFKQR1eBulKfxyFsZw+CP/Gdb+1PAjw2N+3xVPTQ0/Dc1uI3AFcAtVXVFVT3M4PYFS3spXJoFQ0GanY8w+N2AXUec/p5JwxN3EX14qD0x7OFczTtDQZqFqvoOcCaDYJjwLwzuZgvwJuD/jbsuaa4YCtLsfYjBSeUJvwEck+Ry4C3Ab81LVdIc8C6pkqSOewqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpM7/B219RWYQtysKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a large set of Frobenius norms\n",
    "# norms = np.random.normal(loc=10, scale=2, size=10000)\n",
    "norms = np.array(norms)\n",
    "\n",
    "\n",
    "# Compute descriptive statistics\n",
    "mean_norm = np.mean(norms)\n",
    "median_norm = np.median(norms)\n",
    "var_norm = np.var(norms)\n",
    "std_norm = np.std(norms)\n",
    "\n",
    "# Print descriptive statistics\n",
    "print('Mean:', mean_norm)\n",
    "print('Median:', median_norm)\n",
    "print('Variance:', var_norm)\n",
    "print('Standard deviation:', std_norm)\n",
    "\n",
    "# Plot a histogram of the Frobenius norms\n",
    "plt.hist(norms, bins=40)\n",
    "plt.title('Histogram of Frobenius Norms')\n",
    "plt.xlabel('Norm')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbcc5109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lower Bound  Upper Bound  number of neurons\n",
      "0        0.110        0.360                100\n",
      "1        0.110        0.360                300\n",
      "2        0.015        0.110                310\n",
      "3        0.015        0.110               2050\n",
      "4        0.000        0.015               2010\n",
      "5        0.000        0.015              10040\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "lb1 = 0.11\n",
    "ub1 = 0.36\n",
    "idx_1 = np.where((norms > lb1) & (norms < ub1))[0]\n",
    "translated_idx_1 = unit_range[idx_1]\n",
    "\n",
    "lb2 = 0.015\n",
    "ub2 = 0.11\n",
    "idx_2 = np.where((norms > lb2) & (norms < ub2))[0]\n",
    "translated_idx_2 = unit_range[idx_2]\n",
    "\n",
    "lb3 = 0.0\n",
    "ub3 = 0.015\n",
    "idx_3 = np.where((norms > lb3) & (norms < ub3))[0]\n",
    "translated_idx_3 = unit_range[idx_3]\n",
    "\n",
    "# Create a table of threshold values and corresponding indices\n",
    "lower_bound = []\n",
    "upper_bound = []\n",
    "translated_idx = []\n",
    "def fill_bounds(lb, ub, translate):\n",
    "    for i, val in enumerate(translate):\n",
    "        if i == 0:\n",
    "            lower_bound.append(lb)\n",
    "            upper_bound.append(ub)\n",
    "            translated_idx.append(val)\n",
    "        elif i == len(translate) - 1:\n",
    "            lower_bound.append(lb)\n",
    "            upper_bound.append(ub)\n",
    "            translated_idx.append(val)\n",
    "\n",
    "fill_bounds(lb1, ub1, translated_idx_1)\n",
    "fill_bounds(lb2, ub2, translated_idx_2)\n",
    "fill_bounds(lb3, ub3, translated_idx_3)\n",
    "df = pd.DataFrame({'Lower Bound': lower_bound,\n",
    "                  'Upper Bound': upper_bound, 'number of neurons': translated_idx})\n",
    "\n",
    "# Print the table\n",
    "print(df)\n",
    "\n",
    "# set the size of the figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# create the plot\n",
    "ax.plot(unit_range, norms, linestyle='-', marker='o')\n",
    "ax.plot(translated_idx_1, norms[idx_1], 'ro')\n",
    "ax.plot(translated_idx_2, norms[idx_2], 'go')\n",
    "ax.plot(translated_idx_3, norms[idx_3], 'yo')\n",
    "# set the title and axis labels\n",
    "ax.set_title('Segmented Euclidian distances vs number of neurons')\n",
    "ax.set_xlabel('Number of neurons')\n",
    "ax.set_ylabel('Segmented Euclidian distances')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9db8a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the first-order differences\n",
    "diffs = np.diff(norms)\n",
    "\n",
    "# Plot the norms and differences\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "ax[0].plot(norms)\n",
    "ax[0].set_ylabel('Norm')\n",
    "ax[0].set_title('Frobenius Norms')\n",
    "ax[1].plot(diffs)\n",
    "ax[1].set_ylabel('Difference')\n",
    "ax[1].set_xlabel('Index')\n",
    "ax[1].set_title('First-order Differences')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
