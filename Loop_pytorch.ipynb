{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb7da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of units: 100\n",
      "train loss: 0.004721559379502338, at epoch: 329\n",
      "\n",
      "Number of units: 110\n",
      "train loss: 0.0047632742333973965, at epoch: 320\n",
      "\n",
      "Number of units: 120\n",
      "train loss: 0.004850271885238726, at epoch: 344\n",
      "\n",
      "Number of units: 130\n",
      "train loss: 0.004852562177304804, at epoch: 312\n",
      "\n",
      "Number of units: 140\n",
      "train loss: 0.004703225292184925, at epoch: 299\n",
      "\n",
      "Number of units: 150\n",
      "train loss: 0.004902697014192086, at epoch: 284\n",
      "\n",
      "Number of units: 160\n",
      "train loss: 0.004759163043708838, at epoch: 282\n",
      "\n",
      "Number of units: 170\n",
      "train loss: 0.00488559928937093, at epoch: 259\n",
      "\n",
      "Number of units: 180\n",
      "train loss: 0.004743049303292537, at epoch: 263\n",
      "\n",
      "Number of units: 190\n",
      "train loss: 0.004710286336493254, at epoch: 239\n",
      "\n",
      "Number of units: 200\n",
      "train loss: 0.004941364534004151, at epoch: 252\n",
      "\n",
      "Number of units: 210\n",
      "train loss: 0.004923039954807109, at epoch: 237\n",
      "\n",
      "Number of units: 220\n",
      "train loss: 0.004862780243781231, at epoch: 258\n",
      "\n",
      "Number of units: 230\n",
      "train loss: 0.004839528424322452, at epoch: 230\n",
      "\n",
      "Number of units: 240\n",
      "train loss: 0.004660603053891634, at epoch: 212\n",
      "\n",
      "Number of units: 250\n",
      "train loss: 0.0048783369149759895, at epoch: 225\n",
      "\n",
      "Number of units: 260\n",
      "train loss: 0.004237614620258939, at epoch: 208\n",
      "\n",
      "Number of units: 270\n",
      "train loss: 0.004564226618676912, at epoch: 212\n",
      "\n",
      "Number of units: 280\n",
      "train loss: 0.004833363249908871, at epoch: 203\n",
      "\n",
      "Number of units: 290\n",
      "train loss: 0.004638763364411034, at epoch: 204\n",
      "\n",
      "Number of units: 300\n",
      "train loss: 0.004784705962613316, at epoch: 195\n",
      "\n",
      "Number of units: 310\n",
      "train loss: 0.004864920843747313, at epoch: 193\n",
      "\n",
      "Number of units: 320\n",
      "train loss: 0.004541547881701718, at epoch: 199\n",
      "\n",
      "Number of units: 330\n",
      "train loss: 0.004998017366398244, at epoch: 195\n",
      "\n",
      "Number of units: 340\n",
      "train loss: 0.004731397154001513, at epoch: 190\n",
      "\n",
      "Number of units: 350\n",
      "train loss: 0.004517914185603473, at epoch: 186\n",
      "\n",
      "Number of units: 360\n",
      "train loss: 0.004902491907459989, at epoch: 179\n",
      "\n",
      "Number of units: 370\n",
      "train loss: 0.004688889476620375, at epoch: 185\n",
      "\n",
      "Number of units: 380\n",
      "train loss: 0.0046335024656718815, at epoch: 173\n",
      "\n",
      "Number of units: 390\n",
      "train loss: 0.0049059306621188625, at epoch: 174\n",
      "\n",
      "Number of units: 400\n",
      "train loss: 0.004646465910483073, at epoch: 173\n",
      "\n",
      "Number of units: 410\n",
      "train loss: 0.004916373084825239, at epoch: 177\n",
      "\n",
      "Number of units: 420\n",
      "train loss: 0.004670909982205557, at epoch: 167\n",
      "\n",
      "Number of units: 430\n",
      "train loss: 0.004612004198975228, at epoch: 168\n",
      "\n",
      "Number of units: 440\n",
      "train loss: 0.004852690658476036, at epoch: 167\n",
      "\n",
      "Number of units: 450\n",
      "train loss: 0.00493575325119366, at epoch: 164\n",
      "\n",
      "Number of units: 460\n",
      "train loss: 0.004992688079782965, at epoch: 158\n",
      "\n",
      "Number of units: 470\n",
      "train loss: 0.004900042796218145, at epoch: 159\n",
      "\n",
      "Number of units: 480\n",
      "train loss: 0.004938172215557018, at epoch: 158\n",
      "\n",
      "Number of units: 490\n",
      "train loss: 0.00460888948702177, at epoch: 164\n",
      "\n",
      "Number of units: 500\n",
      "train loss: 0.004950926628976049, at epoch: 151\n",
      "\n",
      "Number of units: 510\n",
      "train loss: 0.004993453857980512, at epoch: 152\n",
      "\n",
      "Number of units: 520\n",
      "train loss: 0.004776962251503676, at epoch: 153\n",
      "\n",
      "Number of units: 530\n",
      "train loss: 0.004929358607992072, at epoch: 151\n",
      "\n",
      "Number of units: 540\n",
      "train loss: 0.004767432084236134, at epoch: 146\n",
      "\n",
      "Number of units: 550\n",
      "train loss: 0.00494633239150744, at epoch: 155\n",
      "\n",
      "Number of units: 560\n",
      "train loss: 0.004953934761893066, at epoch: 151\n",
      "\n",
      "Number of units: 570\n",
      "train loss: 0.00495124568848496, at epoch: 145\n",
      "\n",
      "Number of units: 580\n",
      "train loss: 0.004970736102391129, at epoch: 144\n",
      "\n",
      "Number of units: 590\n",
      "train loss: 0.004645118882788779, at epoch: 142\n",
      "\n",
      "Number of units: 600\n",
      "train loss: 0.00452923749662773, at epoch: 147\n",
      "\n",
      "Number of units: 610\n",
      "train loss: 0.004845808181805751, at epoch: 146\n",
      "\n",
      "Number of units: 620\n",
      "train loss: 0.004494868535336991, at epoch: 144\n",
      "\n",
      "Number of units: 630\n",
      "train loss: 0.00491359718827539, at epoch: 147\n",
      "\n",
      "Number of units: 640\n",
      "train loss: 0.004480838926984631, at epoch: 142\n",
      "\n",
      "Number of units: 650\n",
      "train loss: 0.0045223165956861065, at epoch: 137\n",
      "\n",
      "Number of units: 660\n",
      "train loss: 0.004777449176236815, at epoch: 132\n",
      "\n",
      "Number of units: 670\n",
      "train loss: 0.004923125578521024, at epoch: 142\n",
      "\n",
      "Number of units: 680\n",
      "train loss: 0.004748784050893846, at epoch: 133\n",
      "\n",
      "Number of units: 690\n",
      "train loss: 0.0047383259377512844, at epoch: 137\n",
      "\n",
      "Number of units: 700\n",
      "train loss: 0.004818855885360733, at epoch: 132\n",
      "\n",
      "Number of units: 710\n",
      "train loss: 0.004974269386657539, at epoch: 133\n",
      "\n",
      "Number of units: 720\n",
      "train loss: 0.00496568470880959, at epoch: 131\n",
      "\n",
      "Number of units: 730\n",
      "train loss: 0.004843828288042005, at epoch: 140\n",
      "\n",
      "Number of units: 740\n",
      "train loss: 0.004539050241106111, at epoch: 139\n",
      "\n",
      "Number of units: 750\n",
      "train loss: 0.004354449445162345, at epoch: 135\n",
      "\n",
      "Number of units: 760\n",
      "train loss: 0.0047158002962504495, at epoch: 131\n",
      "\n",
      "Number of units: 770\n",
      "train loss: 0.00477669774535002, at epoch: 127\n",
      "\n",
      "Number of units: 780\n",
      "train loss: 0.004955884269401167, at epoch: 130\n",
      "\n",
      "Number of units: 790\n",
      "train loss: 0.004755533410193493, at epoch: 134\n",
      "\n",
      "Number of units: 800\n",
      "train loss: 0.004630460174780637, at epoch: 134\n",
      "\n",
      "Number of units: 810\n",
      "train loss: 0.004654282768424594, at epoch: 129\n",
      "\n",
      "Number of units: 820\n",
      "train loss: 0.004722449775706536, at epoch: 130\n",
      "\n",
      "Number of units: 830\n",
      "train loss: 0.004726322350643386, at epoch: 127\n",
      "\n",
      "Number of units: 840\n",
      "train loss: 0.004604403127079877, at epoch: 127\n",
      "\n",
      "Number of units: 850\n",
      "train loss: 0.004850495816751277, at epoch: 121\n",
      "\n",
      "Number of units: 860\n",
      "train loss: 0.004852133599817421, at epoch: 122\n",
      "\n",
      "Number of units: 870\n",
      "train loss: 0.004617265278380387, at epoch: 128\n",
      "\n",
      "Number of units: 880\n",
      "train loss: 0.004499525344264157, at epoch: 125\n",
      "\n",
      "Number of units: 890\n",
      "train loss: 0.004628462679033873, at epoch: 122\n",
      "\n",
      "Number of units: 900\n",
      "train loss: 0.004890818608628251, at epoch: 122\n",
      "\n",
      "Number of units: 910\n",
      "train loss: 0.004981745952996448, at epoch: 120\n",
      "\n",
      "Number of units: 920\n",
      "train loss: 0.004836352424972574, at epoch: 120\n",
      "\n",
      "Number of units: 930\n",
      "train loss: 0.004652888038482104, at epoch: 119\n",
      "\n",
      "Number of units: 940\n",
      "train loss: 0.004661171143180241, at epoch: 122\n",
      "\n",
      "Number of units: 950\n",
      "train loss: 0.004782832163715227, at epoch: 119\n",
      "\n",
      "Number of units: 960\n",
      "train loss: 0.004901783932728563, at epoch: 121\n",
      "\n",
      "Number of units: 970\n",
      "train loss: 0.004933578039246243, at epoch: 116\n",
      "\n",
      "Number of units: 980\n",
      "train loss: 0.004750086253607293, at epoch: 121\n",
      "\n",
      "Number of units: 990\n",
      "train loss: 0.004838946026148107, at epoch: 118\n",
      "\n",
      "Number of units: 1000\n",
      "train loss: 0.004986256676057792, at epoch: 115\n",
      "\n",
      "Number of units: 1010\n",
      "train loss: 0.004688433985035659, at epoch: 118\n",
      "\n",
      "Number of units: 1020\n",
      "train loss: 0.004955805199575849, at epoch: 115\n",
      "\n",
      "Number of units: 1030\n",
      "train loss: 0.004773887666501792, at epoch: 114\n",
      "\n",
      "Number of units: 1040\n",
      "train loss: 0.004806964968302339, at epoch: 116\n",
      "\n",
      "Number of units: 1050\n",
      "train loss: 0.004714160279838921, at epoch: 111\n",
      "\n",
      "Number of units: 1060\n",
      "train loss: 0.004830296780662593, at epoch: 114\n",
      "\n",
      "Number of units: 1070\n",
      "train loss: 0.004783660587743838, at epoch: 109\n",
      "\n",
      "Number of units: 1080\n",
      "train loss: 0.004535086580133907, at epoch: 113\n",
      "\n",
      "Number of units: 1090\n",
      "train loss: 0.004754968873451162, at epoch: 111\n",
      "\n",
      "Number of units: 1100\n",
      "train loss: 0.00487310233423841, at epoch: 115\n",
      "\n",
      "Number of units: 1110\n",
      "train loss: 0.004935352044028605, at epoch: 112\n",
      "\n",
      "Number of units: 1120\n",
      "train loss: 0.0049621261429230405, at epoch: 114\n",
      "\n",
      "Number of units: 1130\n",
      "train loss: 0.004015706187583418, at epoch: 115\n",
      "\n",
      "Number of units: 1140\n",
      "train loss: 0.004815984069088017, at epoch: 112\n",
      "\n",
      "Number of units: 1150\n",
      "train loss: 0.004746460951787554, at epoch: 112\n",
      "\n",
      "Number of units: 1160\n",
      "train loss: 0.004845191832612841, at epoch: 110\n",
      "\n",
      "Number of units: 1170\n",
      "train loss: 0.004536953446061318, at epoch: 112\n",
      "\n",
      "Number of units: 1180\n",
      "train loss: 0.004805517964568935, at epoch: 109\n",
      "\n",
      "Number of units: 1190\n",
      "train loss: 0.004669985547544116, at epoch: 110\n",
      "\n",
      "Number of units: 1200\n",
      "train loss: 0.004745099251396709, at epoch: 109\n",
      "\n",
      "Number of units: 1210\n",
      "train loss: 0.004984797351335715, at epoch: 111\n",
      "\n",
      "Number of units: 1220\n",
      "train loss: 0.004866791928862426, at epoch: 108\n",
      "\n",
      "Number of units: 1230\n",
      "train loss: 0.004591817200675905, at epoch: 108\n",
      "\n",
      "Number of units: 1240\n",
      "train loss: 0.0048029855718051805, at epoch: 108\n",
      "\n",
      "Number of units: 1250\n",
      "train loss: 0.0040771544235155945, at epoch: 108\n",
      "\n",
      "Number of units: 1260\n",
      "train loss: 0.004843641484551426, at epoch: 105\n",
      "\n",
      "Number of units: 1270\n",
      "train loss: 0.004747966068810569, at epoch: 108\n",
      "\n",
      "Number of units: 1280\n",
      "train loss: 0.004902554010614608, at epoch: 104\n",
      "\n",
      "Number of units: 1290\n",
      "train loss: 0.004569931088481241, at epoch: 110\n",
      "\n",
      "Number of units: 1300\n",
      "train loss: 0.0046512092937490476, at epoch: 110\n",
      "\n",
      "Number of units: 1310\n",
      "train loss: 0.0049597866158717354, at epoch: 106\n",
      "\n",
      "Number of units: 1320\n",
      "train loss: 0.004996439990379144, at epoch: 103\n",
      "\n",
      "Number of units: 1330\n",
      "train loss: 0.004996552349612671, at epoch: 105\n",
      "\n",
      "Number of units: 1340\n",
      "train loss: 0.004742289927992403, at epoch: 105\n",
      "\n",
      "Number of units: 1350\n",
      "train loss: 0.004974174165955105, at epoch: 102\n",
      "\n",
      "Number of units: 1360\n",
      "train loss: 0.004784006133723011, at epoch: 104\n",
      "\n",
      "Number of units: 1370\n",
      "train loss: 0.0048876476558780265, at epoch: 106\n",
      "\n",
      "Number of units: 1380\n",
      "train loss: 0.004998655468959327, at epoch: 101\n",
      "\n",
      "Number of units: 1390\n",
      "train loss: 0.004784811629875492, at epoch: 104\n",
      "\n",
      "Number of units: 1400\n",
      "train loss: 0.004846136231184346, at epoch: 101\n",
      "\n",
      "Number of units: 1410\n",
      "train loss: 0.004918065663421772, at epoch: 103\n",
      "\n",
      "Number of units: 1420\n",
      "train loss: 0.004775028526415212, at epoch: 102\n",
      "\n",
      "Number of units: 1430\n",
      "train loss: 0.004831917118295905, at epoch: 103\n",
      "\n",
      "Number of units: 1440\n",
      "train loss: 0.004726272124021307, at epoch: 102\n",
      "\n",
      "Number of units: 1450\n",
      "train loss: 0.004905066254725626, at epoch: 103\n",
      "\n",
      "Number of units: 1460\n",
      "train loss: 0.004607032051010833, at epoch: 103\n",
      "\n",
      "Number of units: 1470\n",
      "train loss: 0.0047772883493564676, at epoch: 99\n",
      "\n",
      "Number of units: 1480\n",
      "train loss: 0.004052751683254883, at epoch: 105\n",
      "\n",
      "Number of units: 1490\n",
      "train loss: 0.004809800292464388, at epoch: 99\n",
      "\n",
      "Number of units: 1500\n",
      "train loss: 0.004855662779557406, at epoch: 99\n",
      "\n",
      "Number of units: 1510\n",
      "train loss: 0.004818966026506075, at epoch: 100\n",
      "\n",
      "Number of units: 1520\n",
      "train loss: 0.004748099033986933, at epoch: 100\n",
      "\n",
      "Number of units: 1530\n",
      "train loss: 0.004686465537175764, at epoch: 99\n",
      "\n",
      "Number of units: 1540\n",
      "train loss: 0.004561788247238496, at epoch: 97\n",
      "\n",
      "Number of units: 1550\n",
      "train loss: 0.004452117795854065, at epoch: 99\n",
      "\n",
      "Number of units: 1560\n",
      "train loss: 0.004792971344817829, at epoch: 97\n",
      "\n",
      "Number of units: 1570\n",
      "train loss: 0.004909147887338463, at epoch: 99\n",
      "\n",
      "Number of units: 1580\n",
      "train loss: 0.004699898735671013, at epoch: 99\n",
      "\n",
      "Number of units: 1590\n",
      "train loss: 0.0040873173915395, at epoch: 99\n",
      "\n",
      "Number of units: 1600\n",
      "train loss: 0.004643188639868469, at epoch: 98\n",
      "\n",
      "Number of units: 1610\n",
      "train loss: 0.004923699573939189, at epoch: 97\n",
      "\n",
      "Number of units: 1620\n",
      "train loss: 0.0044348116212322, at epoch: 97\n",
      "\n",
      "Number of units: 1630\n",
      "train loss: 0.00477348396419103, at epoch: 97\n",
      "\n",
      "Number of units: 1640\n",
      "train loss: 0.004729901481841808, at epoch: 99\n",
      "\n",
      "Number of units: 1650\n",
      "train loss: 0.004731139842474477, at epoch: 96\n",
      "\n",
      "Number of units: 1660\n",
      "train loss: 0.0048157649994126925, at epoch: 96\n",
      "\n",
      "Number of units: 1670\n",
      "train loss: 0.0048983079233266835, at epoch: 97\n",
      "\n",
      "Number of units: 1680\n",
      "train loss: 0.0047819971549495225, at epoch: 96\n",
      "\n",
      "Number of units: 1690\n",
      "train loss: 0.004858851955027745, at epoch: 96\n",
      "\n",
      "Number of units: 1700\n",
      "train loss: 0.004752967254613622, at epoch: 95\n",
      "\n",
      "Number of units: 1710\n",
      "train loss: 0.0047556046128306665, at epoch: 95\n",
      "\n",
      "Number of units: 1720\n",
      "train loss: 0.004635040119540008, at epoch: 95\n",
      "\n",
      "Number of units: 1730\n",
      "train loss: 0.004614958270813219, at epoch: 97\n",
      "\n",
      "Number of units: 1740\n",
      "train loss: 0.004796721419807568, at epoch: 94\n",
      "\n",
      "Number of units: 1750\n",
      "train loss: 0.004402266986771792, at epoch: 100\n",
      "\n",
      "Number of units: 1760\n",
      "train loss: 0.004894262781732266, at epoch: 94\n",
      "\n",
      "Number of units: 1770\n",
      "train loss: 0.004749034904230598, at epoch: 94\n",
      "\n",
      "Number of units: 1780\n",
      "train loss: 0.004937187324162835, at epoch: 96\n",
      "\n",
      "Number of units: 1790\n",
      "train loss: 0.004592221359012854, at epoch: 95\n",
      "\n",
      "Number of units: 1800\n",
      "train loss: 0.004912684896108601, at epoch: 94\n",
      "\n",
      "Number of units: 1810\n",
      "train loss: 0.004644361774358146, at epoch: 93\n",
      "\n",
      "Number of units: 1820\n",
      "train loss: 0.004994594121833984, at epoch: 91\n",
      "\n",
      "Number of units: 1830\n",
      "train loss: 0.004538860700406531, at epoch: 96\n",
      "\n",
      "Number of units: 1840\n",
      "train loss: 0.0049586041282907445, at epoch: 93\n",
      "\n",
      "Number of units: 1850\n",
      "train loss: 0.0047184351717223195, at epoch: 96\n",
      "\n",
      "Number of units: 1860\n",
      "train loss: 0.004637415002648737, at epoch: 91\n",
      "\n",
      "Number of units: 1870\n",
      "train loss: 0.004874022560708227, at epoch: 91\n",
      "\n",
      "Number of units: 1880\n",
      "train loss: 0.0044963986715129065, at epoch: 94\n",
      "\n",
      "Number of units: 1890\n",
      "train loss: 0.004765391552633673, at epoch: 90\n",
      "\n",
      "Number of units: 1900\n",
      "train loss: 0.004670698469661545, at epoch: 93\n",
      "\n",
      "Number of units: 1910\n",
      "train loss: 0.0049063267717542654, at epoch: 91\n",
      "\n",
      "Number of units: 1920\n",
      "train loss: 0.004643954382242726, at epoch: 94\n",
      "\n",
      "Number of units: 1930\n",
      "train loss: 0.004884338119448018, at epoch: 93\n",
      "\n",
      "Number of units: 1940\n",
      "train loss: 0.004860378718420293, at epoch: 92\n",
      "\n",
      "Number of units: 1950\n",
      "train loss: 0.004833162482751732, at epoch: 90\n",
      "\n",
      "Number of units: 1960\n",
      "train loss: 0.004596033571961016, at epoch: 92\n",
      "\n",
      "Number of units: 1970\n",
      "train loss: 0.004849140773949898, at epoch: 90\n",
      "\n",
      "Number of units: 1980\n",
      "train loss: 0.004770935842871609, at epoch: 91\n",
      "\n",
      "Number of units: 1990\n",
      "train loss: 0.0046614876601196896, at epoch: 91\n",
      "\n",
      "Number of units: 2000\n",
      "train loss: 0.00495352622086898, at epoch: 92\n",
      "\n",
      "Number of units: 2010\n",
      "train loss: 0.004930347510626803, at epoch: 87\n",
      "\n",
      "Number of units: 2020\n",
      "train loss: 0.0047554978816562255, at epoch: 90\n",
      "\n",
      "Number of units: 2030\n",
      "train loss: 0.0046939541586999665, at epoch: 88\n",
      "\n",
      "Number of units: 2040\n",
      "train loss: 0.0049899991721434845, at epoch: 91\n",
      "\n",
      "Number of units: 2050\n",
      "train loss: 0.00484711428232174, at epoch: 87\n",
      "\n",
      "Number of units: 2060\n",
      "train loss: 0.004779557619350498, at epoch: 89\n",
      "\n",
      "Number of units: 2070\n",
      "train loss: 0.0048677480349454075, at epoch: 87\n",
      "\n",
      "Number of units: 2080\n",
      "train loss: 0.004969768719356722, at epoch: 89\n",
      "\n",
      "Number of units: 2090\n",
      "train loss: 0.004981192722929677, at epoch: 87\n",
      "\n",
      "Number of units: 2100\n",
      "train loss: 0.0043431312438053735, at epoch: 93\n",
      "\n",
      "Number of units: 2110\n",
      "train loss: 0.004848032485506479, at epoch: 90\n",
      "\n",
      "Number of units: 2120\n",
      "train loss: 0.004578724237691745, at epoch: 89\n",
      "\n",
      "Number of units: 2130\n",
      "train loss: 0.004993347003592703, at epoch: 87\n",
      "\n",
      "Number of units: 2140\n",
      "train loss: 0.004930901473895802, at epoch: 88\n",
      "\n",
      "Number of units: 2150\n",
      "train loss: 0.004217370389119424, at epoch: 89\n",
      "\n",
      "Number of units: 2160\n",
      "train loss: 0.004949190819756382, at epoch: 87\n",
      "\n",
      "Number of units: 2170\n",
      "train loss: 0.004614050938174046, at epoch: 89\n",
      "\n",
      "Number of units: 2180\n",
      "train loss: 0.004444261901651885, at epoch: 91\n",
      "\n",
      "Number of units: 2190\n",
      "train loss: 0.00429726982764123, at epoch: 89\n",
      "\n",
      "Number of units: 2200\n",
      "train loss: 0.00477629085325475, at epoch: 87\n",
      "\n",
      "Number of units: 2210\n",
      "train loss: 0.004950873381672807, at epoch: 87\n",
      "\n",
      "Number of units: 2220\n",
      "train loss: 0.00481568282295143, at epoch: 86\n",
      "\n",
      "Number of units: 2230\n",
      "train loss: 0.004920382651273485, at epoch: 86\n",
      "\n",
      "Number of units: 2240\n",
      "train loss: 0.004470612363971043, at epoch: 88\n",
      "\n",
      "Number of units: 2250\n",
      "train loss: 0.004627405968636822, at epoch: 87\n",
      "\n",
      "Number of units: 2260\n",
      "train loss: 0.00496304911189327, at epoch: 87\n",
      "\n",
      "Number of units: 2270\n",
      "train loss: 0.004735352121957419, at epoch: 87\n",
      "\n",
      "Number of units: 2280\n",
      "train loss: 0.004956543394554274, at epoch: 83\n",
      "\n",
      "Number of units: 2290\n",
      "train loss: 0.004967632909629743, at epoch: 86\n",
      "\n",
      "Number of units: 2300\n",
      "train loss: 0.004574029914213327, at epoch: 86\n",
      "\n",
      "Number of units: 2310\n",
      "train loss: 0.0047819208330946595, at epoch: 88\n",
      "\n",
      "Number of units: 2320\n",
      "train loss: 0.00496166066347115, at epoch: 87\n",
      "\n",
      "Number of units: 2330\n",
      "train loss: 0.004629804092321024, at epoch: 85\n",
      "\n",
      "Number of units: 2340\n",
      "train loss: 0.004072836921005773, at epoch: 89\n",
      "\n",
      "Number of units: 2350\n",
      "train loss: 0.004949254332596809, at epoch: 87\n",
      "\n",
      "Number of units: 2360\n",
      "train loss: 0.004752918113956923, at epoch: 87\n",
      "\n",
      "Number of units: 2370\n",
      "train loss: 0.0048826296582686265, at epoch: 86\n",
      "\n",
      "Number of units: 2380\n",
      "train loss: 0.00490037987850485, at epoch: 84\n",
      "\n",
      "Number of units: 2390\n",
      "train loss: 0.0045929601522365715, at epoch: 86\n",
      "\n",
      "Number of units: 2400\n",
      "train loss: 0.004323457347536816, at epoch: 86\n",
      "\n",
      "Number of units: 2410\n",
      "train loss: 0.004642096288211519, at epoch: 86\n",
      "\n",
      "Number of units: 2420\n",
      "train loss: 0.004547776951358742, at epoch: 87\n",
      "\n",
      "Number of units: 2430\n",
      "train loss: 0.004549789719860087, at epoch: 85\n",
      "\n",
      "Number of units: 2440\n",
      "train loss: 0.00497149115001946, at epoch: 84\n",
      "\n",
      "Number of units: 2450\n",
      "train loss: 0.0047611733182310444, at epoch: 83\n",
      "\n",
      "Number of units: 2460\n",
      "train loss: 0.004934547410353787, at epoch: 83\n",
      "\n",
      "Number of units: 2470\n",
      "train loss: 0.004669501315466959, at epoch: 82\n",
      "\n",
      "Number of units: 2480\n",
      "train loss: 0.004654919222798526, at epoch: 84\n",
      "\n",
      "Number of units: 2490\n",
      "train loss: 0.004702073822311945, at epoch: 82\n",
      "\n",
      "Number of units: 2500\n",
      "train loss: 0.0048397111035063745, at epoch: 82\n",
      "\n",
      "Number of units: 2510\n",
      "train loss: 0.004825935318349934, at epoch: 83\n",
      "\n",
      "Number of units: 2520\n",
      "train loss: 0.004928122550695662, at epoch: 83\n",
      "\n",
      "Number of units: 2530\n",
      "train loss: 0.004685591476109039, at epoch: 83\n",
      "\n",
      "Number of units: 2540\n",
      "train loss: 0.004613976267544331, at epoch: 83\n",
      "\n",
      "Number of units: 2550\n",
      "train loss: 0.0049291717989905235, at epoch: 84\n",
      "\n",
      "Number of units: 2560\n",
      "train loss: 0.004880060550099756, at epoch: 84\n",
      "\n",
      "Number of units: 2570\n",
      "train loss: 0.004651227321803049, at epoch: 81\n",
      "\n",
      "Number of units: 2580\n",
      "train loss: 0.004992847701097957, at epoch: 80\n",
      "\n",
      "Number of units: 2590\n",
      "train loss: 0.004571303251823906, at epoch: 85\n",
      "\n",
      "Number of units: 2600\n",
      "train loss: 0.004989117246691421, at epoch: 83\n",
      "\n",
      "Number of units: 2610\n",
      "train loss: 0.004271764713645325, at epoch: 84\n",
      "\n",
      "Number of units: 2620\n",
      "train loss: 0.004226872977411062, at epoch: 82\n",
      "\n",
      "Number of units: 2630\n",
      "train loss: 0.004249391584735918, at epoch: 84\n",
      "\n",
      "Number of units: 2640\n",
      "train loss: 0.004894763592780578, at epoch: 84\n",
      "\n",
      "Number of units: 2650\n",
      "train loss: 0.004575734710179517, at epoch: 83\n",
      "\n",
      "Number of units: 2660\n",
      "train loss: 0.0049210585084256304, at epoch: 80\n",
      "\n",
      "Number of units: 2670\n",
      "train loss: 0.004991918985483608, at epoch: 82\n",
      "\n",
      "Number of units: 2680\n",
      "train loss: 0.004851420063565115, at epoch: 82\n",
      "\n",
      "Number of units: 2690\n",
      "train loss: 0.004920185870623754, at epoch: 79\n",
      "\n",
      "Number of units: 2700\n",
      "train loss: 0.004874871877741498, at epoch: 82\n",
      "\n",
      "Number of units: 2710\n",
      "train loss: 0.004159918977588859, at epoch: 84\n",
      "\n",
      "Number of units: 2720\n",
      "train loss: 0.004942273531906665, at epoch: 81\n",
      "\n",
      "Number of units: 2730\n",
      "train loss: 0.004699755025196168, at epoch: 80\n",
      "\n",
      "Number of units: 2740\n",
      "train loss: 0.004802284626539972, at epoch: 92\n",
      "\n",
      "Number of units: 2750\n",
      "train loss: 0.004764542590320957, at epoch: 82\n",
      "\n",
      "Number of units: 2760\n",
      "train loss: 0.004916063712572338, at epoch: 81\n",
      "\n",
      "Number of units: 2770\n",
      "train loss: 0.004760883148083223, at epoch: 80\n",
      "\n",
      "Number of units: 2780\n",
      "train loss: 0.004663700636831436, at epoch: 81\n",
      "\n",
      "Number of units: 2790\n",
      "train loss: 0.0047346972857668845, at epoch: 81\n",
      "\n",
      "Number of units: 2800\n",
      "train loss: 0.004956302994179396, at epoch: 80\n",
      "\n",
      "Number of units: 2810\n",
      "train loss: 0.004617058906451916, at epoch: 81\n",
      "\n",
      "Number of units: 2820\n",
      "train loss: 0.004964527035559172, at epoch: 81\n",
      "\n",
      "Number of units: 2830\n",
      "train loss: 0.004720175643270181, at epoch: 79\n",
      "\n",
      "Number of units: 2840\n",
      "train loss: 0.004983992635013123, at epoch: 81\n",
      "\n",
      "Number of units: 2850\n",
      "train loss: 0.004604731291657345, at epoch: 80\n",
      "\n",
      "Number of units: 2860\n",
      "train loss: 0.004859714175967724, at epoch: 78\n",
      "\n",
      "Number of units: 2870\n",
      "train loss: 0.00429035427392904, at epoch: 84\n",
      "\n",
      "Number of units: 2880\n",
      "train loss: 0.0045565472800893755, at epoch: 81\n",
      "\n",
      "Number of units: 2890\n",
      "train loss: 0.004753313158959713, at epoch: 79\n",
      "\n",
      "Number of units: 2900\n",
      "train loss: 0.0041931275606509645, at epoch: 80\n",
      "\n",
      "Number of units: 2910\n",
      "train loss: 0.004776471231886035, at epoch: 78\n",
      "\n",
      "Number of units: 2920\n",
      "train loss: 0.004867934113995176, at epoch: 79\n",
      "\n",
      "Number of units: 2930\n",
      "train loss: 0.004986781227214579, at epoch: 78\n",
      "\n",
      "Number of units: 2940\n",
      "train loss: 0.004942145337784183, at epoch: 79\n",
      "\n",
      "Number of units: 2950\n",
      "train loss: 0.004845028780936786, at epoch: 79\n",
      "\n",
      "Number of units: 2960\n",
      "train loss: 0.004677709803489165, at epoch: 79\n",
      "\n",
      "Number of units: 2970\n",
      "train loss: 0.0048524769719017515, at epoch: 80\n",
      "\n",
      "Number of units: 2980\n",
      "train loss: 0.004302944967548825, at epoch: 80\n",
      "\n",
      "Number of units: 2990\n",
      "train loss: 0.004784926855045342, at epoch: 79\n",
      "\n",
      "Number of units: 3000\n",
      "train loss: 0.004932617585814967, at epoch: 79\n",
      "\n",
      "Number of units: 3010\n",
      "train loss: 0.004733337308586556, at epoch: 78\n",
      "\n",
      "Number of units: 3020\n",
      "train loss: 0.0043747032965305264, at epoch: 80\n",
      "\n",
      "Number of units: 3030\n",
      "train loss: 0.004369250877027752, at epoch: 79\n",
      "\n",
      "Number of units: 3040\n",
      "train loss: 0.00445984881621257, at epoch: 78\n",
      "\n",
      "Number of units: 3050\n",
      "train loss: 0.004626643214620572, at epoch: 77\n",
      "\n",
      "Number of units: 3060\n",
      "train loss: 0.0049185782418595635, at epoch: 76\n",
      "\n",
      "Number of units: 3070\n",
      "train loss: 0.004536678662067289, at epoch: 79\n",
      "\n",
      "Number of units: 3080\n",
      "train loss: 0.0046098734212262115, at epoch: 78\n",
      "\n",
      "Number of units: 3090\n",
      "train loss: 0.0047712094135550845, at epoch: 78\n",
      "\n",
      "Number of units: 3100\n",
      "train loss: 0.004843397521105431, at epoch: 79\n",
      "\n",
      "Number of units: 3110\n",
      "train loss: 0.004945764387246072, at epoch: 78\n",
      "\n",
      "Number of units: 3120\n",
      "train loss: 0.004510024001162947, at epoch: 76\n",
      "\n",
      "Number of units: 3130\n",
      "train loss: 0.004834176001890569, at epoch: 76\n",
      "\n",
      "Number of units: 3140\n",
      "train loss: 0.004972314941647653, at epoch: 77\n",
      "\n",
      "Number of units: 3150\n",
      "train loss: 0.004939281302888503, at epoch: 76\n",
      "\n",
      "Number of units: 3160\n",
      "train loss: 0.00428403835639159, at epoch: 79\n",
      "\n",
      "Number of units: 3170\n",
      "train loss: 0.0047056539433430085, at epoch: 77\n",
      "\n",
      "Number of units: 3180\n",
      "train loss: 0.004896034457052281, at epoch: 75\n",
      "\n",
      "Number of units: 3190\n",
      "train loss: 0.004717861182068077, at epoch: 76\n",
      "\n",
      "Number of units: 3200\n",
      "train loss: 0.004590481769939743, at epoch: 78\n",
      "\n",
      "Number of units: 3210\n",
      "train loss: 0.0046636135797058385, at epoch: 78\n",
      "\n",
      "Number of units: 3220\n",
      "train loss: 0.004422590090467509, at epoch: 78\n",
      "\n",
      "Number of units: 3230\n",
      "train loss: 0.004528919007754552, at epoch: 77\n",
      "\n",
      "Number of units: 3240\n",
      "train loss: 0.004683686012031103, at epoch: 77\n",
      "\n",
      "Number of units: 3250\n",
      "train loss: 0.004632997914681028, at epoch: 77\n",
      "\n",
      "Number of units: 3260\n",
      "train loss: 0.004348545041672765, at epoch: 77\n",
      "\n",
      "Number of units: 3270\n",
      "train loss: 0.004867170907884883, at epoch: 74\n",
      "\n",
      "Number of units: 3280\n",
      "train loss: 0.004809136334666846, at epoch: 76\n",
      "\n",
      "Number of units: 3290\n",
      "train loss: 0.004986156410814715, at epoch: 77\n",
      "\n",
      "Number of units: 3300\n",
      "train loss: 0.00492576821358, at epoch: 74\n",
      "\n",
      "Number of units: 3310\n",
      "train loss: 0.004448076591797872, at epoch: 77\n",
      "\n",
      "Number of units: 3320\n",
      "train loss: 0.0049044911150861025, at epoch: 75\n",
      "\n",
      "Number of units: 3330\n",
      "train loss: 0.004628446487047313, at epoch: 76\n",
      "\n",
      "Number of units: 3340\n",
      "train loss: 0.004922410830615718, at epoch: 77\n",
      "\n",
      "Number of units: 3350\n",
      "train loss: 0.004908971218928855, at epoch: 75\n",
      "\n",
      "Number of units: 3360\n",
      "train loss: 0.004794701587895247, at epoch: 75\n",
      "\n",
      "Number of units: 3370\n",
      "train loss: 0.004796672252124381, at epoch: 74\n",
      "\n",
      "Number of units: 3380\n",
      "train loss: 0.004812838021780692, at epoch: 76\n",
      "\n",
      "Number of units: 3390\n",
      "train loss: 0.004802766705909392, at epoch: 75\n",
      "\n",
      "Number of units: 3400\n",
      "train loss: 0.004893620494399897, at epoch: 75\n",
      "\n",
      "Number of units: 3410\n",
      "train loss: 0.004442279475597388, at epoch: 74\n",
      "\n",
      "Number of units: 3420\n",
      "train loss: 0.004813069983198375, at epoch: 76\n",
      "\n",
      "Number of units: 3430\n",
      "train loss: 0.004812823457187392, at epoch: 75\n",
      "\n",
      "Number of units: 3440\n",
      "train loss: 0.004984192133010765, at epoch: 74\n",
      "\n",
      "Number of units: 3450\n",
      "train loss: 0.004866965904305971, at epoch: 74\n",
      "\n",
      "Number of units: 3460\n",
      "train loss: 0.004834264351903244, at epoch: 78\n",
      "\n",
      "Number of units: 3470\n",
      "train loss: 0.004984165521120758, at epoch: 74\n",
      "\n",
      "Number of units: 3480\n",
      "train loss: 0.004591518942584258, at epoch: 73\n",
      "\n",
      "Number of units: 3490\n",
      "train loss: 0.004904060459263064, at epoch: 75\n",
      "\n",
      "Number of units: 3500\n",
      "train loss: 0.004941811564354453, at epoch: 73\n",
      "\n",
      "Number of units: 3510\n",
      "train loss: 0.0040989241521745615, at epoch: 78\n",
      "\n",
      "Number of units: 3520\n",
      "train loss: 0.004946910735671395, at epoch: 73\n",
      "\n",
      "Number of units: 3530\n",
      "train loss: 0.004872190702499211, at epoch: 74\n",
      "\n",
      "Number of units: 3540\n",
      "train loss: 0.004619330932584376, at epoch: 73\n",
      "\n",
      "Number of units: 3550\n",
      "train loss: 0.004671736591490685, at epoch: 74\n",
      "\n",
      "Number of units: 3560\n",
      "train loss: 0.004535274843930779, at epoch: 73\n",
      "\n",
      "Number of units: 3570\n",
      "train loss: 0.004461506015437351, at epoch: 74\n",
      "\n",
      "Number of units: 3580\n",
      "train loss: 0.004975830804670523, at epoch: 74\n",
      "\n",
      "Number of units: 3590\n",
      "train loss: 0.004736959205491758, at epoch: 75\n",
      "\n",
      "Number of units: 3600\n",
      "train loss: 0.004800379308972538, at epoch: 75\n",
      "\n",
      "Number of units: 3610\n",
      "train loss: 0.004943096791221819, at epoch: 74\n",
      "\n",
      "Number of units: 3620\n",
      "train loss: 0.0041916858047262905, at epoch: 76\n",
      "\n",
      "Number of units: 3630\n",
      "train loss: 0.004676098755558087, at epoch: 74\n",
      "\n",
      "Number of units: 3640\n",
      "train loss: 0.004865385726051272, at epoch: 74\n",
      "\n",
      "Number of units: 3650\n",
      "train loss: 0.004716090265343382, at epoch: 75\n",
      "\n",
      "Number of units: 3660\n",
      "train loss: 0.004662368839132114, at epoch: 74\n",
      "\n",
      "Number of units: 3670\n",
      "train loss: 0.004678441054074937, at epoch: 75\n",
      "\n",
      "Number of units: 3680\n",
      "train loss: 0.0045138159161942325, at epoch: 72\n",
      "\n",
      "Number of units: 3690\n",
      "train loss: 0.004770755900268569, at epoch: 73\n",
      "\n",
      "Number of units: 3700\n",
      "train loss: 0.004751725155422264, at epoch: 72\n",
      "\n",
      "Number of units: 3710\n",
      "train loss: 0.00467603661266537, at epoch: 74\n",
      "\n",
      "Number of units: 3720\n",
      "train loss: 0.004630496878955909, at epoch: 72\n",
      "\n",
      "Number of units: 3730\n",
      "train loss: 0.004870660840474699, at epoch: 73\n",
      "\n",
      "Number of units: 3740\n",
      "train loss: 0.004937247106732343, at epoch: 72\n",
      "\n",
      "Number of units: 3750\n",
      "train loss: 0.004128329877468672, at epoch: 74\n",
      "\n",
      "Number of units: 3760\n",
      "train loss: 0.00484401072488879, at epoch: 72\n",
      "\n",
      "Number of units: 3770\n",
      "train loss: 0.0049150406866380085, at epoch: 70\n",
      "\n",
      "Number of units: 3780\n",
      "train loss: 0.004970970515630029, at epoch: 73\n",
      "\n",
      "Number of units: 3790\n",
      "train loss: 0.004534794420284811, at epoch: 72\n",
      "\n",
      "Number of units: 3800\n",
      "train loss: 0.004718612939965397, at epoch: 72\n",
      "\n",
      "Number of units: 3810\n",
      "train loss: 0.004940959366689412, at epoch: 72\n",
      "\n",
      "Number of units: 3820\n",
      "train loss: 0.004318314129884584, at epoch: 73\n",
      "\n",
      "Number of units: 3830\n",
      "train loss: 0.004827935679520579, at epoch: 72\n",
      "\n",
      "Number of units: 3840\n",
      "train loss: 0.004951063848559443, at epoch: 72\n",
      "\n",
      "Number of units: 3850\n",
      "train loss: 0.004866773588439628, at epoch: 73\n",
      "\n",
      "Number of units: 3860\n",
      "train loss: 0.004961943955370316, at epoch: 71\n",
      "\n",
      "Number of units: 3870\n",
      "train loss: 0.004627202141921316, at epoch: 72\n",
      "\n",
      "Number of units: 3880\n",
      "train loss: 0.0047488618685753185, at epoch: 72\n",
      "\n",
      "Number of units: 3890\n",
      "train loss: 0.004465289626137406, at epoch: 72\n",
      "\n",
      "Number of units: 3900\n",
      "train loss: 0.004809427040453329, at epoch: 73\n",
      "\n",
      "Number of units: 3910\n",
      "train loss: 0.004895001942206818, at epoch: 71\n",
      "\n",
      "Number of units: 3920\n",
      "train loss: 0.004908789849030768, at epoch: 71\n",
      "\n",
      "Number of units: 3930\n",
      "train loss: 0.004680821575075811, at epoch: 72\n",
      "\n",
      "Number of units: 3940\n",
      "train loss: 0.004869337592740521, at epoch: 70\n",
      "\n",
      "Number of units: 3950\n",
      "train loss: 0.004691162936380806, at epoch: 71\n",
      "\n",
      "Number of units: 3960\n",
      "train loss: 0.004645871610302379, at epoch: 72\n",
      "\n",
      "Number of units: 3970\n",
      "train loss: 0.004892539126359452, at epoch: 71\n",
      "\n",
      "Number of units: 3980\n",
      "train loss: 0.004788887742005841, at epoch: 71\n",
      "\n",
      "Number of units: 3990\n",
      "train loss: 0.004590086329559142, at epoch: 74\n",
      "\n",
      "Number of units: 4000\n",
      "train loss: 0.004436947755390861, at epoch: 71\n",
      "\n",
      "Number of units: 4010\n",
      "train loss: 0.00491079968034569, at epoch: 71\n",
      "\n",
      "Number of units: 4020\n",
      "train loss: 0.0045519641383913265, at epoch: 71\n",
      "\n",
      "Number of units: 4030\n",
      "train loss: 0.004858924837400025, at epoch: 70\n",
      "\n",
      "Number of units: 4040\n",
      "train loss: 0.004985411694706272, at epoch: 72\n",
      "\n",
      "Number of units: 4050\n",
      "train loss: 0.004695157800772449, at epoch: 69\n",
      "\n",
      "Number of units: 4060\n",
      "train loss: 0.0048447711627136415, at epoch: 70\n",
      "\n",
      "Number of units: 4070\n",
      "train loss: 0.004782860355749676, at epoch: 72\n",
      "\n",
      "Number of units: 4080\n",
      "train loss: 0.004931770056032576, at epoch: 71\n",
      "\n",
      "Number of units: 4090\n",
      "train loss: 0.004995000850852307, at epoch: 70\n",
      "\n",
      "Number of units: 4100\n",
      "train loss: 0.004561493164187596, at epoch: 78\n",
      "\n",
      "Number of units: 4110\n",
      "train loss: 0.004723160800255073, at epoch: 71\n",
      "\n",
      "Number of units: 4120\n",
      "train loss: 0.004602786911184467, at epoch: 71\n",
      "\n",
      "Number of units: 4130\n",
      "train loss: 0.004761462556263041, at epoch: 70\n",
      "\n",
      "Number of units: 4140\n",
      "train loss: 0.004822500571090131, at epoch: 70\n",
      "\n",
      "Number of units: 4150\n",
      "train loss: 0.00477374746929911, at epoch: 70\n",
      "\n",
      "Number of units: 4160\n",
      "train loss: 0.004532690834810183, at epoch: 73\n",
      "\n",
      "Number of units: 4170\n",
      "train loss: 0.004863307397009464, at epoch: 71\n",
      "\n",
      "Number of units: 4180\n",
      "train loss: 0.004812605438551998, at epoch: 68\n",
      "\n",
      "Number of units: 4190\n",
      "train loss: 0.004834394489062959, at epoch: 71\n",
      "\n",
      "Number of units: 4200\n",
      "train loss: 0.004910252970377655, at epoch: 69\n",
      "\n",
      "Number of units: 4210\n",
      "train loss: 0.004588070268516731, at epoch: 70\n",
      "\n",
      "Number of units: 4220\n",
      "train loss: 0.004961601930445454, at epoch: 69\n",
      "\n",
      "Number of units: 4230\n",
      "train loss: 0.0048919401203613684, at epoch: 69\n",
      "\n",
      "Number of units: 4240\n",
      "train loss: 0.0049029211394122285, at epoch: 69\n",
      "\n",
      "Number of units: 4250\n",
      "train loss: 0.004837928939775225, at epoch: 71\n",
      "\n",
      "Number of units: 4260\n",
      "train loss: 0.004902505962579653, at epoch: 69\n",
      "\n",
      "Number of units: 4270\n",
      "train loss: 0.004859828854597197, at epoch: 69\n",
      "\n",
      "Number of units: 4280\n",
      "train loss: 0.004656004511041374, at epoch: 71\n",
      "\n",
      "Number of units: 4290\n",
      "train loss: 0.004669231133532321, at epoch: 69\n",
      "\n",
      "Number of units: 4300\n",
      "train loss: 0.004901389228482458, at epoch: 70\n",
      "\n",
      "Number of units: 4310\n",
      "train loss: 0.004496026947605856, at epoch: 70\n",
      "\n",
      "Number of units: 4320\n",
      "train loss: 0.004548821162611603, at epoch: 70\n",
      "\n",
      "Number of units: 4330\n",
      "train loss: 0.004962527715175611, at epoch: 68\n",
      "\n",
      "Number of units: 4340\n",
      "train loss: 0.004606344426881606, at epoch: 71\n",
      "\n",
      "Number of units: 4350\n",
      "train loss: 0.004501548267051021, at epoch: 69\n",
      "\n",
      "Number of units: 4360\n",
      "train loss: 0.00486255107028228, at epoch: 68\n",
      "\n",
      "Number of units: 4370\n",
      "train loss: 0.004895231372026956, at epoch: 67\n",
      "\n",
      "Number of units: 4380\n",
      "train loss: 0.004532787694396916, at epoch: 69\n",
      "\n",
      "Number of units: 4390\n",
      "train loss: 0.004466928976733016, at epoch: 70\n",
      "\n",
      "Number of units: 4400\n",
      "train loss: 0.004763516552098963, at epoch: 68\n",
      "\n",
      "Number of units: 4410\n",
      "train loss: 0.004703035661771082, at epoch: 69\n",
      "\n",
      "Number of units: 4420\n",
      "train loss: 0.004766852295481385, at epoch: 69\n",
      "\n",
      "Number of units: 4430\n",
      "train loss: 0.0047321504935780466, at epoch: 68\n",
      "\n",
      "Number of units: 4440\n",
      "train loss: 0.0049164906936766785, at epoch: 69\n",
      "\n",
      "Number of units: 4450\n",
      "train loss: 0.004974119737972842, at epoch: 68\n",
      "\n",
      "Number of units: 4460\n",
      "train loss: 0.004856400505187537, at epoch: 69\n",
      "\n",
      "Number of units: 4470\n",
      "train loss: 0.004952870966150158, at epoch: 68\n",
      "\n",
      "Number of units: 4480\n",
      "train loss: 0.004774452650954117, at epoch: 68\n",
      "\n",
      "Number of units: 4490\n",
      "train loss: 0.00427530842702879, at epoch: 71\n",
      "\n",
      "Number of units: 4500\n",
      "train loss: 0.0043614478088341005, at epoch: 70\n",
      "\n",
      "Number of units: 4510\n",
      "train loss: 0.00483913030134886, at epoch: 67\n",
      "\n",
      "Number of units: 4520\n",
      "train loss: 0.00478584320285421, at epoch: 69\n",
      "\n",
      "Number of units: 4530\n",
      "train loss: 0.004683803251446932, at epoch: 68\n",
      "\n",
      "Number of units: 4540\n",
      "train loss: 0.004976082490118188, at epoch: 66\n",
      "\n",
      "Number of units: 4550\n",
      "train loss: 0.0045262931018444875, at epoch: 68\n",
      "\n",
      "Number of units: 4560\n",
      "train loss: 0.0048862031763849244, at epoch: 68\n",
      "\n",
      "Number of units: 4570\n",
      "train loss: 0.004728630033571335, at epoch: 68\n",
      "\n",
      "Number of units: 4580\n",
      "train loss: 0.00492594311680648, at epoch: 67\n",
      "\n",
      "Number of units: 4590\n",
      "train loss: 0.004613716792335936, at epoch: 68\n",
      "\n",
      "Number of units: 4600\n",
      "train loss: 0.004781229055933522, at epoch: 71\n",
      "\n",
      "Number of units: 4610\n",
      "train loss: 0.004818018766157479, at epoch: 67\n",
      "\n",
      "Number of units: 4620\n",
      "train loss: 0.004814781325555941, at epoch: 67\n",
      "\n",
      "Number of units: 4630\n",
      "train loss: 0.00492503639397114, at epoch: 67\n",
      "\n",
      "Number of units: 4640\n",
      "train loss: 0.004894782496264725, at epoch: 66\n",
      "\n",
      "Number of units: 4650\n",
      "train loss: 0.004820242120850367, at epoch: 68\n",
      "\n",
      "Number of units: 4660\n",
      "train loss: 0.004514449432688821, at epoch: 69\n",
      "\n",
      "Number of units: 4670\n",
      "train loss: 0.004592912093661425, at epoch: 68\n",
      "\n",
      "Number of units: 4680\n",
      "train loss: 0.004861326980491754, at epoch: 67\n",
      "\n",
      "Number of units: 4690\n",
      "train loss: 0.004969056723187464, at epoch: 67\n",
      "\n",
      "Number of units: 4700\n",
      "train loss: 0.004773910791587355, at epoch: 68\n",
      "\n",
      "Number of units: 4710\n",
      "train loss: 0.004595872138435766, at epoch: 68\n",
      "\n",
      "Number of units: 4720\n",
      "train loss: 0.004838517500390935, at epoch: 67\n",
      "\n",
      "Number of units: 4730\n",
      "train loss: 0.004694002444963985, at epoch: 68\n",
      "\n",
      "Number of units: 4740\n",
      "train loss: 0.004928075073290188, at epoch: 66\n",
      "\n",
      "Number of units: 4750\n",
      "train loss: 0.004589263327255253, at epoch: 68\n",
      "\n",
      "Number of units: 4760\n",
      "train loss: 0.004884989156738015, at epoch: 66\n",
      "\n",
      "Number of units: 4770\n",
      "train loss: 0.004781538254493967, at epoch: 66\n",
      "\n",
      "Number of units: 4780\n",
      "train loss: 0.004554164841576949, at epoch: 69\n",
      "\n",
      "Number of units: 4790\n",
      "train loss: 0.004671106794742741, at epoch: 67\n",
      "\n",
      "Number of units: 4800\n",
      "train loss: 0.004598082000435965, at epoch: 68\n",
      "\n",
      "Number of units: 4810\n",
      "train loss: 0.004753489305877281, at epoch: 67\n",
      "\n",
      "Number of units: 4820\n",
      "train loss: 0.004991892137416869, at epoch: 65\n",
      "\n",
      "Number of units: 4830\n",
      "train loss: 0.004367902950722282, at epoch: 67\n",
      "\n",
      "Number of units: 4840\n",
      "train loss: 0.004482750527546955, at epoch: 67\n",
      "\n",
      "Number of units: 4850\n",
      "train loss: 0.004361155178559102, at epoch: 70\n",
      "\n",
      "Number of units: 4860\n",
      "train loss: 0.00463461339649541, at epoch: 68\n",
      "\n",
      "Number of units: 4870\n",
      "train loss: 0.0049108807244579115, at epoch: 66\n",
      "\n",
      "Number of units: 4880\n",
      "train loss: 0.00493460244253356, at epoch: 66\n",
      "\n",
      "Number of units: 4890\n",
      "train loss: 0.004818886423188928, at epoch: 67\n",
      "\n",
      "Number of units: 4900\n",
      "train loss: 0.004908616466074136, at epoch: 66\n",
      "\n",
      "Number of units: 4910\n",
      "train loss: 0.004785008255764751, at epoch: 67\n",
      "\n",
      "Number of units: 4920\n",
      "train loss: 0.004991430813863076, at epoch: 66\n",
      "\n",
      "Number of units: 4930\n",
      "train loss: 0.004891275336897252, at epoch: 66\n",
      "\n",
      "Number of units: 4940\n",
      "train loss: 0.004667069793565588, at epoch: 66\n",
      "\n",
      "Number of units: 4950\n",
      "train loss: 0.004772224099220921, at epoch: 66\n",
      "\n",
      "Number of units: 4960\n",
      "train loss: 0.004856769481769448, at epoch: 66\n",
      "\n",
      "Number of units: 4970\n",
      "train loss: 0.004793367474628667, at epoch: 65\n",
      "\n",
      "Number of units: 4980\n",
      "train loss: 0.004803274157267765, at epoch: 67\n",
      "\n",
      "Number of units: 4990\n",
      "train loss: 0.004630189037158629, at epoch: 66\n",
      "\n",
      "Number of units: 5000\n",
      "train loss: 0.004650608109561745, at epoch: 65\n",
      "\n",
      "Number of units: 5010\n",
      "train loss: 0.004834804725217055, at epoch: 72\n",
      "\n",
      "Number of units: 5020\n",
      "train loss: 0.004769590898364981, at epoch: 66\n",
      "\n",
      "Number of units: 5030\n",
      "train loss: 0.00486034666311923, at epoch: 66\n",
      "\n",
      "Number of units: 5040\n",
      "train loss: 0.004786953556753133, at epoch: 66\n",
      "\n",
      "Number of units: 5050\n",
      "train loss: 0.004907010026993248, at epoch: 66\n",
      "\n",
      "Number of units: 5060\n",
      "train loss: 0.004147052285380823, at epoch: 69\n",
      "\n",
      "Number of units: 5070\n",
      "train loss: 0.004940049371021758, at epoch: 65\n",
      "\n",
      "Number of units: 5080\n",
      "train loss: 0.004988747716805619, at epoch: 65\n",
      "\n",
      "Number of units: 5090\n",
      "train loss: 0.004702948861847744, at epoch: 66\n",
      "\n",
      "Number of units: 5100\n",
      "train loss: 0.004938478878273145, at epoch: 64\n",
      "\n",
      "Number of units: 5110\n",
      "train loss: 0.00499348458970644, at epoch: 65\n",
      "\n",
      "Number of units: 5120\n",
      "train loss: 0.004307768580651441, at epoch: 67\n",
      "\n",
      "Number of units: 5130\n",
      "train loss: 0.004831146351436928, at epoch: 65\n",
      "\n",
      "Number of units: 5140\n",
      "train loss: 0.004789387856847043, at epoch: 66\n",
      "\n",
      "Number of units: 5150\n",
      "train loss: 0.00453878921214141, at epoch: 67\n",
      "\n",
      "Number of units: 5160\n",
      "train loss: 0.0044248992478458146, at epoch: 65\n",
      "\n",
      "Number of units: 5170\n",
      "train loss: 0.00484048937048783, at epoch: 65\n",
      "\n",
      "Number of units: 5180\n",
      "train loss: 0.004893380978270443, at epoch: 66\n",
      "\n",
      "Number of units: 5190\n",
      "train loss: 0.00432832206885763, at epoch: 67\n",
      "\n",
      "Number of units: 5200\n",
      "train loss: 0.004846176049910298, at epoch: 66\n",
      "\n",
      "Number of units: 5210\n",
      "train loss: 0.004889206276777714, at epoch: 65\n",
      "\n",
      "Number of units: 5220\n",
      "train loss: 0.004445622816884907, at epoch: 66\n",
      "\n",
      "Number of units: 5230\n",
      "train loss: 0.004936092134532828, at epoch: 63\n",
      "\n",
      "Number of units: 5240\n",
      "train loss: 0.0046590149290557294, at epoch: 65\n",
      "\n",
      "Number of units: 5250\n",
      "train loss: 0.004731921281719451, at epoch: 65\n",
      "\n",
      "Number of units: 5260\n",
      "train loss: 0.00475607110919583, at epoch: 66\n",
      "\n",
      "Number of units: 5270\n",
      "train loss: 0.004614467828670286, at epoch: 66\n",
      "\n",
      "Number of units: 5280\n",
      "train loss: 0.0045447886257909435, at epoch: 65\n",
      "\n",
      "Number of units: 5290\n",
      "train loss: 0.004598636024625193, at epoch: 65\n",
      "\n",
      "Number of units: 5300\n",
      "train loss: 0.00475995558715681, at epoch: 65\n",
      "\n",
      "Number of units: 5310\n",
      "train loss: 0.004573100033328501, at epoch: 66\n",
      "\n",
      "Number of units: 5320\n",
      "train loss: 0.004611600720651836, at epoch: 65\n",
      "\n",
      "Number of units: 5330\n",
      "train loss: 0.004887455335571644, at epoch: 64\n",
      "\n",
      "Number of units: 5340\n",
      "train loss: 0.00475026804509298, at epoch: 64\n",
      "\n",
      "Number of units: 5350\n",
      "train loss: 0.004901988108483693, at epoch: 64\n",
      "\n",
      "Number of units: 5360\n",
      "train loss: 0.004979047373001322, at epoch: 64\n",
      "\n",
      "Number of units: 5370\n",
      "train loss: 0.0045831108364072295, at epoch: 65\n",
      "\n",
      "Number of units: 5380\n",
      "train loss: 0.004488623019281022, at epoch: 65\n",
      "\n",
      "Number of units: 5390\n",
      "train loss: 0.004414387700027191, at epoch: 66\n",
      "\n",
      "Number of units: 5400\n",
      "train loss: 0.004321111838423803, at epoch: 66\n",
      "\n",
      "Number of units: 5410\n",
      "train loss: 0.004646959292747397, at epoch: 65\n",
      "\n",
      "Number of units: 5420\n",
      "train loss: 0.004913451567587685, at epoch: 63\n",
      "\n",
      "Number of units: 5430\n",
      "train loss: 0.004747007400125653, at epoch: 67\n",
      "\n",
      "Number of units: 5440\n",
      "train loss: 0.0044247467896491345, at epoch: 65\n",
      "\n",
      "Number of units: 5450\n",
      "train loss: 0.00487831322642819, at epoch: 64\n",
      "\n",
      "Number of units: 5460\n",
      "train loss: 0.004954366125305114, at epoch: 64\n",
      "\n",
      "Number of units: 5470\n",
      "train loss: 0.004953525938119014, at epoch: 65\n",
      "\n",
      "Number of units: 5480\n",
      "train loss: 0.0046272181668041415, at epoch: 65\n",
      "\n",
      "Number of units: 5490\n",
      "train loss: 0.004530569346265452, at epoch: 65\n",
      "\n",
      "Number of units: 5500\n",
      "train loss: 0.00484608478416817, at epoch: 65\n",
      "\n",
      "Number of units: 5510\n",
      "train loss: 0.004412998957843115, at epoch: 65\n",
      "\n",
      "Number of units: 5520\n",
      "train loss: 0.0042096749270109516, at epoch: 67\n",
      "\n",
      "Number of units: 5530\n",
      "train loss: 0.0047467133224813555, at epoch: 64\n",
      "\n",
      "Number of units: 5540\n",
      "train loss: 0.004940543843677858, at epoch: 64\n",
      "\n",
      "Number of units: 5550\n",
      "train loss: 0.004619574086555644, at epoch: 64\n",
      "\n",
      "Number of units: 5560\n",
      "train loss: 0.004469594747222345, at epoch: 64\n",
      "\n",
      "Number of units: 5570\n",
      "train loss: 0.0047789532069117515, at epoch: 64\n",
      "\n",
      "Number of units: 5580\n",
      "train loss: 0.004516672675092081, at epoch: 65\n",
      "\n",
      "Number of units: 5590\n",
      "train loss: 0.00489848175150371, at epoch: 63\n",
      "\n",
      "Number of units: 5600\n",
      "train loss: 0.0048969634220794945, at epoch: 65\n",
      "\n",
      "Number of units: 5610\n",
      "train loss: 0.0043936316666997755, at epoch: 64\n",
      "\n",
      "Number of units: 5620\n",
      "train loss: 0.00454533589990433, at epoch: 64\n",
      "\n",
      "Number of units: 5630\n",
      "train loss: 0.004657972189954194, at epoch: 63\n",
      "\n",
      "Number of units: 5640\n",
      "train loss: 0.004509421268218716, at epoch: 66\n",
      "\n",
      "Number of units: 5650\n",
      "train loss: 0.004937322404800284, at epoch: 63\n",
      "\n",
      "Number of units: 5660\n",
      "train loss: 0.004464451595464994, at epoch: 64\n",
      "\n",
      "Number of units: 5670\n",
      "train loss: 0.004917660873596219, at epoch: 63\n",
      "\n",
      "Number of units: 5680\n",
      "train loss: 0.004957816367127634, at epoch: 63\n",
      "\n",
      "Number of units: 5690\n",
      "train loss: 0.004769452119900279, at epoch: 65\n",
      "\n",
      "Number of units: 5700\n",
      "train loss: 0.004974540578356823, at epoch: 64\n",
      "\n",
      "Number of units: 5710\n",
      "train loss: 0.004769579909886943, at epoch: 64\n",
      "\n",
      "Number of units: 5720\n",
      "train loss: 0.004804888092147052, at epoch: 64\n",
      "\n",
      "Number of units: 5730\n",
      "train loss: 0.0041119572877744304, at epoch: 66\n",
      "\n",
      "Number of units: 5740\n",
      "train loss: 0.004511297272830177, at epoch: 64\n",
      "\n",
      "Number of units: 5750\n",
      "train loss: 0.004798536090130483, at epoch: 63\n",
      "\n",
      "Number of units: 5760\n",
      "train loss: 0.004709436127069466, at epoch: 67\n",
      "\n",
      "Number of units: 5770\n",
      "train loss: 0.004839066403069978, at epoch: 64\n",
      "\n",
      "Number of units: 5780\n",
      "train loss: 0.004824290874095709, at epoch: 64\n",
      "\n",
      "Number of units: 5790\n",
      "train loss: 0.004454227951197823, at epoch: 63\n",
      "\n",
      "Number of units: 5800\n",
      "train loss: 0.004654662910152468, at epoch: 64\n",
      "\n",
      "Number of units: 5810\n",
      "train loss: 0.0049310524589310486, at epoch: 62\n",
      "\n",
      "Number of units: 5820\n",
      "train loss: 0.004837199615122927, at epoch: 64\n",
      "\n",
      "Number of units: 5830\n",
      "train loss: 0.004964363898780846, at epoch: 63\n",
      "\n",
      "Number of units: 5840\n",
      "train loss: 0.004559553020641829, at epoch: 63\n",
      "\n",
      "Number of units: 5850\n",
      "train loss: 0.004796876457214125, at epoch: 63\n",
      "\n",
      "Number of units: 5860\n",
      "train loss: 0.004723355543852108, at epoch: 63\n",
      "\n",
      "Number of units: 5870\n",
      "train loss: 0.004333507476954423, at epoch: 63\n",
      "\n",
      "Number of units: 5880\n",
      "train loss: 0.0048577399150838115, at epoch: 63\n",
      "\n",
      "Number of units: 5890\n",
      "train loss: 0.004774878008626615, at epoch: 63\n",
      "\n",
      "Number of units: 5900\n",
      "train loss: 0.004907405810309058, at epoch: 63\n",
      "\n",
      "Number of units: 5910\n",
      "train loss: 0.004895634230347241, at epoch: 62\n",
      "\n",
      "Number of units: 5920\n",
      "train loss: 0.004820091113326157, at epoch: 62\n",
      "\n",
      "Number of units: 5930\n",
      "train loss: 0.004928982373914437, at epoch: 62\n",
      "\n",
      "Number of units: 5940\n",
      "train loss: 0.004730270326651862, at epoch: 64\n",
      "\n",
      "Number of units: 5950\n",
      "train loss: 0.0046396777669338, at epoch: 62\n",
      "\n",
      "Number of units: 5960\n",
      "train loss: 0.0048905033508094675, at epoch: 61\n",
      "\n",
      "Number of units: 5970\n",
      "train loss: 0.004526612294172878, at epoch: 64\n",
      "\n",
      "Number of units: 5980\n",
      "train loss: 0.004458771849875802, at epoch: 63\n",
      "\n",
      "Number of units: 5990\n",
      "train loss: 0.00494264991787702, at epoch: 63\n",
      "\n",
      "Number of units: 6000\n",
      "train loss: 0.0045558289151358625, at epoch: 63\n",
      "\n",
      "Number of units: 6010\n",
      "train loss: 0.004957162636250701, at epoch: 62\n",
      "\n",
      "Number of units: 6020\n",
      "train loss: 0.004692547506869573, at epoch: 63\n",
      "\n",
      "Number of units: 6030\n",
      "train loss: 0.004650581726505152, at epoch: 65\n",
      "\n",
      "Number of units: 6040\n",
      "train loss: 0.004997995602004721, at epoch: 61\n",
      "\n",
      "Number of units: 6050\n",
      "train loss: 0.00443506587911088, at epoch: 63\n",
      "\n",
      "Number of units: 6060\n",
      "train loss: 0.0049331105531507545, at epoch: 63\n",
      "\n",
      "Number of units: 6070\n",
      "train loss: 0.004644038936013146, at epoch: 64\n",
      "\n",
      "Number of units: 6080\n",
      "train loss: 0.0047664065340842394, at epoch: 63\n",
      "\n",
      "Number of units: 6090\n",
      "train loss: 0.004876178890371534, at epoch: 62\n",
      "\n",
      "Number of units: 6100\n",
      "train loss: 0.0047357782911564075, at epoch: 61\n",
      "\n",
      "Number of units: 6110\n",
      "train loss: 0.004985281984210133, at epoch: 62\n",
      "\n",
      "Number of units: 6120\n",
      "train loss: 0.004226534604928816, at epoch: 63\n",
      "\n",
      "Number of units: 6130\n",
      "train loss: 0.00430476815664747, at epoch: 63\n",
      "\n",
      "Number of units: 6140\n",
      "train loss: 0.004614151543808021, at epoch: 63\n",
      "\n",
      "Number of units: 6150\n",
      "train loss: 0.004848268182161064, at epoch: 61\n",
      "\n",
      "Number of units: 6160\n",
      "train loss: 0.004904535698813106, at epoch: 63\n",
      "\n",
      "Number of units: 6170\n",
      "train loss: 0.0047943482115272214, at epoch: 62\n",
      "\n",
      "Number of units: 6180\n",
      "train loss: 0.004858144761719814, at epoch: 61\n",
      "\n",
      "Number of units: 6190\n",
      "train loss: 0.0049680410329278855, at epoch: 62\n",
      "\n",
      "Number of units: 6200\n",
      "train loss: 0.004974445558584079, at epoch: 60\n",
      "\n",
      "Number of units: 6210\n",
      "train loss: 0.004689837146831906, at epoch: 61\n",
      "\n",
      "Number of units: 6220\n",
      "train loss: 0.004888552737075429, at epoch: 61\n",
      "\n",
      "Number of units: 6230\n",
      "train loss: 0.0046146618562966065, at epoch: 61\n",
      "\n",
      "Number of units: 6240\n",
      "train loss: 0.004871572434877294, at epoch: 62\n",
      "\n",
      "Number of units: 6250\n",
      "train loss: 0.0049737650487185195, at epoch: 60\n",
      "\n",
      "Number of units: 6260\n",
      "train loss: 0.004878043279619533, at epoch: 61\n",
      "\n",
      "Number of units: 6270\n",
      "train loss: 0.004663870270970278, at epoch: 62\n",
      "\n",
      "Number of units: 6280\n",
      "train loss: 0.004843204430972321, at epoch: 62\n",
      "\n",
      "Number of units: 6290\n",
      "train loss: 0.004942908988410864, at epoch: 60\n",
      "\n",
      "Number of units: 6300\n",
      "train loss: 0.004722958864293787, at epoch: 62\n",
      "\n",
      "Number of units: 6310\n",
      "train loss: 0.0049200054768709835, at epoch: 60\n",
      "\n",
      "Number of units: 6320\n",
      "train loss: 0.004830045930572169, at epoch: 61\n",
      "\n",
      "Number of units: 6330\n",
      "train loss: 0.004956300334599746, at epoch: 62\n",
      "\n",
      "Number of units: 6340\n",
      "train loss: 0.004233983791813216, at epoch: 62\n",
      "\n",
      "Number of units: 6350\n",
      "train loss: 0.00485965963413264, at epoch: 61\n",
      "\n",
      "Number of units: 6360\n",
      "train loss: 0.0048189368124235445, at epoch: 60\n",
      "\n",
      "Number of units: 6370\n",
      "train loss: 0.004544175772231256, at epoch: 60\n",
      "\n",
      "Number of units: 6380\n",
      "train loss: 0.004722283945981189, at epoch: 62\n",
      "\n",
      "Number of units: 6390\n",
      "train loss: 0.004581596042482943, at epoch: 62\n",
      "\n",
      "Number of units: 6400\n",
      "train loss: 0.004827748705268959, at epoch: 62\n",
      "\n",
      "Number of units: 6410\n",
      "train loss: 0.004993076262364866, at epoch: 58\n",
      "\n",
      "Number of units: 6420\n",
      "train loss: 0.004738140037808876, at epoch: 61\n",
      "\n",
      "Number of units: 6430\n",
      "train loss: 0.0044556555668873446, at epoch: 62\n",
      "\n",
      "Number of units: 6440\n",
      "train loss: 0.004850203482366738, at epoch: 63\n",
      "\n",
      "Number of units: 6450\n",
      "train loss: 0.0045096024865569, at epoch: 61\n",
      "\n",
      "Number of units: 6460\n",
      "train loss: 0.004564984629985247, at epoch: 61\n",
      "\n",
      "Number of units: 6470\n",
      "train loss: 0.004835519144000955, at epoch: 60\n",
      "\n",
      "Number of units: 6480\n",
      "train loss: 0.004835676269505598, at epoch: 61\n",
      "\n",
      "Number of units: 6490\n",
      "train loss: 0.004871560305989533, at epoch: 62\n",
      "\n",
      "Number of units: 6500\n",
      "train loss: 0.004723685176277854, at epoch: 61\n",
      "\n",
      "Number of units: 6510\n",
      "train loss: 0.004595160709923789, at epoch: 63\n",
      "\n",
      "Number of units: 6520\n",
      "train loss: 0.004274994796348892, at epoch: 62\n",
      "\n",
      "Number of units: 6530\n",
      "train loss: 0.004886429397971597, at epoch: 61\n",
      "\n",
      "Number of units: 6540\n",
      "train loss: 0.004280733869276219, at epoch: 62\n",
      "\n",
      "Number of units: 6550\n",
      "train loss: 0.004578545757820507, at epoch: 60\n",
      "\n",
      "Number of units: 6560\n",
      "train loss: 0.004709651717570295, at epoch: 60\n",
      "\n",
      "Number of units: 6570\n",
      "train loss: 0.004280821250720237, at epoch: 61\n",
      "\n",
      "Number of units: 6580\n",
      "train loss: 0.0043875657426156065, at epoch: 60\n",
      "\n",
      "Number of units: 6590\n",
      "train loss: 0.004661334484574127, at epoch: 62\n",
      "\n",
      "Number of units: 6600\n",
      "train loss: 0.0046283872664855605, at epoch: 61\n",
      "\n",
      "Number of units: 6610\n",
      "train loss: 0.004880299240141994, at epoch: 60\n",
      "\n",
      "Number of units: 6620\n",
      "train loss: 0.004756169847273668, at epoch: 59\n",
      "\n",
      "Number of units: 6630\n",
      "train loss: 0.004857218589777545, at epoch: 60\n",
      "\n",
      "Number of units: 6640\n",
      "train loss: 0.004858331249585035, at epoch: 60\n",
      "\n",
      "Number of units: 6650\n",
      "train loss: 0.004875057228103969, at epoch: 62\n",
      "\n",
      "Number of units: 6660\n",
      "train loss: 0.004742999524885363, at epoch: 60\n",
      "\n",
      "Number of units: 6670\n",
      "train loss: 0.004933490411537491, at epoch: 60\n",
      "\n",
      "Number of units: 6680\n",
      "train loss: 0.004742251480711843, at epoch: 61\n",
      "\n",
      "Number of units: 6690\n",
      "train loss: 0.0047843439380449125, at epoch: 61\n",
      "\n",
      "Number of units: 6700\n",
      "train loss: 0.004947882267372279, at epoch: 61\n",
      "\n",
      "Number of units: 6710\n",
      "train loss: 0.004503566104705783, at epoch: 61\n",
      "\n",
      "Number of units: 6720\n",
      "train loss: 0.0047316924550733575, at epoch: 60\n",
      "\n",
      "Number of units: 6730\n",
      "train loss: 0.004878493784003695, at epoch: 59\n",
      "\n",
      "Number of units: 6740\n",
      "train loss: 0.004941091725871729, at epoch: 59\n",
      "\n",
      "Number of units: 6750\n",
      "train loss: 0.00457037528511762, at epoch: 60\n",
      "\n",
      "Number of units: 6760\n",
      "train loss: 0.004837287738970986, at epoch: 59\n",
      "\n",
      "Number of units: 6770\n",
      "train loss: 0.004260405995714791, at epoch: 59\n",
      "\n",
      "Number of units: 6780\n",
      "train loss: 0.0049906423329690594, at epoch: 59\n",
      "\n",
      "Number of units: 6790\n",
      "train loss: 0.0044405797649653776, at epoch: 59\n",
      "\n",
      "Number of units: 6800\n",
      "train loss: 0.004710128295847085, at epoch: 60\n",
      "\n",
      "Number of units: 6810\n",
      "train loss: 0.004708737827063487, at epoch: 61\n",
      "\n",
      "Number of units: 6820\n",
      "train loss: 0.004585975054441178, at epoch: 61\n",
      "\n",
      "Number of units: 6830\n",
      "train loss: 0.004810837248003281, at epoch: 59\n",
      "\n",
      "Number of units: 6840\n",
      "train loss: 0.004776111510580563, at epoch: 60\n",
      "\n",
      "Number of units: 6850\n",
      "train loss: 0.004933641589009313, at epoch: 60\n",
      "\n",
      "Number of units: 6860\n",
      "train loss: 0.004797057466203683, at epoch: 60\n",
      "\n",
      "Number of units: 6870\n",
      "train loss: 0.004862270950114862, at epoch: 62\n",
      "\n",
      "Number of units: 6880\n",
      "train loss: 0.004674658120858339, at epoch: 60\n",
      "\n",
      "Number of units: 6890\n",
      "train loss: 0.0049391759002014625, at epoch: 59\n",
      "\n",
      "Number of units: 6900\n",
      "train loss: 0.004824613727790848, at epoch: 60\n",
      "\n",
      "Number of units: 6910\n",
      "train loss: 0.004957849112715848, at epoch: 60\n",
      "\n",
      "Number of units: 6920\n",
      "train loss: 0.0043712771959289395, at epoch: 60\n",
      "\n",
      "Number of units: 6930\n",
      "train loss: 0.004961131039246424, at epoch: 59\n",
      "\n",
      "Number of units: 6940\n",
      "train loss: 0.00498957714801918, at epoch: 59\n",
      "\n",
      "Number of units: 6950\n",
      "train loss: 0.004765649293882461, at epoch: 58\n",
      "\n",
      "Number of units: 6960\n",
      "train loss: 0.004320958121979288, at epoch: 61\n",
      "\n",
      "Number of units: 6970\n",
      "train loss: 0.00433899037712024, at epoch: 63\n",
      "\n",
      "Number of units: 6980\n",
      "train loss: 0.004848389489941382, at epoch: 60\n",
      "\n",
      "Number of units: 6990\n",
      "train loss: 0.004936388625816051, at epoch: 58\n",
      "\n",
      "Number of units: 7000\n",
      "train loss: 0.004220537086177955, at epoch: 61\n",
      "\n",
      "Number of units: 7010\n",
      "train loss: 0.004554155124711769, at epoch: 60\n",
      "\n",
      "Number of units: 7020\n",
      "train loss: 0.004556199481464205, at epoch: 60\n",
      "\n",
      "Number of units: 7030\n",
      "train loss: 0.00485407113434178, at epoch: 59\n",
      "\n",
      "Number of units: 7040\n",
      "train loss: 0.004919669283950725, at epoch: 58\n",
      "\n",
      "Number of units: 7050\n",
      "train loss: 0.004731768882607099, at epoch: 59\n",
      "\n",
      "Number of units: 7060\n",
      "train loss: 0.004353200323011492, at epoch: 61\n",
      "\n",
      "Number of units: 7070\n",
      "train loss: 0.004424967563703035, at epoch: 60\n",
      "\n",
      "Number of units: 7080\n",
      "train loss: 0.004607907281331336, at epoch: 61\n",
      "\n",
      "Number of units: 7090\n",
      "train loss: 0.00491431707817128, at epoch: 62\n",
      "\n",
      "Number of units: 7100\n",
      "train loss: 0.004616289451534499, at epoch: 59\n",
      "\n",
      "Number of units: 7110\n",
      "train loss: 0.004739251197496515, at epoch: 59\n",
      "\n",
      "Number of units: 7120\n",
      "train loss: 0.004718091513132095, at epoch: 59\n",
      "\n",
      "Number of units: 7130\n",
      "train loss: 0.00484661232948497, at epoch: 58\n",
      "\n",
      "Number of units: 7140\n",
      "train loss: 0.004794304775042519, at epoch: 58\n",
      "\n",
      "Number of units: 7150\n",
      "train loss: 0.004821285860667785, at epoch: 59\n",
      "\n",
      "Number of units: 7160\n",
      "train loss: 0.004896816199566274, at epoch: 60\n",
      "\n",
      "Number of units: 7170\n",
      "train loss: 0.004609566403537428, at epoch: 60\n",
      "\n",
      "Number of units: 7180\n",
      "train loss: 0.004952804192314488, at epoch: 58\n",
      "\n",
      "Number of units: 7190\n",
      "train loss: 0.004493028641356318, at epoch: 60\n",
      "\n",
      "Number of units: 7200\n",
      "train loss: 0.004987564333532646, at epoch: 58\n",
      "\n",
      "Number of units: 7210\n",
      "train loss: 0.004859512989464747, at epoch: 59\n",
      "\n",
      "Number of units: 7220\n",
      "train loss: 0.004984480578467582, at epoch: 57\n",
      "\n",
      "Number of units: 7230\n",
      "train loss: 0.004869040210850244, at epoch: 58\n",
      "\n",
      "Number of units: 7240\n",
      "train loss: 0.004963229843385761, at epoch: 59\n",
      "\n",
      "Number of units: 7250\n",
      "train loss: 0.004334623614711291, at epoch: 59\n",
      "\n",
      "Number of units: 7260\n",
      "train loss: 0.004884935753126456, at epoch: 59\n",
      "\n",
      "Number of units: 7270\n",
      "train loss: 0.004696973584270268, at epoch: 58\n",
      "\n",
      "Number of units: 7280\n",
      "train loss: 0.004934519511746203, at epoch: 57\n",
      "\n",
      "Number of units: 7290\n",
      "train loss: 0.004963387171779914, at epoch: 60\n",
      "\n",
      "Number of units: 7300\n",
      "train loss: 0.004694676485024729, at epoch: 59\n",
      "\n",
      "Number of units: 7310\n",
      "train loss: 0.004954174923994401, at epoch: 57\n",
      "\n",
      "Number of units: 7320\n",
      "train loss: 0.0049619550707598135, at epoch: 58\n",
      "\n",
      "Number of units: 7330\n",
      "train loss: 0.004675716099527562, at epoch: 59\n",
      "\n",
      "Number of units: 7340\n",
      "train loss: 0.0048244044840657805, at epoch: 59\n",
      "\n",
      "Number of units: 7350\n",
      "train loss: 0.004854117115590952, at epoch: 59\n",
      "\n",
      "Number of units: 7360\n",
      "train loss: 0.004778061196749377, at epoch: 58\n",
      "\n",
      "Number of units: 7370\n",
      "train loss: 0.0047262784117555155, at epoch: 68\n",
      "\n",
      "Number of units: 7380\n",
      "train loss: 0.004547145147151639, at epoch: 61\n",
      "\n",
      "Number of units: 7390\n",
      "train loss: 0.0049986309014309425, at epoch: 57\n",
      "\n",
      "Number of units: 7400\n",
      "train loss: 0.004957748107810289, at epoch: 58\n",
      "\n",
      "Number of units: 7410\n",
      "train loss: 0.004829622057365555, at epoch: 58\n",
      "\n",
      "Number of units: 7420\n",
      "train loss: 0.004981047719787171, at epoch: 58\n",
      "\n",
      "Number of units: 7430\n",
      "train loss: 0.004662804806052918, at epoch: 58\n",
      "\n",
      "Number of units: 7440\n",
      "train loss: 0.0046471168881942046, at epoch: 58\n",
      "\n",
      "Number of units: 7450\n",
      "train loss: 0.004738192552798637, at epoch: 58\n",
      "\n",
      "Number of units: 7460\n",
      "train loss: 0.004682598487344762, at epoch: 59\n",
      "\n",
      "Number of units: 7470\n",
      "train loss: 0.004573875918651993, at epoch: 58\n",
      "\n",
      "Number of units: 7480\n",
      "train loss: 0.004954674558275656, at epoch: 57\n",
      "\n",
      "Number of units: 7490\n",
      "train loss: 0.004918613882491058, at epoch: 58\n",
      "\n",
      "Number of units: 7500\n",
      "train loss: 0.004984936334831786, at epoch: 69\n",
      "\n",
      "Number of units: 7510\n",
      "train loss: 0.00495881006316381, at epoch: 57\n",
      "\n",
      "Number of units: 7520\n",
      "train loss: 0.004637428493745119, at epoch: 59\n",
      "\n",
      "Number of units: 7530\n",
      "train loss: 0.004580615758246722, at epoch: 58\n",
      "\n",
      "Number of units: 7540\n",
      "train loss: 0.004130818326613621, at epoch: 61\n",
      "\n",
      "Number of units: 7550\n",
      "train loss: 0.004666001035297995, at epoch: 58\n",
      "\n",
      "Number of units: 7560\n",
      "train loss: 0.004977055111600634, at epoch: 58\n",
      "\n",
      "Number of units: 7570\n",
      "train loss: 0.004653320956819016, at epoch: 58\n",
      "\n",
      "Number of units: 7580\n",
      "train loss: 0.004942639260156057, at epoch: 59\n",
      "\n",
      "Number of units: 7590\n",
      "train loss: 0.0049994424748661, at epoch: 58\n",
      "\n",
      "Number of units: 7600\n",
      "train loss: 0.004660438543976397, at epoch: 58\n",
      "\n",
      "Number of units: 7610\n",
      "train loss: 0.004872908235988689, at epoch: 59\n",
      "\n",
      "Number of units: 7620\n",
      "train loss: 0.0046781110066194745, at epoch: 58\n",
      "\n",
      "Number of units: 7630\n",
      "train loss: 0.004934892626830276, at epoch: 57\n",
      "\n",
      "Number of units: 7640\n",
      "train loss: 0.004602916159442714, at epoch: 58\n",
      "\n",
      "Number of units: 7650\n",
      "train loss: 0.004904242471972111, at epoch: 57\n",
      "\n",
      "Number of units: 7660\n",
      "train loss: 0.004487033223032313, at epoch: 58\n",
      "\n",
      "Number of units: 7670\n",
      "train loss: 0.004182140874324319, at epoch: 59\n",
      "\n",
      "Number of units: 7680\n",
      "train loss: 0.004525641177671673, at epoch: 59\n",
      "\n",
      "Number of units: 7690\n",
      "train loss: 0.004895162737307146, at epoch: 58\n",
      "\n",
      "Number of units: 7700\n",
      "train loss: 0.004799354790611688, at epoch: 58\n",
      "\n",
      "Number of units: 7710\n",
      "train loss: 0.00449813590921849, at epoch: 58\n",
      "\n",
      "Number of units: 7720\n",
      "train loss: 0.004948444129997825, at epoch: 57\n",
      "\n",
      "Number of units: 7730\n",
      "train loss: 0.004955519725349404, at epoch: 57\n",
      "\n",
      "Number of units: 7740\n",
      "train loss: 0.004706045869045426, at epoch: 58\n",
      "\n",
      "Number of units: 7750\n",
      "train loss: 0.004684577363442486, at epoch: 59\n",
      "\n",
      "Number of units: 7760\n",
      "train loss: 0.004842896160797636, at epoch: 57\n",
      "\n",
      "Number of units: 7770\n",
      "train loss: 0.004530133808307255, at epoch: 59\n",
      "\n",
      "Number of units: 7780\n",
      "train loss: 0.004314117458418423, at epoch: 59\n",
      "\n",
      "Number of units: 7790\n",
      "train loss: 0.004908434754520385, at epoch: 57\n",
      "\n",
      "Number of units: 7800\n",
      "train loss: 0.004573448527855817, at epoch: 58\n",
      "\n",
      "Number of units: 7810\n",
      "train loss: 0.004848957152387356, at epoch: 57\n",
      "\n",
      "Number of units: 7820\n",
      "train loss: 0.004639119540559023, at epoch: 57\n",
      "\n",
      "Number of units: 7830\n",
      "train loss: 0.0047460559122299625, at epoch: 58\n",
      "\n",
      "Number of units: 7840\n",
      "train loss: 0.004821764501383541, at epoch: 57\n",
      "\n",
      "Number of units: 7850\n",
      "train loss: 0.004951197124210011, at epoch: 55\n",
      "\n",
      "Number of units: 7860\n",
      "train loss: 0.004620907424514371, at epoch: 57\n",
      "\n",
      "Number of units: 7870\n",
      "train loss: 0.0047892785371891474, at epoch: 58\n",
      "\n",
      "Number of units: 7880\n",
      "train loss: 0.004888480386085803, at epoch: 56\n",
      "\n",
      "Number of units: 7890\n",
      "train loss: 0.004351047502856887, at epoch: 58\n",
      "\n",
      "Number of units: 7900\n",
      "train loss: 0.004971726573023716, at epoch: 56\n",
      "\n",
      "Number of units: 7910\n",
      "train loss: 0.004862679299204729, at epoch: 59\n",
      "\n",
      "Number of units: 7920\n",
      "train loss: 0.004640372624989481, at epoch: 68\n",
      "\n",
      "Number of units: 7930\n",
      "train loss: 0.004922683186030099, at epoch: 56\n",
      "\n",
      "Number of units: 7940\n",
      "train loss: 0.00467264846586204, at epoch: 58\n",
      "\n",
      "Number of units: 7950\n",
      "train loss: 0.00488498734416396, at epoch: 58\n",
      "\n",
      "Number of units: 7960\n",
      "train loss: 0.004813111110822774, at epoch: 57\n",
      "\n",
      "Number of units: 7970\n",
      "train loss: 0.004438460382473295, at epoch: 58\n",
      "\n",
      "Number of units: 7980\n",
      "train loss: 0.004530718191155643, at epoch: 58\n",
      "\n",
      "Number of units: 7990\n",
      "train loss: 0.004863158765350022, at epoch: 56\n",
      "\n",
      "Number of units: 8000\n",
      "train loss: 0.004860825519319292, at epoch: 57\n",
      "\n",
      "Number of units: 8010\n",
      "train loss: 0.004995980784808012, at epoch: 57\n",
      "\n",
      "Number of units: 8020\n",
      "train loss: 0.004673491731576291, at epoch: 57\n",
      "\n",
      "Number of units: 8030\n",
      "train loss: 0.004592420843748641, at epoch: 57\n",
      "\n",
      "Number of units: 8040\n",
      "train loss: 0.004873244823923528, at epoch: 56\n",
      "\n",
      "Number of units: 8050\n",
      "train loss: 0.004904220132347064, at epoch: 57\n",
      "\n",
      "Number of units: 8060\n",
      "train loss: 0.00495079330709018, at epoch: 56\n",
      "\n",
      "Number of units: 8070\n",
      "train loss: 0.004911127820786305, at epoch: 56\n",
      "\n",
      "Number of units: 8080\n",
      "train loss: 0.004916431866602125, at epoch: 55\n",
      "\n",
      "Number of units: 8090\n",
      "train loss: 0.004898893119996046, at epoch: 56\n",
      "\n",
      "Number of units: 8100\n",
      "train loss: 0.004990545929915129, at epoch: 57\n",
      "\n",
      "Number of units: 8110\n",
      "train loss: 0.004623798197333145, at epoch: 57\n",
      "\n",
      "Number of units: 8120\n",
      "train loss: 0.004952409703682861, at epoch: 55\n",
      "\n",
      "Number of units: 8130\n",
      "train loss: 0.004550052807683187, at epoch: 58\n",
      "\n",
      "Number of units: 8140\n",
      "train loss: 0.004744776882809561, at epoch: 57\n",
      "\n",
      "Number of units: 8150\n",
      "train loss: 0.0049441537583214765, at epoch: 58\n",
      "\n",
      "Number of units: 8160\n",
      "train loss: 0.004332698047712711, at epoch: 58\n",
      "\n",
      "Number of units: 8170\n",
      "train loss: 0.0043636346207063074, at epoch: 58\n",
      "\n",
      "Number of units: 8180\n",
      "train loss: 0.004729686757833633, at epoch: 57\n",
      "\n",
      "Number of units: 8190\n",
      "train loss: 0.004645434532736772, at epoch: 57\n",
      "\n",
      "Number of units: 8200\n",
      "train loss: 0.004820117616885682, at epoch: 56\n",
      "\n",
      "Number of units: 8210\n",
      "train loss: 0.004486304441395532, at epoch: 58\n",
      "\n",
      "Number of units: 8220\n",
      "train loss: 0.004557760803210158, at epoch: 56\n",
      "\n",
      "Number of units: 8230\n",
      "train loss: 0.004943595645314645, at epoch: 56\n",
      "\n",
      "Number of units: 8240\n",
      "train loss: 0.004913959555644851, at epoch: 56\n",
      "\n",
      "Number of units: 8250\n",
      "train loss: 0.004636673430744622, at epoch: 56\n",
      "\n",
      "Number of units: 8260\n",
      "train loss: 0.004951623060233033, at epoch: 55\n",
      "\n",
      "Number of units: 8270\n",
      "train loss: 0.004907999824889657, at epoch: 56\n",
      "\n",
      "Number of units: 8280\n",
      "train loss: 0.0047486647175105645, at epoch: 56\n",
      "\n",
      "Number of units: 8290\n",
      "train loss: 0.004841377560599085, at epoch: 58\n",
      "\n",
      "Number of units: 8300\n",
      "train loss: 0.004700574166308229, at epoch: 57\n",
      "\n",
      "Number of units: 8310\n",
      "train loss: 0.0043603097741078045, at epoch: 58\n",
      "\n",
      "Number of units: 8320\n",
      "train loss: 0.004925886192742155, at epoch: 55\n",
      "\n",
      "Number of units: 8330\n",
      "train loss: 0.004706382122768389, at epoch: 58\n",
      "\n",
      "Number of units: 8340\n",
      "train loss: 0.004465778963478897, at epoch: 56\n",
      "\n",
      "Number of units: 8350\n",
      "train loss: 0.004713936771827321, at epoch: 57\n",
      "\n",
      "Number of units: 8360\n",
      "train loss: 0.004736279707413474, at epoch: 55\n",
      "\n",
      "Number of units: 8370\n",
      "train loss: 0.0043614315419404194, at epoch: 57\n",
      "\n",
      "Number of units: 8380\n",
      "train loss: 0.004579414048316153, at epoch: 57\n",
      "\n",
      "Number of units: 8390\n",
      "train loss: 0.004743654474045797, at epoch: 56\n",
      "\n",
      "Number of units: 8400\n",
      "train loss: 0.004815633938263773, at epoch: 55\n",
      "\n",
      "Number of units: 8410\n",
      "train loss: 0.004900994012379556, at epoch: 55\n",
      "\n",
      "Number of units: 8420\n",
      "train loss: 0.0044380892644983305, at epoch: 57\n",
      "\n",
      "Number of units: 8430\n",
      "train loss: 0.00466835297286309, at epoch: 58\n",
      "\n",
      "Number of units: 8440\n",
      "train loss: 0.004947004869678437, at epoch: 56\n",
      "\n",
      "Number of units: 8450\n",
      "train loss: 0.004651391665217944, at epoch: 56\n",
      "\n",
      "Number of units: 8460\n",
      "train loss: 0.004897861913975134, at epoch: 56\n",
      "\n",
      "Number of units: 8470\n",
      "train loss: 0.004807420575920105, at epoch: 56\n",
      "\n",
      "Number of units: 8480\n",
      "train loss: 0.004280664733971662, at epoch: 58\n",
      "\n",
      "Number of units: 8490\n",
      "train loss: 0.0048596065909134725, at epoch: 57\n",
      "\n",
      "Number of units: 8500\n",
      "train loss: 0.0042937913210434435, at epoch: 57\n",
      "\n",
      "Number of units: 8510\n",
      "train loss: 0.0045121903068206844, at epoch: 57\n",
      "\n",
      "Number of units: 8520\n",
      "train loss: 0.004990144874619489, at epoch: 55\n",
      "\n",
      "Number of units: 8530\n",
      "train loss: 0.004908298371411206, at epoch: 57\n",
      "\n",
      "Number of units: 8540\n",
      "train loss: 0.004784665057221673, at epoch: 55\n",
      "\n",
      "Number of units: 8550\n",
      "train loss: 0.0046362533673084275, at epoch: 57\n",
      "\n",
      "Number of units: 8560\n",
      "train loss: 0.004785465726782832, at epoch: 56\n",
      "\n",
      "Number of units: 8570\n",
      "train loss: 0.004909982625849807, at epoch: 55\n",
      "\n",
      "Number of units: 8580\n",
      "train loss: 0.004679249880015277, at epoch: 55\n",
      "\n",
      "Number of units: 8590\n",
      "train loss: 0.004676651330021287, at epoch: 57\n",
      "\n",
      "Number of units: 8600\n",
      "train loss: 0.004664539233164078, at epoch: 56\n",
      "\n",
      "Number of units: 8610\n",
      "train loss: 0.004401079752946089, at epoch: 57\n",
      "\n",
      "Number of units: 8620\n",
      "train loss: 0.004855642711892756, at epoch: 57\n",
      "\n",
      "Number of units: 8630\n",
      "train loss: 0.0049877292820679035, at epoch: 56\n",
      "\n",
      "Number of units: 8640\n",
      "train loss: 0.004968351669798494, at epoch: 55\n",
      "\n",
      "Number of units: 8650\n",
      "train loss: 0.004910493140378094, at epoch: 56\n",
      "\n",
      "Number of units: 8660\n",
      "train loss: 0.004752640706209945, at epoch: 57\n",
      "\n",
      "Number of units: 8670\n",
      "train loss: 0.004583579874063162, at epoch: 56\n",
      "\n",
      "Number of units: 8680\n",
      "train loss: 0.00442926014338866, at epoch: 57\n",
      "\n",
      "Number of units: 8690\n",
      "train loss: 0.004661153049809173, at epoch: 55\n",
      "\n",
      "Number of units: 8700\n",
      "train loss: 0.004625806534315871, at epoch: 56\n",
      "\n",
      "Number of units: 8710\n",
      "train loss: 0.004207698670136324, at epoch: 58\n",
      "\n",
      "Number of units: 8720\n",
      "train loss: 0.004892509533436851, at epoch: 55\n",
      "\n",
      "Number of units: 8730\n",
      "train loss: 0.004989138610609984, at epoch: 54\n",
      "\n",
      "Number of units: 8740\n",
      "train loss: 0.004852631519025863, at epoch: 56\n",
      "\n",
      "Number of units: 8750\n",
      "train loss: 0.00487288221905601, at epoch: 54\n",
      "\n",
      "Number of units: 8760\n",
      "train loss: 0.00449022727500278, at epoch: 56\n",
      "\n",
      "Number of units: 8770\n",
      "train loss: 0.004945429033870141, at epoch: 55\n",
      "\n",
      "Number of units: 8780\n",
      "train loss: 0.00495238074531585, at epoch: 54\n",
      "\n",
      "Number of units: 8790\n",
      "train loss: 0.004751511095488468, at epoch: 55\n",
      "\n",
      "Number of units: 8800\n",
      "train loss: 0.004891648390168939, at epoch: 57\n",
      "\n",
      "Number of units: 8810\n",
      "train loss: 0.004718828272500559, at epoch: 56\n",
      "\n",
      "Number of units: 8820\n",
      "train loss: 0.004905234515948109, at epoch: 55\n",
      "\n",
      "Number of units: 8830\n",
      "train loss: 0.00469010913357863, at epoch: 56\n",
      "\n",
      "Number of units: 8840\n",
      "train loss: 0.0049318346218484525, at epoch: 55\n",
      "\n",
      "Number of units: 8850\n",
      "train loss: 0.004731731354229396, at epoch: 56\n",
      "\n",
      "Number of units: 8860\n",
      "train loss: 0.004403088635357904, at epoch: 56\n",
      "\n",
      "Number of units: 8870\n",
      "train loss: 0.004985984645123835, at epoch: 54\n",
      "\n",
      "Number of units: 8880\n",
      "train loss: 0.004825578032666727, at epoch: 56\n",
      "\n",
      "Number of units: 8890\n",
      "train loss: 0.004668857510675366, at epoch: 55\n",
      "\n",
      "Number of units: 8900\n",
      "train loss: 0.004984516412464473, at epoch: 55\n",
      "\n",
      "Number of units: 8910\n",
      "train loss: 0.0048323305725043045, at epoch: 54\n",
      "\n",
      "Number of units: 8920\n",
      "train loss: 0.00464258992239138, at epoch: 55\n",
      "\n",
      "Number of units: 8930\n",
      "train loss: 0.004962357715695589, at epoch: 55\n",
      "\n",
      "Number of units: 8940\n",
      "train loss: 0.004552095778693683, at epoch: 56\n",
      "\n",
      "Number of units: 8950\n",
      "train loss: 0.0047545090686560345, at epoch: 54\n",
      "\n",
      "Number of units: 8960\n",
      "train loss: 0.004955619912770999, at epoch: 54\n",
      "\n",
      "Number of units: 8970\n",
      "train loss: 0.004779681391109989, at epoch: 56\n",
      "\n",
      "Number of units: 8980\n",
      "train loss: 0.004801803233940518, at epoch: 55\n",
      "\n",
      "Number of units: 8990\n",
      "train loss: 0.004695852136668463, at epoch: 55\n",
      "\n",
      "Number of units: 9000\n",
      "train loss: 0.00478368982834752, at epoch: 56\n",
      "\n",
      "Number of units: 9010\n",
      "train loss: 0.004633104166975386, at epoch: 55\n",
      "\n",
      "Number of units: 9020\n",
      "train loss: 0.0048142463770926725, at epoch: 55\n",
      "\n",
      "Number of units: 9030\n",
      "train loss: 0.004547227519595367, at epoch: 56\n",
      "\n",
      "Number of units: 9040\n",
      "train loss: 0.004903353192582926, at epoch: 54\n",
      "\n",
      "Number of units: 9050\n",
      "train loss: 0.004711999668645603, at epoch: 54\n",
      "\n",
      "Number of units: 9060\n",
      "train loss: 0.00451015702815198, at epoch: 56\n",
      "\n",
      "Number of units: 9070\n",
      "train loss: 0.0048127782356522176, at epoch: 56\n",
      "\n",
      "Number of units: 9080\n",
      "train loss: 0.004504439587584556, at epoch: 56\n",
      "\n",
      "Number of units: 9090\n",
      "train loss: 0.0048309066670640275, at epoch: 55\n",
      "\n",
      "Number of units: 9100\n",
      "train loss: 0.004743252578980446, at epoch: 54\n",
      "\n",
      "Number of units: 9110\n",
      "train loss: 0.004359121332995528, at epoch: 56\n",
      "\n",
      "Number of units: 9120\n",
      "train loss: 0.0048833265200892125, at epoch: 54\n",
      "\n",
      "Number of units: 9130\n",
      "train loss: 0.004760286140819972, at epoch: 56\n",
      "\n",
      "Number of units: 9140\n",
      "train loss: 0.004260581985723775, at epoch: 57\n",
      "\n",
      "Number of units: 9150\n",
      "train loss: 0.00470996212380328, at epoch: 55\n",
      "\n",
      "Number of units: 9160\n",
      "train loss: 0.004532233947750228, at epoch: 55\n",
      "\n",
      "Number of units: 9170\n",
      "train loss: 0.004948412109583842, at epoch: 54\n",
      "\n",
      "Number of units: 9180\n",
      "train loss: 0.004903048060726291, at epoch: 53\n",
      "\n",
      "Number of units: 9190\n",
      "train loss: 0.004368163567151555, at epoch: 56\n",
      "\n",
      "Number of units: 9200\n",
      "train loss: 0.00481818157151423, at epoch: 56\n",
      "\n",
      "Number of units: 9210\n",
      "train loss: 0.004763423148549464, at epoch: 55\n",
      "\n",
      "Number of units: 9220\n",
      "train loss: 0.0045960087489288525, at epoch: 55\n",
      "\n",
      "Number of units: 9230\n",
      "train loss: 0.0047011752883562965, at epoch: 54\n",
      "\n",
      "Number of units: 9240\n",
      "train loss: 0.004568193812604022, at epoch: 55\n",
      "\n",
      "Number of units: 9250\n",
      "train loss: 0.004803725262619878, at epoch: 55\n",
      "\n",
      "Number of units: 9260\n",
      "train loss: 0.00474387559910781, at epoch: 54\n",
      "\n",
      "Number of units: 9270\n",
      "train loss: 0.0046137308350887455, at epoch: 55\n",
      "\n",
      "Number of units: 9280\n",
      "train loss: 0.0049164829861035745, at epoch: 55\n",
      "\n",
      "Number of units: 9290\n",
      "train loss: 0.004897916351108051, at epoch: 54\n",
      "\n",
      "Number of units: 9300\n",
      "train loss: 0.0049879638203367445, at epoch: 53\n",
      "\n",
      "Number of units: 9310\n",
      "train loss: 0.0049685689835519044, at epoch: 54\n",
      "\n",
      "Number of units: 9320\n",
      "train loss: 0.004264502314038054, at epoch: 55\n",
      "\n",
      "Number of units: 9330\n",
      "train loss: 0.004646791632611666, at epoch: 54\n",
      "\n",
      "Number of units: 9340\n",
      "train loss: 0.004619122517500501, at epoch: 55\n",
      "\n",
      "Number of units: 9350\n",
      "train loss: 0.004837337393729513, at epoch: 54\n",
      "\n",
      "Number of units: 9360\n",
      "train loss: 0.004334315142493779, at epoch: 54\n",
      "\n",
      "Number of units: 9370\n",
      "train loss: 0.004534882351854321, at epoch: 54\n",
      "\n",
      "Number of units: 9380\n",
      "train loss: 0.004939016125367743, at epoch: 54\n",
      "\n",
      "Number of units: 9390\n",
      "train loss: 0.0049987053891078406, at epoch: 53\n",
      "\n",
      "Number of units: 9400\n",
      "train loss: 0.004682208142914987, at epoch: 54\n",
      "\n",
      "Number of units: 9410\n",
      "train loss: 0.004601521441382488, at epoch: 55\n",
      "\n",
      "Number of units: 9420\n",
      "train loss: 0.004906638295954053, at epoch: 55\n",
      "\n",
      "Number of units: 9430\n",
      "train loss: 0.0047631351092127265, at epoch: 53\n",
      "\n",
      "Number of units: 9440\n",
      "train loss: 0.0048979415124392744, at epoch: 55\n",
      "\n",
      "Number of units: 9450\n",
      "train loss: 0.004924864021184305, at epoch: 54\n",
      "\n",
      "Number of units: 9460\n",
      "train loss: 0.004792756795325204, at epoch: 54\n",
      "\n",
      "Number of units: 9470\n",
      "train loss: 0.00493207406775241, at epoch: 54\n",
      "\n",
      "Number of units: 9480\n",
      "train loss: 0.004217816062578379, at epoch: 56\n",
      "\n",
      "Number of units: 9490\n",
      "train loss: 0.00465915672100607, at epoch: 55\n",
      "\n",
      "Number of units: 9500\n",
      "train loss: 0.0040128432558111625, at epoch: 56\n",
      "\n",
      "Number of units: 9510\n",
      "train loss: 0.004997434592539775, at epoch: 55\n",
      "\n",
      "Number of units: 9520\n",
      "train loss: 0.0048007761369643735, at epoch: 53\n",
      "\n",
      "Number of units: 9530\n",
      "train loss: 0.004972130827420642, at epoch: 54\n",
      "\n",
      "Number of units: 9540\n",
      "train loss: 0.00483062442592427, at epoch: 55\n",
      "\n",
      "Number of units: 9550\n",
      "train loss: 0.004296263338883932, at epoch: 56\n",
      "\n",
      "Number of units: 9560\n",
      "train loss: 0.004758126833563097, at epoch: 54\n",
      "\n",
      "Number of units: 9570\n",
      "train loss: 0.004637963037059194, at epoch: 55\n",
      "\n",
      "Number of units: 9580\n",
      "train loss: 0.004893837120495732, at epoch: 55\n",
      "\n",
      "Number of units: 9590\n",
      "train loss: 0.004952939702550338, at epoch: 55\n",
      "\n",
      "Number of units: 9600\n",
      "train loss: 0.004241850150220614, at epoch: 56\n",
      "\n",
      "Number of units: 9610\n",
      "train loss: 0.004768252627530956, at epoch: 54\n",
      "\n",
      "Number of units: 9620\n",
      "train loss: 0.0043562414232940225, at epoch: 54\n",
      "\n",
      "Number of units: 9630\n",
      "train loss: 0.004954996358285371, at epoch: 54\n",
      "\n",
      "Number of units: 9640\n",
      "train loss: 0.004859324657618913, at epoch: 53\n",
      "\n",
      "Number of units: 9650\n",
      "train loss: 0.004590449327877195, at epoch: 53\n",
      "\n",
      "Number of units: 9660\n",
      "train loss: 0.004779770662958071, at epoch: 54\n",
      "\n",
      "Number of units: 9670\n",
      "train loss: 0.004845763809782398, at epoch: 54\n",
      "\n",
      "Number of units: 9680\n",
      "train loss: 0.004991311971502341, at epoch: 53\n",
      "\n",
      "Number of units: 9690\n",
      "train loss: 0.004808279949295411, at epoch: 54\n",
      "\n",
      "Number of units: 9700\n",
      "train loss: 0.0048976486614651545, at epoch: 54\n",
      "\n",
      "Number of units: 9710\n",
      "train loss: 0.004888373975656463, at epoch: 55\n",
      "\n",
      "Number of units: 9720\n",
      "train loss: 0.004908834329793876, at epoch: 54\n",
      "\n",
      "Number of units: 9730\n",
      "train loss: 0.004933217841035002, at epoch: 53\n",
      "\n",
      "Number of units: 9740\n",
      "train loss: 0.004744475591851369, at epoch: 55\n",
      "\n",
      "Number of units: 9750\n",
      "train loss: 0.004613604062517993, at epoch: 54\n",
      "\n",
      "Number of units: 9760\n",
      "train loss: 0.004351581147900561, at epoch: 54\n",
      "\n",
      "Number of units: 9770\n",
      "train loss: 0.004984030890011581, at epoch: 52\n",
      "\n",
      "Number of units: 9780\n",
      "train loss: 0.004680021314788974, at epoch: 53\n",
      "\n",
      "Number of units: 9790\n",
      "train loss: 0.004550319422185112, at epoch: 53\n",
      "\n",
      "Number of units: 9800\n",
      "train loss: 0.004873394221406784, at epoch: 53\n",
      "\n",
      "Number of units: 9810\n",
      "train loss: 0.004622941372759897, at epoch: 54\n",
      "\n",
      "Number of units: 9820\n",
      "train loss: 0.004415606348259189, at epoch: 54\n",
      "\n",
      "Number of units: 9830\n",
      "train loss: 0.00496494036047352, at epoch: 52\n",
      "\n",
      "Number of units: 9840\n",
      "train loss: 0.004571826134178991, at epoch: 55\n",
      "\n",
      "Number of units: 9850\n",
      "train loss: 0.004585891460725122, at epoch: 53\n",
      "\n",
      "Number of units: 9860\n",
      "train loss: 0.0047464211975750455, at epoch: 54\n",
      "\n",
      "Number of units: 9870\n",
      "train loss: 0.004442353609140923, at epoch: 54\n",
      "\n",
      "Number of units: 9880\n",
      "train loss: 0.004535216321088455, at epoch: 53\n",
      "\n",
      "Number of units: 9890\n",
      "train loss: 0.004644767535420442, at epoch: 53\n",
      "\n",
      "Number of units: 9900\n",
      "train loss: 0.004731498244135537, at epoch: 53\n",
      "\n",
      "Number of units: 9910\n",
      "train loss: 0.00497745552046922, at epoch: 54\n",
      "\n",
      "Number of units: 9920\n",
      "train loss: 0.00494657487176255, at epoch: 53\n",
      "\n",
      "Number of units: 9930\n",
      "train loss: 0.004934351729028777, at epoch: 52\n",
      "\n",
      "Number of units: 9940\n",
      "train loss: 0.004713075504976132, at epoch: 53\n",
      "\n",
      "Number of units: 9950\n",
      "train loss: 0.004864717187134033, at epoch: 54\n",
      "\n",
      "Number of units: 9960\n",
      "train loss: 0.00464340203803772, at epoch: 53\n",
      "\n",
      "Number of units: 9970\n",
      "train loss: 0.004834358475073941, at epoch: 53\n",
      "\n",
      "Number of units: 9980\n",
      "train loss: 0.004954660819756214, at epoch: 52\n",
      "\n",
      "Number of units: 9990\n",
      "train loss: 0.0048008626815851585, at epoch: 54\n",
      "\n",
      "Number of units: 10000\n",
      "train loss: 0.0049787081527688315, at epoch: 52\n",
      "\n",
      "Number of units: 10010\n",
      "train loss: 0.004694181097195269, at epoch: 53\n",
      "\n",
      "Number of units: 10020\n",
      "train loss: 0.004709767309273047, at epoch: 54\n",
      "\n",
      "Number of units: 10030\n",
      "train loss: 0.004807313302221132, at epoch: 52\n",
      "\n",
      "Number of units: 10040\n",
      "train loss: 0.004909914143605647, at epoch: 52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Generate synthetic dataset\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "X = np.random.rand(100, 10) # 100 datapoints of 10 features each\n",
    "y = np.random.randint(0, 2, size = 100) # binary classification labels\n",
    "\n",
    "# Initialize arrays for storing weights\n",
    "initial_weights = []\n",
    "final_weights = []\n",
    "diff_weights = []\n",
    "\n",
    "\n",
    "class DynamicDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # X: (N, 9), Y: (N, 6)\n",
    "        self.X = data['X'].astype(np.float32)\n",
    "        self.Y = data['Y'].astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "#define model\n",
    "class NeuralNet(nn.Module):\n",
    "    # ---\n",
    "    # Your code goes here\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, units)\n",
    "        self.layer2 = nn.Linear(units, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.layer1(x))\n",
    "        x = torch.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "\n",
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        train_prediction = model.forward(features)\n",
    "        labels = labels.view(-1, 1)\n",
    "        # print(\n",
    "        #     f\"prediction: {train_prediction}, and its shape: {train_prediction.size()}\")\n",
    "        # print(f\"ground_truth: {labels}, and its shape: {labels.size()}\")\n",
    "        loss = criterion(train_prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    # print(f\"train loss: {train_loss/(i+1)}\")\n",
    "    # ---\n",
    "    train_loss /= (i + 1)\n",
    "    return train_loss\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(test_loader):\n",
    "          features = data[0]\n",
    "          labels = data[1]\n",
    "          test_prediction = model.forward(features)\n",
    "          loss = criterion(test_prediction, labels)\n",
    "          test_loss += loss.item()\n",
    "    print(f\"test loss: {test_loss/(i+1)}\\n\")\n",
    "    # ---\n",
    "    return test_loss\n",
    "\n",
    "# We are only using CPU, and GPU is not allowed.\n",
    "device = torch.device(\"cpu\")\n",
    "# torch.manual_seed(random_state)\n",
    "\n",
    "data = {\"X\":X, \"Y\":y}\n",
    "dataset = DynamicDataset(data)\n",
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=True, batch_size=batch_size)\n",
    "# The name of the directory to save all the checkpoints\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_dir = os.path.join('models', timestr)\n",
    "\n",
    "# Define the range of units in the first layer\n",
    "unit_range = np.arange(100, 10050, 10)\n",
    "\n",
    "for units in unit_range:\n",
    "    # Define the model architecture\n",
    "    print(f\"Number of units: {units}\")\n",
    "    model = NeuralNet(input_dim=10, units=units)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print initial weights\n",
    "    # initial_weights.append(model.layers[0].get_weights()[0])\n",
    "    # initial_model_copy = type(model)(input_dim=10, units=units)\n",
    "    # initial_model_copy.load_state_dict(model.state_dict())\n",
    "    # initial_layer_weights = initial_model_copy.state_dict()\n",
    "    initial_layer_weights = copy.deepcopy(model.state_dict())  # to keep it seperate from its internal pointers\n",
    "    initial_weights.append(initial_layer_weights)\n",
    "    # print(f\"initial layer weights: \\n{initial_layer_weights}\")\n",
    "    # Compile the model with a loss function and an optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    epochs = 2000\n",
    "    previous_lowest_train_loss = float('inf')\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # print(f\"epoch number {epoch}\")\n",
    "        train_loss = train(model=model, train_loader=train_loader)\n",
    "        # print(f\"train loss: {train_loss}, at epoch: {epoch}\")\n",
    "        if train_loss <= 0.005:\n",
    "            print(f\"train loss: {train_loss}, at epoch: {epoch}\\n\")\n",
    "            break\n",
    "    final_layer_weights = model.state_dict()\n",
    "    final_weights.append(final_layer_weights)\n",
    "    # # print(f\"final layer weights: \\n{final_layer_weights}\")\n",
    "    # layer1_max_difference = torch.max(final_weights[-1][\"layer1.weight\"] - initial_weights[-1][\"layer1.weight\"])\n",
    "    # layer2_max_difference = torch.max(final_weights[-1][\"layer2.weight\"] - initial_weights[-1][\"layer2.weight\"])\n",
    "    # print(f\"layer 1 diff: {layer1_max_difference}\")\n",
    "    # print(f\"layer 2 diff: {layer2_max_difference}\")\n",
    "    # max_difference = max(layer1_max_difference, layer2_max_difference)\n",
    "    # print(f\"the max difference is {max_difference} for {units} units\\n\")\n",
    "    # diff_weights.append(max_difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e81aef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "weights = {\"initial weights\" : initial_weights, \"final weights\": final_weights}\n",
    "pickle.dump(weights, open( \"data_big.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70fdc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# max_vals = []\n",
    "\n",
    "# for i in range(len(diff_weights)):\n",
    "#     max_vals.append(diff_weights[i])\n",
    "    \n",
    "# # set the size of the figure\n",
    "# fig, ax = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "# # create the plot\n",
    "# ax.plot(unit_range, max_vals, linestyle = '-', marker = 'o')\n",
    "\n",
    "# # set the title and axis labels\n",
    "# ax.set_title('Maximum difference in weights vs neurons')\n",
    "# ax.set_xlabel('Number of neurons')\n",
    "# ax.set_ylabel('Maximum weight difference')\n",
    "# ax.set_ylim([0, 2.5])\n",
    "# ax.set_xlim([100, 1000])\n",
    "\n",
    "# # calculate line of best fit\n",
    "# coefficients = np.polyfit(unit_range, max_vals, 2)\n",
    "# line_of_best_fit = coefficients[0] * unit_range**2 + coefficients[1] * unit_range + coefficients[2]\n",
    "\n",
    "# # plot line of best fit \n",
    "# ax.plot(unit_range, line_of_best_fit, linestyle = '--', color = 'red')\n",
    "\n",
    "# # display the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52bd086",
   "metadata": {},
   "source": [
    "Personal progress:\n",
    "- reimplement code in pytorch\n",
    "- added early stoping at training loss of 0.005\n",
    "- added data saving in pickle file format for futher processing\n",
    "- implemented Frobenius norm of layer weights and unit calculation to plot results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaf90f7e",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- classify bound of significant movement on synthetic data\n",
    "- 2 layer neural nets\n",
    "- find network under our bound of significance of lazy training\n",
    "- take that network\n",
    "- add depth\n",
    "- find how many neurons we can narrow it by with 2 layers instead of 1\n",
    "- switch to MNIST and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3690c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"results/data_big.pkl\", \"rb\"))\n",
    "initial = data[\"initial weights\"]\n",
    "final = data[\"final weights\"]\n",
    "size = len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83b08296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4628d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = []\n",
    "for i in range(size):\n",
    "    # Compute Frobenius norm between A and B\n",
    "    fro_norm_1 = torch.norm(\n",
    "        initial[i][\"layer1.weight\"]-final[i][\"layer1.weight\"], p='fro')\n",
    "    fro_norm_2 = torch.norm(\n",
    "        initial[i][\"layer2.weight\"]-final[i][\"layer2.weight\"], p='fro')\n",
    "    fro_norm = fro_norm_1 + fro_norm_2\n",
    "    norms.append(fro_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2964bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "unit_range = np.arange(100, 10050, 10)\n",
    "for units in unit_range:\n",
    "    norms[count] = norms[count] / units \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6504938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the size of the figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# create the plot\n",
    "ax.plot(unit_range, norms, linestyle='-', marker='o')\n",
    "\n",
    "# set the title and axis labels\n",
    "ax.set_title('Euclidian distance between the initial and final weights vs number of neurons')\n",
    "ax.set_xlabel('Number of neurons')\n",
    "ax.set_ylabel('Euclidian distance between the initial and final weights')\n",
    "\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fb1b71d",
   "metadata": {},
   "source": [
    "find the percantage changes in euclidian distance between neurons\n",
    "- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4aaa384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.01515685\n",
      "Median: 0.006108641\n",
      "Variance: 0.0009900859\n",
      "Standard deviation: 0.03146563\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a large set of Frobenius norms\n",
    "# norms = np.random.normal(loc=10, scale=2, size=10000)\n",
    "norms = np.array(norms)\n",
    "\n",
    "\n",
    "# Compute descriptive statistics\n",
    "mean_norm = np.mean(norms)\n",
    "median_norm = np.median(norms)\n",
    "var_norm = np.var(norms)\n",
    "std_norm = np.std(norms)\n",
    "\n",
    "# Print descriptive statistics\n",
    "print('Mean:', mean_norm)\n",
    "print('Median:', median_norm)\n",
    "print('Variance:', var_norm)\n",
    "print('Standard deviation:', std_norm)\n",
    "\n",
    "# Plot a histogram of the Frobenius norms\n",
    "plt.hist(norms, bins=40)\n",
    "plt.title('Histogram of Frobenius Norms')\n",
    "plt.xlabel('Norm')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9db8a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the first-order differences\n",
    "diffs = np.diff(norms)\n",
    "\n",
    "# Plot the norms and differences\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "ax[0].plot(norms)\n",
    "ax[0].set_ylabel('Norm')\n",
    "ax[0].set_title('Frobenius Norms')\n",
    "ax[1].plot(diffs)\n",
    "ax[1].set_ylabel('Difference')\n",
    "ax[1].set_xlabel('Index')\n",
    "ax[1].set_title('First-order Differences')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70e89a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Threshold  Index\n",
      "0       0.001      0\n",
      "1       0.001      1\n",
      "2       0.001      2\n",
      "3       0.001      3\n",
      "4       0.001      4\n",
      "5       0.001      5\n",
      "6       0.001      6\n",
      "7       0.001      7\n",
      "8       0.001      8\n",
      "9       0.001      9\n",
      "10      0.001     10\n",
      "11      0.001     11\n",
      "12      0.001     12\n",
      "13      0.001     13\n",
      "14      0.001     14\n",
      "15      0.001     15\n",
      "16      0.001     16\n",
      "17      0.001     17\n",
      "18      0.001     18\n",
      "19      0.001     19\n",
      "20      0.001     21\n",
      "21      0.001     22\n",
      "22      0.001     23\n",
      "23      0.001     24\n",
      "24      0.001     25\n",
      "25      0.001     26\n",
      "26      0.001     27\n",
      "27      0.001     28\n",
      "28      0.001     29\n",
      "29      0.001     31\n",
      "30      0.001     33\n",
      "31      0.001     34\n",
      "32      0.001     35\n",
      "33      0.001     36\n",
      "34      0.001     37\n",
      "35      0.001     38\n",
      "36      0.001     39\n",
      "37      0.001     40\n",
      "38      0.001     41\n",
      "39      0.001     45\n",
      "40      0.001     46\n",
      "41      0.001     50\n",
      "42      0.001     52\n",
      "43      0.001     55\n",
      "44      0.001     57\n",
      "45      0.001     59\n",
      "46      0.001     61\n",
      "47      0.001     65\n",
      "48      0.001     70\n",
      "49      0.001     74\n",
      "50      0.001     78\n",
      "51      0.001    263\n",
      "52      0.001    264\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "threshold = 0.001\n",
    "idx = np.where(np.abs(diffs) > threshold)[0]\n",
    "\n",
    "# Create a table of threshold values and corresponding indices\n",
    "df = pd.DataFrame({'Threshold': threshold, 'Index': idx})\n",
    "\n",
    "# Print the table\n",
    "print(df)\n",
    "# Plot the norms and differences\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "ax[0].plot(norms)\n",
    "ax[0].set_ylabel('Norm')\n",
    "ax[0].set_title('Frobenius Norms')\n",
    "ax[1].plot(diffs)\n",
    "ax[1].plot(idx, diffs[idx], 'ro')\n",
    "ax[1].set_ylabel('Difference')\n",
    "ax[1].set_xlabel('Index')\n",
    "ax[1].set_title('First-order Differences')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320b6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
